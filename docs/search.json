[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Measurement Error",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "2  Data Visualization",
    "section": "",
    "text": "2.1 Descriptive Graphs",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#descriptive-graphs",
    "href": "visualization.html#descriptive-graphs",
    "title": "2  Data Visualization",
    "section": "",
    "text": "2.1.1 Demographic Histograms (Blood Pressure vs Demographic Variables)\nSystolic vs Age and Systolic vs Gender are very clear\n\nnhanes_data %&gt;% drop_na(bp_dia_mean) %&gt;%\n  ggplot(aes(x=bp_dia_mean, color=demo_age_cat)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Diastolic) with Age\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_age_cat)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Age\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_race)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Race\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_gender)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Gender\")\n\n\n\n\n\n\n\nnhanes_female &lt;- nhanes_data[nhanes_data$demo_gender == \"Women\", ]\nnhanes_female %&gt;% drop_na(demo_pregnant) %&gt;% \n    ggplot(aes(x=bp_sys_mean, color=demo_pregnant)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Pregnancy (Men Excluded)\")\n\nWarning: Removed 1678 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_female %&gt;% drop_na(demo_pregnant) %&gt;% \n    ggplot(aes(x=bp_dia_mean, color=demo_pregnant)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Diastolic) with Pregnancy (Men Excluded)\")\n\nWarning: Removed 1809 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Comorbidities Box Plots (Blood Pressure vs Covariate)\n\nnhanes_data %&gt;% drop_na(cc_smoke) %&gt;%\n  ggplot(aes(x=cc_smoke, y=bp_sys_mean, fill=cc_smoke)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Smoking Status\") +\n    xlab(\"\")\n\nWarning: Removed 3111 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_bmi) %&gt;%\n  ggplot(aes(x=cc_bmi, y=bp_sys_mean, fill=cc_bmi)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS BMI Status\") +\n    xlab(\"\")\n\nWarning: Removed 2867 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_cvd_chd) %&gt;%\n  ggplot(aes(x=cc_cvd_chd, y=bp_sys_mean, fill=cc_cvd_chd)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Chronic Heart Disease Status\") +\n    xlab(\"\")\n\nWarning: Removed 3049 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_ckd) %&gt;%\n  ggplot(aes(x=cc_ckd, y=bp_sys_mean, fill=cc_ckd)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Chronic Kidney Disease Status\") +\n    xlab(\"\")\n\nWarning: Removed 3265 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_diabetes) %&gt;%\n  ggplot(aes(x=cc_diabetes, y=bp_sys_mean, fill=cc_diabetes)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Diabetes\") +\n    xlab(\"\")\n\nWarning: Removed 3265 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n2.1.3 Comorbidities Histograms (Blood Pressure vs Covariate)\n\nnhanes_data %&gt;% drop_na(cc_smoke) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_smoke)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins= 80) +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    ggtitle(\"Blood Pressure with Smoking Histogram\")\n\nWarning: Removed 3111 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_bmi) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_bmi)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with BMI Histogram\")\n\nWarning: Removed 2867 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_cvd_stroke) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_cvd_stroke)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with Stroke Histogram\")\n\nWarning: Removed 3050 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_diabetes) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_diabetes)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with Diabetes Histogram\")\n\nWarning: Removed 3265 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n2.1.4 Chi Squared Tests (Testing difference between covariates and hypertension status)\nI realize this isn’t very useful (of course the result will be significant) but I left them in anyways\n\n#Body Mass Index\nnhanes_bmi_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_bmi) %&gt;% drop_na(cc_bmi)\nnhanes_bmi_df &lt;- table(nhanes_bmi_df$htn_accaha, nhanes_bmi_df$cc_bmi)\nchisq.test(nhanes_bmi_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_df\nX-squared = 2576, df = 3, p-value &lt; 2.2e-16\n\n#Smoking \nnhanes_smoke_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_smoke) %&gt;% drop_na(cc_smoke)\nnhanes_smoke_df &lt;- table(nhanes_smoke_df$htn_accaha, nhanes_smoke_df$cc_smoke)\nchisq.test(nhanes_smoke_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_df\nX-squared = 991.83, df = 2, p-value &lt; 2.2e-16\n\n#Chronic Heart Disease\nnhanes_chd_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_cvd_chd) %&gt;% drop_na(cc_cvd_chd)\nnhanes_chd_df &lt;- table(nhanes_chd_df$htn_accaha, nhanes_chd_df$cc_cvd_chd)\nchisq.test(nhanes_chd_df)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_chd_df\nX-squared = 1357.9, df = 1, p-value &lt; 2.2e-16\n\n#Chronic Kidney Disease\nnhanes_ckd_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_ckd) %&gt;% drop_na(cc_ckd)\nnhanes_ckd_df &lt;- table(nhanes_ckd_df$htn_accaha, nhanes_ckd_df$cc_ckd)\nchisq.test(nhanes_ckd_df)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_ckd_df\nX-squared = 3702.1, df = 1, p-value &lt; 2.2e-16\n\n\n\n\n2.1.5 Two Sample T Tests\n(Testing the Difference in blood pressure between comorbidities)\nShould I extend to demographic data?\n\n#Don't know if this is the idea but:\nnhanes_dia_df &lt;- nhanes_data %&gt;% select(htn_accaha, bp_dia_mean) %&gt;% drop_na(bp_dia_mean)\nt_test &lt;- t.test(bp_dia_mean ~ htn_accaha, data=nhanes_dia_df)\nt_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_dia_mean by htn_accaha\nt = -96.487, df = 45747, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -9.443644 -9.067610\nsample estimates:\n mean in group No mean in group Yes \n         65.87311          75.12873 \n\n#Smoking T Test (Excludes Former):\nnhanes_sys_smoke &lt;- nhanes_data[nhanes_data$cc_smoke != \"Former\", ] %&gt;% select(cc_smoke, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_smoke)\nsmoke_test &lt;- t.test(bp_sys_mean ~ cc_smoke, data = nhanes_sys_smoke)\nsmoke_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_smoke\nt = 0.85479, df = 20379, p-value = 0.3927\nalternative hypothesis: true difference in means between group Never and group Current is not equal to 0\n95 percent confidence interval:\n -0.2343734  0.5968840\nsample estimates:\n  mean in group Never mean in group Current \n             123.6788              123.4975 \n\n#BMI T Test (Compares &lt;25 and 35+):\nnhanes_sys_bmi &lt;- nhanes_data[nhanes_data$cc_bmi %in% c(\"&lt;25\", \"35+\"), ] %&gt;% select(cc_bmi, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_bmi)\nbmi_test &lt;- t.test(bp_sys_mean ~ cc_bmi, data = nhanes_sys_bmi)\nbmi_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_bmi\nt = -26.614, df = 18857, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group &lt;25 and group 35+ is not equal to 0\n95 percent confidence interval:\n -6.963786 -6.008393\nsample estimates:\nmean in group &lt;25 mean in group 35+ \n          120.332           126.818 \n\n#Diabetes T Test:\nnhanes_sys_diabetes &lt;- nhanes_data %&gt;% select(cc_diabetes, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_diabetes)\ndiabetes_test &lt;- t.test(bp_sys_mean ~ cc_diabetes, data = nhanes_sys_diabetes)\ndiabetes_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_diabetes\nt = -40.314, df = 9221.3, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -10.84351  -9.83791\nsample estimates:\n mean in group No mean in group Yes \n         122.7845          133.1252",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#simple-diabetes-modeling",
    "href": "visualization.html#simple-diabetes-modeling",
    "title": "2  Data Visualization",
    "section": "2.2 Simple Diabetes Modeling",
    "text": "2.2 Simple Diabetes Modeling\nWe are choosing Diabetes as the co-morbidity for modeling. We will try to predict the occurrence of diabetes as a function of blood pressure as well as other covariates.\nThe most basic model possible is a simple logistic regression model predicting diabetes status based on blood pressure:\n\nsimple_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.9404827  0.0770324  -64.14   &lt;2e-16 ***\nbp_sys_mean  0.0238141  0.0005811   40.98   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 41987  on 56532  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 41991\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0071511\n0.0770324\n-64.13512\n0\n0.0061477\n0.0083151\n\n\nbp_sys_mean\n1.0240999\n0.0005811\n40.98151\n0\n1.0229344\n1.0252673\n\n\n\n\nsimple_diab_model_dia &lt;- glm(cc_diabetes ~ bp_dia_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_dia)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_dia_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.652673   0.073728 -22.416  &lt; 2e-16 ***\nbp_dia_mean -0.003651   0.001039  -3.514 0.000441 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43309  on 56285  degrees of freedom\nResidual deviance: 43297  on 56284  degrees of freedom\n  (3513 observations deleted due to missingness)\nAIC: 43301\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_dia, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.1915372\n0.0737285\n-22.415661\n0.0000000\n0.1657332\n0.2212722\n\n\nbp_dia_mean\n0.9963553\n0.0010390\n-3.514294\n0.0004409\n0.9943280\n0.9983860\n\n\n\n\n\n\n2.2.0.1 Model Explanation:\nFor the logistic regression using systolic blood pressure, we can see that the odds ratio beta parameter is 1.024. This implies that a higher systolic blood pressure corresponds to increased chances of observing diabetes.\nA more exact interpretation would be that: for one additional unit increase in systolic blood pressure, the estimated risk of having diabetes increases by 2.4%.\nThis value may not seem extremely high, yet it still has a p value evaluated to be 0 by R. We can also see that the 95% confidence interval of this parameter ranges between 1.0229 and 1.0253, meaning that the model predicts that the true relationship falls within this interval with a 95% certainty, since the true value of the parameter is most likely within this interval.\nThe opposite is true with diastolic blood pressure: the beta parameter is 0.996, implying that higher diastolic blood pressure corresponds to a lower chance of observing diabetes. For an additional unit increase in diastolic blood pressure, the estimated risk of having diabetes decreases by 0.04%.\nNote: systolic blood pressure is a better predictor of cardiovascular disease, so I chose to consider systolic rather than diastolic in future models.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#demographic-model",
    "href": "visualization.html#demographic-model",
    "title": "2  Data Visualization",
    "section": "2.3 Demographic Model",
    "text": "2.3 Demographic Model\nNext, we build a model including the demographic variables as well. This will hopefully provide a more accurate model, since it will have access to the further information in order to make predictions.\n\ndemo_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender,data = nhanes_data, family = binomial)\n\nsummary (demo_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender, family = binomial, data = nhanes_data)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -5.6927561  0.0885174 -64.312  &lt; 2e-16 ***\nbp_sys_mean                  0.0037581  0.0006792   5.533 3.14e-08 ***\ndemo_age_years               0.0529545  0.0009161  57.806  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.9034242  0.0350353  25.786  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  0.8093210  0.0606852  13.336  &lt; 2e-16 ***\ndemo_raceHispanic            0.8592775  0.0343392  25.023  &lt; 2e-16 ***\ndemo_raceOther               0.7478892  0.0718834  10.404  &lt; 2e-16 ***\ndemo_genderWomen            -0.1547613  0.0265581  -5.827 5.63e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 37780  on 56526  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 37796\n\nNumber of Fisher Scoring iterations: 5\n\nknitr::kable(tidy(demo_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0033703\n0.0885174\n-64.312318\n0\n0.0028326\n0.0040077\n\n\nbp_sys_mean\n1.0037652\n0.0006792\n5.533450\n0\n1.0024283\n1.0051008\n\n\ndemo_age_years\n1.0543817\n0.0009161\n57.805744\n0\n1.0524962\n1.0562830\n\n\ndemo_raceNon-Hispanic Black\n2.4680396\n0.0350353\n25.786107\n0\n2.3042427\n2.6434926\n\n\ndemo_raceNon-Hispanic Asian\n2.2463822\n0.0606852\n13.336382\n0\n1.9925692\n2.5278493\n\n\ndemo_raceHispanic\n2.3614540\n0.0343392\n25.023206\n0\n2.2077734\n2.5259187\n\n\ndemo_raceOther\n2.1125361\n0.0718834\n10.404206\n0\n1.8320999\n2.4286788\n\n\ndemo_genderWomen\n0.8566196\n0.0265581\n-5.827267\n0\n0.8131556\n0.9023806\n\n\n\n\n\n\n2.3.0.1 Model Explanation\nIn this model, we can still see a slight upwards trend with systolic blood pressure, although it is a bit weaker (1.024 &gt; 1.003). With this parameter, the estimated risk of having diabetes increases only by 0.3%. Although the effect is smaller, we can see that the confidence interval is between 1.0024 and 1.0051, which does not include 1. So, although small, the positive relationship is most likely significant.\n\n\n2.3.0.2 Demographics\nAge:\nThe model also tells us that age is positively correlated with the observation of diabetes. With a log odds ratio of 1.054, it seems that every year increases the risk of diabetes occurrence by 5.4%.\nRace:\nThe log odds ratio for categorical variables compares the other variables to the baseline “reference group”. Here, the “reference group” for the race variable is Non-Hispanic White. We can see that, in comparison to this group, all other races have significantly higher risk of diabetes: for example, the Hispanic population’s risk of diabetes occurrence is 2.36 times higher than the Non-Hispanic White population.\nGender:\nWith this variable, the reference group is men. We can see that women have a lower odds of having diabetes compared to men. Specifically, the risk of diabetes in women is about 85.6% of in men.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#full-model",
    "href": "visualization.html#full-model",
    "title": "2  Data Visualization",
    "section": "2.4 Full Model",
    "text": "2.4 Full Model\nLastly, we want to create a model including confounding variables. To achieve this, we must first determine which other variables are confounding, meaning they have significant associations with diabetes.\nWe can achieve this by using chi squared test, which compares whether or not the observed ratios of diabetes and confounding variables matches the ratios expected by random chance. If the chi squared test determines significance, then diabetes and the other variables commonly occur together and therefore are confounding.\n\n2.4.0.1 Perform Chi Squared Tests:\n\n#Testing for BMI\nnhanes_bmi_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_bmi) %&gt;% drop_na(cc_bmi) %&gt;% drop_na(cc_diabetes)\nnhanes_bmi_diab &lt;- table(nhanes_bmi_diab)\nnhanes_bmi_diab\n\n           cc_bmi\ncc_diabetes   &lt;25 25 to &lt;30 30 to &lt;35   35+\n        No  17390     16913      9476  6965\n        Yes   974      2173      2056  2274\n\nchisq.test(nhanes_bmi_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_df\nX-squared = 2576, df = 3, p-value &lt; 2.2e-16\n\n#Testing for Smoking\nnhanes_smoke_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_smoke) %&gt;% drop_na(cc_smoke) %&gt;% drop_na(cc_diabetes)\nnhanes_smoke_diab &lt;- table(nhanes_smoke_diab)\nnhanes_smoke_diab\n\n           cc_smoke\ncc_diabetes Never Former Current\n        No  27414  11107   10366\n        Yes  3917   2587    1249\n\nchisq.test(nhanes_smoke_diab)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_diab\nX-squared = 435.81, df = 2, p-value &lt; 2.2e-16\n\n#Testing for Hypertensive Medication use\nnhanes_med_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, bp_med_use) %&gt;% drop_na(bp_med_use) %&gt;% drop_na(cc_diabetes)\nnhanes_med_diab &lt;- table(nhanes_med_diab)\nnhanes_med_diab\n\n           bp_med_use\ncc_diabetes    No   Yes\n        No  41679 10079\n        Yes  3138  4611\n\nchisq.test(nhanes_med_diab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_med_diab\nX-squared = 5807.1, df = 1, p-value &lt; 2.2e-16\n\n\nAfter this analysis, we can see that all three variables, BMI, Smoking, and Medication Use, are all confounding. We can include all of them in the next model, in addition to systolic blood pressure and the demographic variables:\n\n#to prevent errors down the line, exclude the rows with na:\nused_vars = c('cc_diabetes', 'bp_sys_mean', 'demo_age_years', 'demo_race', 'demo_gender', 'cc_bmi', 'cc_smoke', 'bp_med_use')\nclean_nhanes &lt;- nhanes_data[complete.cases(nhanes_data[,..used_vars]), ]\n\nfull_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender+ cc_bmi + cc_smoke + bp_med_use, data = clean_nhanes, family = binomial)\n\nsummary(full_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender + cc_bmi + cc_smoke + bp_med_use, family = binomial, \n    data = clean_nhanes)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -6.3003463  0.1112295 -56.643  &lt; 2e-16 ***\nbp_sys_mean                  0.0017066  0.0007373   2.315   0.0206 *  \ndemo_age_years               0.0470354  0.0011312  41.579  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.6987360  0.0374745  18.646  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  1.3022903  0.0660355  19.721  &lt; 2e-16 ***\ndemo_raceHispanic            0.8889260  0.0366792  24.235  &lt; 2e-16 ***\ndemo_raceOther               0.8913458  0.0763522  11.674  &lt; 2e-16 ***\ndemo_genderWomen            -0.3082492  0.0295124 -10.445  &lt; 2e-16 ***\ncc_bmi25 to &lt;30              0.5927344  0.0444524  13.334  &lt; 2e-16 ***\ncc_bmi30 to &lt;35              1.1736075  0.0463565  25.317  &lt; 2e-16 ***\ncc_bmi35+                    1.7702868  0.0480051  36.877  &lt; 2e-16 ***\ncc_smokeFormer               0.0614704  0.0335729   1.831   0.0671 .  \ncc_smokeCurrent              0.1853436  0.0403687   4.591 4.41e-06 ***\nbp_med_useYes                0.9121351  0.0314064  29.043  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 33055  on 52183  degrees of freedom\nAIC: 33083\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(full_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0018357\n0.1112295\n-56.642782\n0.0000000\n0.0014752\n0.0022815\n\n\nbp_sys_mean\n1.0017080\n0.0007373\n2.314675\n0.0206307\n1.0002594\n1.0031545\n\n\ndemo_age_years\n1.0481591\n0.0011312\n41.579121\n0.0000000\n1.0458438\n1.0504919\n\n\ndemo_raceNon-Hispanic Black\n2.0112090\n0.0374745\n18.645645\n0.0000000\n1.8687584\n2.1644762\n\n\ndemo_raceNon-Hispanic Asian\n3.6777100\n0.0660355\n19.721057\n0.0000000\n3.2286139\n4.1827136\n\n\ndemo_raceHispanic\n2.4325157\n0.0366792\n24.235131\n0.0000000\n2.2638469\n2.6139232\n\n\ndemo_raceOther\n2.4384090\n0.0763522\n11.674130\n0.0000000\n2.0964731\n2.8282006\n\n\ndemo_genderWomen\n0.7347322\n0.0295124\n-10.444726\n0.0000000\n0.6934113\n0.7784570\n\n\ncc_bmi25 to &lt;30\n1.8089279\n0.0444524\n13.334145\n0.0000000\n1.6585185\n1.9742572\n\n\ncc_bmi30 to &lt;35\n3.2336368\n0.0463565\n25.316997\n0.0000000\n2.9536973\n3.5423428\n\n\ncc_bmi35+\n5.8725376\n0.0480051\n36.877031\n0.0000000\n5.3470462\n6.4542286\n\n\ncc_smokeFormer\n1.0633990\n0.0335729\n1.830951\n0.0671079\n0.9956021\n1.1356446\n\n\ncc_smokeCurrent\n1.2036319\n0.0403687\n4.591266\n0.0000044\n1.1117990\n1.3024331\n\n\nbp_med_useYes\n2.4896325\n0.0314064\n29.042966\n0.0000000\n2.3411270\n2.6478476\n\n\n\n\n\n\n\n2.4.0.2 Model Explanation\nThe previous variables in this model continue to show the same patterns, although again, the effect of systolic blood pressure is again reduced due to a lower log odds ratio. Now, the p value seems to be much higher at 0.02 (which is still significant, but much less so). The demographic variables also have much the same pattern, although Non-Hispanic Asians seem to have a much higher odds ratio than in the previous model.\n\n\n2.4.0.3 Covariates\nBMI:\nIn this variable, the baseline reference level is bmi &lt;25. In comparison, those with higher bmi have increased risk of having diabetes, with the risk increasing the higher the bmi becomes. For example, those with bmi from 25-30 have a 1.8 times higher risk, while those with a bmi of 35+ have a 5.8 times higher risk.\nSmoking:\nWith a baseline level of nonsmoking, former smokers may have about a 6% higher risk of diabetes. This may not be significant, however, given that the p value is only 0.067 and the odds ratio of 1 falls within the confidence interval. Current smokers, on the other hand, have about a 20% higher risk, this time with a much lower p value of 4*10^-6\nBlood Pressure Medication Use:\nCompared to those who do not use blood pressure medication, individuals who do have about a 2.5 times higher risk of experiencing diabetes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#model-selection",
    "href": "visualization.html#model-selection",
    "title": "2  Data Visualization",
    "section": "2.5 Model Selection",
    "text": "2.5 Model Selection\nIt is possible to find an even better model by modifying which variables we include in our logistic regression model. We can achieve this using model selection, which will selectively add or subtract our explanatory variables from the model and evaluate its performance to choose the final best set of variables.\nExplanation of model selection and or AIC?\n\n2.5.0.1 Backwards Selection:\n\nbackwards = step(full_diab_model_sys)\n\nStart:  AIC=33082.55\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n                 Df Deviance   AIC\n&lt;none&gt;                 33055 33083\n- bp_sys_mean     1    33060 33086\n- cc_smoke        2    33076 33100\n- demo_gender     1    33164 33190\n- bp_med_use      1    33909 33935\n- demo_race       4    33930 33950\n- cc_bmi          3    34756 34778\n- demo_age_years  1    34931 34957\n\nformula(backwards)\n\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n\nIt looks like the backwards selection model returned the same full model. In other words, removing variables does not improve its AIC, and therefore does not improve its performance.\n\n\n2.5.0.2 Forward Selection\n\n#start from a model without any predictors\nnothing &lt;- glm(cc_diabetes ~ 1, data = clean_nhanes, family=binomial)\nsummary(nothing)\n\n\nCall:\nglm(formula = cc_diabetes ~ 1, family = binomial, data = clean_nhanes)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.85919    0.01282  -145.1   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 41278  on 52196  degrees of freedom\nAIC: 41280\n\nNumber of Fisher Scoring iterations: 4\n\nforwards = step(nothing,\nscope=list(lower=formula(nothing),upper=formula(full_diab_model_sys)), direction=\"forward\")\n\nStart:  AIC=41279.9\ncc_diabetes ~ 1\n\n                 Df Deviance   AIC\n+ bp_med_use      1    37076 37080\n+ demo_age_years  1    37252 37256\n+ cc_bmi          3    39218 39226\n+ bp_sys_mean     1    39888 39892\n+ demo_race       4    40891 40901\n+ cc_smoke        2    40911 40917\n+ demo_gender     1    41242 41246\n&lt;none&gt;                 41278 41280\n\nStep:  AIC=37079.85\ncc_diabetes ~ bp_med_use\n\n                 Df Deviance   AIC\n+ demo_age_years  1    35675 35681\n+ cc_bmi          3    35907 35917\n+ demo_race       4    36597 36609\n+ bp_sys_mean     1    36788 36794\n+ cc_smoke        2    36968 36976\n+ demo_gender     1    37009 37015\n&lt;none&gt;                 37076 37080\n\nStep:  AIC=35681.48\ncc_diabetes ~ bp_med_use + demo_age_years\n\n              Df Deviance   AIC\n+ cc_bmi       3    34070 34082\n+ demo_race    4    34834 34848\n+ demo_gender  1    35624 35632\n+ bp_sys_mean  1    35654 35662\n+ cc_smoke     2    35670 35680\n&lt;none&gt;              35675 35681\n\nStep:  AIC=34082.43\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi\n\n              Df Deviance   AIC\n+ demo_race    4    33213 33233\n+ demo_gender  1    33963 33977\n+ bp_sys_mean  1    34050 34064\n+ cc_smoke     2    34054 34070\n&lt;none&gt;              34070 34082\n\nStep:  AIC=33232.52\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race\n\n              Df Deviance   AIC\n+ demo_gender  1    33081 33103\n+ cc_smoke     2    33170 33194\n+ bp_sys_mean  1    33208 33230\n&lt;none&gt;              33213 33233\n\nStep:  AIC=33102.89\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender\n\n              Df Deviance   AIC\n+ cc_smoke     2    33060 33086\n+ bp_sys_mean  1    33076 33100\n&lt;none&gt;              33081 33103\n\nStep:  AIC=33085.88\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke\n\n              Df Deviance   AIC\n+ bp_sys_mean  1    33055 33083\n&lt;none&gt;              33060 33086\n\nStep:  AIC=33082.55\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward Selection process again selects the full model.\n\nbothways = step(nothing, list(lower=formula(nothing),upper=formula(full_diab_model_sys)),\ndirection=\"both\",trace=0)\nformula(bothways)\n\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward-Backward algorithm also selects all of the variables",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#model-diagnostics",
    "href": "visualization.html#model-diagnostics",
    "title": "2  Data Visualization",
    "section": "2.6 Model Diagnostics",
    "text": "2.6 Model Diagnostics\nI followed a guide online but I don’t really know what this is doing:\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"demo_age_years\"]*demo_age_years + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = demo_age_years, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"bp_sys_mean\"]*bp_sys_mean + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = bp_sys_mean, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nTest for Multicollinearity\n\nvif(full_diab_model_sys)\n\n                   GVIF Df GVIF^(1/(2*Df))\nbp_sys_mean    1.169212  1        1.081301\ndemo_age_years 1.528167  1        1.236191\ndemo_race      1.207663  4        1.023866\ndemo_gender    1.091056  1        1.044536\ncc_bmi         1.182024  3        1.028263\ncc_smoke       1.173951  2        1.040908\nbp_med_use     1.235766  1        1.111650\n\n\nOutliers\n\noutlier_nhanes &lt;-\n  clean_nhanes %&gt;% \n  mutate(dffits = dffits(full_diab_model_sys))\n\noutlier_nhanes %&gt;% \n  mutate(obs_number = row_number(),\n         large = ifelse(abs(dffits) &gt; 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)),\n                        \"red\", \"black\")) %&gt;% \n  ggplot(aes(obs_number, dffits, color = large)) +\n  geom_point() + \n  geom_hline(yintercept = c(-1,1) * 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)), color = \"red\") +\n  scale_color_identity()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html",
    "href": "initial_modeling.html",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "",
    "text": "3.1 Simple Diabetes Modeling\nWe are choosing Diabetes as the co-morbidity for modeling. We will try to predict the occurrence of diabetes as a function of blood pressure as well as other covariates.\nThe most basic model possible is a simple logistic regression model predicting diabetes status based on blood pressure:\n#to prevent errors, exclude the rows with na:\nused_vars = c('cc_diabetes', 'bp_sys_mean', 'demo_age_years', 'demo_race', 'demo_gender', 'cc_bmi', 'cc_smoke', 'bp_med_use')\nclean_nhanes &lt;- nhanes_data[complete.cases(nhanes_data[,..used_vars]), ]\n\nsimple_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean, data = clean_nhanes, family = binomial)\n\nsummary(simple_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean, family = binomial, data = clean_nhanes)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.7658807  0.0796600  -59.83   &lt;2e-16 ***\nbp_sys_mean  0.0227452  0.0006007   37.87   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 39888  on 52195  degrees of freedom\nAIC: 39892\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.009\n0.080\n-59.828\n0\n0.007\n0.010\n\n\nbp_sys_mean\n1.023\n0.001\n37.866\n0\n1.022\n1.024\n\n\n\n\nsimple_diab_model_dia &lt;- glm(cc_diabetes ~ bp_dia_mean, data = clean_nhanes, family = binomial)\n\nsummary(simple_diab_model_dia)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_dia_mean, family = binomial, data = clean_nhanes)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.406666   0.076384 -18.416  &lt; 2e-16 ***\nbp_dia_mean -0.006488   0.001074  -6.039 1.55e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41006  on 51976  degrees of freedom\nResidual deviance: 40969  on 51975  degrees of freedom\n  (220 observations deleted due to missingness)\nAIC: 40973\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_dia, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.245\n0.076\n-18.416\n0\n0.211\n0.284\n\n\nbp_dia_mean\n0.994\n0.001\n-6.039\n0\n0.991\n0.996",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#simple-diabetes-modeling",
    "href": "initial_modeling.html#simple-diabetes-modeling",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "",
    "text": "3.1.0.1 Model Explanation:\nFor the logistic regression using systolic blood pressure, we can see that the odds ratio beta parameter is 1.024. This implies that a higher systolic blood pressure corresponds to increased chances of observing diabetes.\nA more exact interpretation would be that: for one additional unit increase in systolic blood pressure, the estimated risk of having diabetes increases by 2.4%.\nThis value may not seem extremely high, yet it still has a p value evaluated to be 0 by R. We can also see that the 95% confidence interval of this parameter ranges between 1.022 and 1.024, meaning that the model predicts that the true relationship falls within this interval with a 95% certainty, since the true value of the parameter is most likely within this interval.\nThe opposite is true with diastolic blood pressure: the beta parameter is 0.996, implying that higher diastolic blood pressure corresponds to a lower chance of observing diabetes. For an additional unit increase in diastolic blood pressure, the estimated risk of having diabetes decreases by 0.04%.\nNote: systolic blood pressure is a better predictor of cardiovascular disease, so I chose to consider systolic rather than diastolic in future models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#demographic-model",
    "href": "initial_modeling.html#demographic-model",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "3.2 Demographic Model",
    "text": "3.2 Demographic Model\nNext, we build a model including the demographic variables as well. This will hopefully provide a more accurate model, since it will have access to the further information in order to make predictions.\n\ndemo_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender,data = clean_nhanes, family = binomial)\n\nsummary (demo_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender, family = binomial, data = clean_nhanes)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -5.6473577  0.0915063 -61.716  &lt; 2e-16 ***\nbp_sys_mean                  0.0040216  0.0006986   5.756 8.60e-09 ***\ndemo_age_years               0.0516294  0.0009596  53.804  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.9071035  0.0357034  25.407  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  0.7971431  0.0615302  12.955  &lt; 2e-16 ***\ndemo_raceHispanic            0.8596099  0.0349608  24.588  &lt; 2e-16 ***\ndemo_raceOther               0.7732236  0.0727607  10.627  &lt; 2e-16 ***\ndemo_genderWomen            -0.1472718  0.0270704  -5.440 5.32e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 36211  on 52189  degrees of freedom\nAIC: 36227\n\nNumber of Fisher Scoring iterations: 5\n\nknitr::kable(tidy(demo_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.004\n0.092\n-61.716\n0\n0.003\n0.004\n\n\nbp_sys_mean\n1.004\n0.001\n5.756\n0\n1.003\n1.005\n\n\ndemo_age_years\n1.053\n0.001\n53.804\n0\n1.051\n1.055\n\n\ndemo_raceNon-Hispanic Black\n2.477\n0.036\n25.407\n0\n2.310\n2.657\n\n\ndemo_raceNon-Hispanic Asian\n2.219\n0.062\n12.955\n0\n1.965\n2.501\n\n\ndemo_raceHispanic\n2.362\n0.035\n24.588\n0\n2.206\n2.530\n\n\ndemo_raceOther\n2.167\n0.073\n10.627\n0\n1.876\n2.495\n\n\ndemo_genderWomen\n0.863\n0.027\n-5.440\n0\n0.818\n0.910\n\n\n\n\n\n\n3.2.0.1 Model Explanation\nIn this model, we can still see a slight upwards trend with systolic blood pressure, although it is a bit weaker (1.024 &gt; 1.003). With this parameter, the estimated risk of having diabetes increases only by 0.3%. Although the effect is smaller, we can see that the confidence interval is between 1.003 and 1.005, which does not include 1. So, although small, the positive relationship is most likely significant.\n\n\n3.2.0.2 Demographics\nAge:\nThe model also tells us that age is positively correlated with the observation of diabetes. With a log odds ratio of 1.054, it seems that every year increases the risk of diabetes occurrence by 5.4%.\nRace:\nThe log odds ratio for categorical variables compares the other variables to the baseline “reference group”. Here, the “reference group” for the race variable is Non-Hispanic White. We can see that, in comparison to this group, all other races have significantly higher risk of diabetes: for example, the Hispanic population’s risk of diabetes occurrence is 2.36 times higher than the Non-Hispanic White population.\nGender:\nWith this variable, the reference group is men. We can see that women have a lower odds of having diabetes compared to men. Specifically, the risk of diabetes in women is about 85.6% of that of men.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#full-model",
    "href": "initial_modeling.html#full-model",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "3.3 Full Model",
    "text": "3.3 Full Model\nLastly, we want to create a model including confounding variables. To achieve this, we must first determine which other variables are confounding, meaning they have significant associations with diabetes.\nWe can achieve this by using chi squared test, which compares whether or not the observed ratios of diabetes and confounding variables matches the ratios expected by random chance. If the chi squared test determines significance, then diabetes and the other variables commonly occur together and therefore are confounding.\n\n3.3.0.1 Perform Chi Squared Tests:\n\n#Testing for BMI\nnhanes_bmi_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_bmi) %&gt;% drop_na(cc_bmi) %&gt;% drop_na(cc_diabetes)\nnhanes_bmi_diab &lt;- table(nhanes_bmi_diab)\n#nhanes_bmi_diab\nchisq.test(nhanes_bmi_diab)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_diab\nX-squared = 2368.3, df = 3, p-value &lt; 2.2e-16\n\n#Testing for Smoking\nnhanes_smoke_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_smoke) %&gt;% drop_na(cc_smoke) %&gt;% drop_na(cc_diabetes)\nnhanes_smoke_diab &lt;- table(nhanes_smoke_diab)\n#nhanes_smoke_diab\nchisq.test(nhanes_smoke_diab)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_diab\nX-squared = 435.81, df = 2, p-value &lt; 2.2e-16\n\n#Testing for Hypertensive Medication use\nnhanes_med_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, bp_med_use) %&gt;% drop_na(bp_med_use) %&gt;% drop_na(cc_diabetes)\nnhanes_med_diab &lt;- table(nhanes_med_diab)\n#nhanes_med_diab\nchisq.test(nhanes_med_diab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_med_diab\nX-squared = 5807.1, df = 1, p-value &lt; 2.2e-16\n\n\nAfter this analysis, we can see that all three variables, BMI, Smoking, and Medication Use, are all confounding. We can include all of them in the next model, in addition to systolic blood pressure and the demographic variables:\n\nfull_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender+ cc_bmi + cc_smoke + bp_med_use, data = clean_nhanes, family = binomial)\n\nsummary(full_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender + cc_bmi + cc_smoke + bp_med_use, family = binomial, \n    data = clean_nhanes)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -6.3003463  0.1112295 -56.643  &lt; 2e-16 ***\nbp_sys_mean                  0.0017066  0.0007373   2.315   0.0206 *  \ndemo_age_years               0.0470354  0.0011312  41.579  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.6987360  0.0374745  18.646  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  1.3022903  0.0660355  19.721  &lt; 2e-16 ***\ndemo_raceHispanic            0.8889260  0.0366792  24.235  &lt; 2e-16 ***\ndemo_raceOther               0.8913458  0.0763522  11.674  &lt; 2e-16 ***\ndemo_genderWomen            -0.3082492  0.0295124 -10.445  &lt; 2e-16 ***\ncc_bmi25 to &lt;30              0.5927344  0.0444524  13.334  &lt; 2e-16 ***\ncc_bmi30 to &lt;35              1.1736075  0.0463565  25.317  &lt; 2e-16 ***\ncc_bmi35+                    1.7702868  0.0480051  36.877  &lt; 2e-16 ***\ncc_smokeFormer               0.0614704  0.0335729   1.831   0.0671 .  \ncc_smokeCurrent              0.1853436  0.0403687   4.591 4.41e-06 ***\nbp_med_useYes                0.9121351  0.0314064  29.043  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 33055  on 52183  degrees of freedom\nAIC: 33083\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(full_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.002\n0.111\n-56.643\n0.000\n0.001\n0.002\n\n\nbp_sys_mean\n1.002\n0.001\n2.315\n0.021\n1.000\n1.003\n\n\ndemo_age_years\n1.048\n0.001\n41.579\n0.000\n1.046\n1.050\n\n\ndemo_raceNon-Hispanic Black\n2.011\n0.037\n18.646\n0.000\n1.869\n2.164\n\n\ndemo_raceNon-Hispanic Asian\n3.678\n0.066\n19.721\n0.000\n3.229\n4.183\n\n\ndemo_raceHispanic\n2.433\n0.037\n24.235\n0.000\n2.264\n2.614\n\n\ndemo_raceOther\n2.438\n0.076\n11.674\n0.000\n2.096\n2.828\n\n\ndemo_genderWomen\n0.735\n0.030\n-10.445\n0.000\n0.693\n0.778\n\n\ncc_bmi25 to &lt;30\n1.809\n0.044\n13.334\n0.000\n1.659\n1.974\n\n\ncc_bmi30 to &lt;35\n3.234\n0.046\n25.317\n0.000\n2.954\n3.542\n\n\ncc_bmi35+\n5.873\n0.048\n36.877\n0.000\n5.347\n6.454\n\n\ncc_smokeFormer\n1.063\n0.034\n1.831\n0.067\n0.996\n1.136\n\n\ncc_smokeCurrent\n1.204\n0.040\n4.591\n0.000\n1.112\n1.302\n\n\nbp_med_useYes\n2.490\n0.031\n29.043\n0.000\n2.341\n2.648\n\n\n\n\n\n\n\n3.3.0.2 Model Explanation\nThe previous variables in this model continue to show the same patterns, although again, the effect of systolic blood pressure is again reduced due to a lower log odds ratio. Now, the p value seems to be much higher at 0.02 (which is still significant, but much less so). The demographic variables also have much the same pattern, although Non-Hispanic Asians seem to have a much higher odds ratio than in the previous model.\n\n\n3.3.0.3 Covariates\nBMI:\nIn this variable, the baseline reference level is bmi &lt;25. In comparison, those with higher bmi have increased risk of having diabetes, with the risk increasing the higher the bmi becomes. For example, those with bmi from 25-30 have a 1.8 times higher risk, while those with a bmi of 35+ have a 5.8 times higher risk.\nSmoking:\nWith a baseline level of nonsmoking, former smokers may have about a 6% higher risk of diabetes. This may not be significant, however, given that the p value is only 0.067 and the odds ratio of 1 falls within the confidence interval. Current smokers, on the other hand, have about a 20% higher risk, this time with a much lower p value of 4*10^-6\nBlood Pressure Medication Use:\nCompared to those who do not use blood pressure medication, individuals who do have about a 2.5 times higher risk of experiencing diabetes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#model-selection",
    "href": "initial_modeling.html#model-selection",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "3.4 Model Selection",
    "text": "3.4 Model Selection\nIt is possible to find an even better model by modifying which variables we include in our logistic regression model. We can achieve this using model selection, which will selectively add or subtract our explanatory variables from the model and evaluate its performance to choose the final best set of variables.\nExplanation of model selection and or AIC?\n\n3.4.0.1 Backwards Selection:\n\nbackwards = step(full_diab_model_sys)\n\nStart:  AIC=33082.55\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n                 Df Deviance   AIC\n&lt;none&gt;                 33055 33083\n- bp_sys_mean     1    33060 33086\n- cc_smoke        2    33076 33100\n- demo_gender     1    33164 33190\n- bp_med_use      1    33909 33935\n- demo_race       4    33930 33950\n- cc_bmi          3    34756 34778\n- demo_age_years  1    34931 34957\n\nformula(backwards)\n\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n\nIt looks like the backwards selection model returned the same full model. In other words, removing variables does not improve its AIC, and therefore does not improve its performance.\n\n\n3.4.0.2 Forward Selection\n\n#start from a model without any predictors\nnothing &lt;- glm(cc_diabetes ~ 1, data = clean_nhanes, family=binomial)\nsummary(nothing)\n\n\nCall:\nglm(formula = cc_diabetes ~ 1, family = binomial, data = clean_nhanes)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.85919    0.01282  -145.1   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 41278  on 52196  degrees of freedom\nAIC: 41280\n\nNumber of Fisher Scoring iterations: 4\n\nforwards = step(nothing,\nscope=list(lower=formula(nothing),upper=formula(full_diab_model_sys)), direction=\"forward\")\n\nStart:  AIC=41279.9\ncc_diabetes ~ 1\n\n                 Df Deviance   AIC\n+ bp_med_use      1    37076 37080\n+ demo_age_years  1    37252 37256\n+ cc_bmi          3    39218 39226\n+ bp_sys_mean     1    39888 39892\n+ demo_race       4    40891 40901\n+ cc_smoke        2    40911 40917\n+ demo_gender     1    41242 41246\n&lt;none&gt;                 41278 41280\n\nStep:  AIC=37079.85\ncc_diabetes ~ bp_med_use\n\n                 Df Deviance   AIC\n+ demo_age_years  1    35675 35681\n+ cc_bmi          3    35907 35917\n+ demo_race       4    36597 36609\n+ bp_sys_mean     1    36788 36794\n+ cc_smoke        2    36968 36976\n+ demo_gender     1    37009 37015\n&lt;none&gt;                 37076 37080\n\nStep:  AIC=35681.48\ncc_diabetes ~ bp_med_use + demo_age_years\n\n              Df Deviance   AIC\n+ cc_bmi       3    34070 34082\n+ demo_race    4    34834 34848\n+ demo_gender  1    35624 35632\n+ bp_sys_mean  1    35654 35662\n+ cc_smoke     2    35670 35680\n&lt;none&gt;              35675 35681\n\nStep:  AIC=34082.43\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi\n\n              Df Deviance   AIC\n+ demo_race    4    33213 33233\n+ demo_gender  1    33963 33977\n+ bp_sys_mean  1    34050 34064\n+ cc_smoke     2    34054 34070\n&lt;none&gt;              34070 34082\n\nStep:  AIC=33232.52\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race\n\n              Df Deviance   AIC\n+ demo_gender  1    33081 33103\n+ cc_smoke     2    33170 33194\n+ bp_sys_mean  1    33208 33230\n&lt;none&gt;              33213 33233\n\nStep:  AIC=33102.89\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender\n\n              Df Deviance   AIC\n+ cc_smoke     2    33060 33086\n+ bp_sys_mean  1    33076 33100\n&lt;none&gt;              33081 33103\n\nStep:  AIC=33085.88\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke\n\n              Df Deviance   AIC\n+ bp_sys_mean  1    33055 33083\n&lt;none&gt;              33060 33086\n\nStep:  AIC=33082.55\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward Selection process again selects the full model.\n\n\n3.4.1 Forward-Backward Selection\n\nbothways = step(nothing, list(lower=formula(nothing),upper=formula(full_diab_model_sys)),\ndirection=\"both\",trace=0)\nformula(bothways)\n\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward-Backward algorithm also selects all of the variables.\nIn this case, the best model (as determined by the AIC) includes all of the variables (systolic blood pressure, age, race, sex, smoking status, BMI, and medication use). In other situations, it may have returned just a few of these variables, but for this example, we can proceed with the full model.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#simple-diabetes-modeling-1",
    "href": "initial_modeling.html#simple-diabetes-modeling-1",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "4.1 Simple Diabetes Modeling",
    "text": "4.1 Simple Diabetes Modeling\nWe are choosing Diabetes as the co-morbidity for modeling. We will try to predict the occurrence of diabetes as a function of blood pressure as well as other covariates.\nThe most basic model possible is a simple logistic regression model predicting diabetes status based on blood pressure:\n\n#to prevent errors, exclude the rows with na:\nused_vars = c('cc_diabetes', 'bp_sys_mean', 'demo_age_years', 'demo_race', 'demo_gender', 'cc_bmi', 'cc_smoke', 'bp_med_use')\nclean_subset &lt;- subset_nhanes[,..used_vars]\nclean_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncc_diabetes\nbp_sys_mean\ndemo_age_years\ndemo_race\ndemo_gender\ncc_bmi\ncc_smoke\nbp_med_use\n\n\n\n\nYes\n134.00000\n77\nNon-Hispanic White\nMen\n35+\nNever\nYes\n\n\nYes\n171.33333\n63\nHispanic\nWomen\n&lt;25\nFormer\nYes\n\n\nYes\n133.16667\n61\nNon-Hispanic Black\nWomen\n35+\nNever\nYes\n\n\nYes\n136.66667\n40\nHispanic\nWomen\n35+\nNever\nYes\n\n\nYes\n177.33333\n76\nHispanic\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nYes\n132.00000\n68\nHispanic\nWomen\n35+\nNever\nYes\n\n\nYes\n146.83333\n76\nOther\nMen\n25 to &lt;30\nNever\nNo\n\n\nYes\n107.33333\n52\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nYes\n125.33333\n71\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nYes\n132.66667\n80\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nYes\n\n\nYes\n121.33333\n65\nHispanic\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nYes\n105.50000\n71\nNon-Hispanic Black\nMen\n35+\nFormer\nYes\n\n\nYes\n138.00000\n44\nNon-Hispanic Black\nWomen\n35+\nCurrent\nYes\n\n\nYes\n137.33333\n49\nNon-Hispanic White\nMen\n&lt;25\nFormer\nNo\n\n\nYes\n112.66667\n62\nNon-Hispanic Black\nMen\n30 to &lt;35\nFormer\nYes\n\n\nYes\n130.66667\n68\nHispanic\nWomen\n25 to &lt;30\nCurrent\nYes\n\n\nYes\n120.16667\n41\nNon-Hispanic White\nMen\n35+\nFormer\nYes\n\n\nYes\n133.33333\n73\nNon-Hispanic Black\nMen\n&lt;25\nCurrent\nYes\n\n\nYes\n139.33333\n74\nHispanic\nMen\n&lt;25\nNever\nYes\n\n\nYes\n116.66667\n71\nNon-Hispanic Black\nMen\n30 to &lt;35\nNever\nNo\n\n\nYes\n193.83333\n45\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nYes\n\n\nYes\n134.00000\n59\nNon-Hispanic Black\nMen\n30 to &lt;35\nNever\nNo\n\n\nYes\n155.33333\n57\nNon-Hispanic Black\nWomen\n35+\nFormer\nYes\n\n\nYes\n138.00000\n49\nHispanic\nWomen\n35+\nNever\nNo\n\n\nYes\n118.16667\n70\nNon-Hispanic Black\nMen\n25 to &lt;30\nNever\nNo\n\n\nYes\n131.33333\n40\nNon-Hispanic White\nWomen\n35+\nCurrent\nYes\n\n\nYes\n160.66667\n64\nHispanic\nWomen\n35+\nNever\nYes\n\n\nYes\n154.66667\n80\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nYes\n\n\nYes\n106.66667\n63\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nYes\n161.33333\n73\nNon-Hispanic Black\nMen\n25 to &lt;30\nNever\nNo\n\n\nYes\n153.33333\n57\nNon-Hispanic Black\nMen\n35+\nCurrent\nNo\n\n\nYes\n136.66667\n66\nHispanic\nMen\n25 to &lt;30\nNever\nYes\n\n\nYes\n171.83333\n60\nNon-Hispanic Black\nMen\n30 to &lt;35\nCurrent\nYes\n\n\nYes\n135.33333\n72\nHispanic\nMen\n25 to &lt;30\nFormer\nNo\n\n\nYes\n89.50000\n59\nHispanic\nMen\n35+\nCurrent\nYes\n\n\nYes\n112.00000\n58\nNon-Hispanic Black\nMen\n35+\nNever\nYes\n\n\nYes\n156.66667\n49\nNon-Hispanic Black\nWomen\n30 to &lt;35\nFormer\nNo\n\n\nYes\n140.00000\n41\nHispanic\nWomen\n35+\nFormer\nNo\n\n\nYes\n126.66667\n66\nNon-Hispanic White\nWomen\n30 to &lt;35\nFormer\nNo\n\n\nYes\n129.33333\n55\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nYes\n136.66667\n51\nHispanic\nWomen\n35+\nCurrent\nYes\n\n\nYes\n123.33333\n64\nHispanic\nMen\n25 to &lt;30\nCurrent\nYes\n\n\nYes\n111.50000\n61\nOther\nWomen\n30 to &lt;35\nCurrent\nNo\n\n\nYes\n146.66667\n44\nHispanic\nMen\n25 to &lt;30\nFormer\nNo\n\n\nYes\n135.33333\n30\nNon-Hispanic White\nMen\n35+\nNever\nYes\n\n\nYes\n176.00000\n79\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nYes\n\n\nYes\n116.00000\n40\nNon-Hispanic White\nWomen\n30 to &lt;35\nCurrent\nYes\n\n\nYes\n150.00000\n79\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nYes\n140.16667\n72\nHispanic\nMen\n25 to &lt;30\nFormer\nNo\n\n\nYes\n114.00000\n57\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nYes\n152.00000\n68\nHispanic\nMen\n30 to &lt;35\nCurrent\nYes\n\n\nYes\n132.83333\n64\nNon-Hispanic Black\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nYes\n125.16667\n51\nNon-Hispanic Black\nMen\n30 to &lt;35\nCurrent\nYes\n\n\nYes\n135.33333\n46\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nYes\n138.66667\n70\nNon-Hispanic White\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nYes\n132.66667\n66\nNon-Hispanic Black\nMen\n30 to &lt;35\nFormer\nYes\n\n\nYes\n119.33333\n64\nHispanic\nMen\n30 to &lt;35\nFormer\nYes\n\n\nYes\n166.00000\n72\nHispanic\nMen\n&lt;25\nFormer\nYes\n\n\nYes\n114.66667\n54\nHispanic\nWomen\n&lt;25\nNever\nYes\n\n\nYes\n128.66667\n54\nHispanic\nMen\n25 to &lt;30\nFormer\nNo\n\n\nYes\n114.66667\n33\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nYes\n105.33333\n45\nHispanic\nMen\n30 to &lt;35\nFormer\nNo\n\n\nYes\n117.50000\n33\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nYes\n169.33333\n70\nHispanic\nWomen\n30 to &lt;35\nNever\nYes\n\n\nYes\n136.00000\n68\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nYes\n103.33333\n41\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nYes\n160.83333\n78\nNon-Hispanic Black\nMen\n25 to &lt;30\nFormer\nYes\n\n\nYes\n99.33333\n80\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nYes\n\n\nYes\n140.00000\n59\nHispanic\nMen\n35+\nFormer\nNo\n\n\nYes\n143.16667\n52\nHispanic\nWomen\n25 to &lt;30\nNever\nYes\n\n\nYes\n133.33333\n59\nNon-Hispanic White\nWomen\n30 to &lt;35\nFormer\nNo\n\n\nYes\n138.50000\n24\nNon-Hispanic Asian\nMen\n25 to &lt;30\nNever\nNo\n\n\nYes\n148.00000\n75\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nYes\n\n\nYes\n116.66667\n66\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nYes\n\n\nYes\n135.33333\n70\nNon-Hispanic Black\nWomen\n35+\nFormer\nYes\n\n\nYes\n114.66667\n75\nNon-Hispanic White\nMen\n35+\nFormer\nYes\n\n\nYes\n132.83333\n66\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nYes\n133.16667\n60\nNon-Hispanic Black\nMen\n25 to &lt;30\nCurrent\nYes\n\n\nNo\n114.66667\n58\nNon-Hispanic White\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n122.66667\n63\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n122.00000\n43\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n105.33333\n23\nNon-Hispanic Asian\nWomen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n116.66667\n47\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nNo\n132.00000\n44\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n126.66667\n39\nNon-Hispanic White\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n116.83333\n43\nNon-Hispanic Asian\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n131.33333\n64\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n146.66667\n69\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n96.00000\n39\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n118.83333\n68\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nNo\n131.33333\n32\nNon-Hispanic Black\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n120.66667\n39\nNon-Hispanic Black\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n158.66667\n50\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n101.33333\n31\nNon-Hispanic White\nWomen\n35+\nCurrent\nNo\n\n\nNo\n126.16667\n39\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n120.66667\n60\nNon-Hispanic Black\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n129.33333\n26\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n118.00000\n34\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n134.66667\n37\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nNo\n112.66667\n36\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n123.33333\n75\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n137.33333\n80\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n144.00000\n57\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n172.66667\n80\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n119.50000\n76\nNon-Hispanic Black\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n134.66667\n59\nOther\nMen\n&lt;25\nCurrent\nYes\n\n\nNo\n105.33333\n33\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n126.00000\n52\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n108.00000\n47\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n101.33333\n20\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n126.00000\n37\nNon-Hispanic Black\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n120.00000\n29\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n110.00000\n80\nNon-Hispanic White\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n113.33333\n55\nHispanic\nMen\n35+\nNever\nNo\n\n\nNo\n134.16667\n80\nNon-Hispanic White\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n126.00000\n43\nOther\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n107.33333\n18\nNon-Hispanic Asian\nMen\n&lt;25\nNever\nNo\n\n\nNo\n147.33333\n80\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n110.00000\n40\nOther\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n111.50000\n32\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n141.33333\n62\nNon-Hispanic White\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n126.66667\n61\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nNo\n113.33333\n33\nNon-Hispanic White\nWomen\n&lt;25\nFormer\nNo\n\n\nNo\n110.00000\n44\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n146.16667\n65\nNon-Hispanic Asian\nMen\n25 to &lt;30\nCurrent\nYes\n\n\nNo\n128.66667\n19\nNon-Hispanic Black\nMen\n&lt;25\nNever\nNo\n\n\nNo\n122.66667\n31\nNon-Hispanic White\nWomen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n129.33333\n68\nNon-Hispanic Black\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n144.00000\n57\nNon-Hispanic White\nWomen\n35+\nFormer\nYes\n\n\nNo\n101.83333\n35\nNon-Hispanic White\nWomen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n126.00000\n80\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nYes\n\n\nNo\n142.00000\n80\nHispanic\nMen\n&lt;25\nNever\nNo\n\n\nNo\n114.66667\n57\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n98.16667\n33\nNon-Hispanic Black\nWomen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n121.16667\n35\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nNo\n149.33333\n60\nHispanic\nMen\n25 to &lt;30\nCurrent\nYes\n\n\nNo\n91.33333\n34\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n120.66667\n36\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n135.33333\n32\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nNo\n120.66667\n56\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n92.00000\n40\nNon-Hispanic Asian\nMen\n&lt;25\nNever\nNo\n\n\nNo\n131.33333\n45\nNon-Hispanic Asian\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n109.33333\n35\nHispanic\nWomen\n&lt;25\nFormer\nNo\n\n\nNo\n153.33333\n70\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n128.00000\n20\nNon-Hispanic Black\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n118.66667\n35\nNon-Hispanic Black\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n130.00000\n62\nOther\nMen\n&lt;25\nNever\nNo\n\n\nNo\n137.33333\n73\nNon-Hispanic White\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n152.66667\n53\nHispanic\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n119.83333\n52\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nNo\n99.83333\n19\nOther\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n116.00000\n20\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n94.00000\n31\nNon-Hispanic Black\nMen\n&lt;25\nNever\nNo\n\n\nNo\n100.50000\n27\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n112.66667\n46\nHispanic\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n128.00000\n60\nNon-Hispanic Black\nMen\n25 to &lt;30\nNever\nYes\n\n\nNo\n120.66667\n64\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n116.00000\n44\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n106.66667\n30\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n96.66667\n27\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n105.33333\n76\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n114.00000\n74\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nYes\n\n\nNo\n114.66667\n57\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n106.00000\n27\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n169.33333\n59\nNon-Hispanic Black\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n120.00000\n80\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n140.66667\n69\nHispanic\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n128.00000\n38\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nNo\n100.16667\n67\nNon-Hispanic Black\nMen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n148.00000\n80\nHispanic\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n100.00000\n35\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n119.33333\n48\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n129.33333\n20\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n118.00000\n34\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n88.00000\n31\nNon-Hispanic White\nWomen\n&lt;25\nFormer\nNo\n\n\nNo\n145.33333\n57\nNon-Hispanic Black\nWomen\n25 to &lt;30\nCurrent\nYes\n\n\nNo\n117.33333\n35\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n146.66667\n62\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n106.00000\n32\nNon-Hispanic White\nWomen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n152.66667\n47\nNon-Hispanic Black\nMen\n35+\nNever\nYes\n\n\nNo\n121.33333\n30\nHispanic\nMen\n&lt;25\nNever\nNo\n\n\nNo\n133.33333\n76\nHispanic\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n124.66667\n26\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nNo\n96.00000\n30\nNon-Hispanic White\nWomen\n&lt;25\nFormer\nNo\n\n\nNo\n172.00000\n80\nHispanic\nMen\n&lt;25\nNever\nYes\n\n\nNo\n136.00000\n69\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nYes\n\n\nNo\n100.66667\n28\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n198.00000\n52\nNon-Hispanic Black\nWomen\n35+\nNever\nYes\n\n\nNo\n121.33333\n61\nNon-Hispanic Black\nWomen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n107.33333\n30\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n104.00000\n57\nNon-Hispanic White\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n113.33333\n44\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n118.00000\n38\nOther\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n114.66667\n24\nOther\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n117.33333\n80\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n111.33333\n45\nNon-Hispanic Black\nWomen\n&lt;25\nCurrent\nYes\n\n\nNo\n107.33333\n31\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n112.66667\n33\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n144.00000\n52\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n112.00000\n45\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n99.33333\n49\nHispanic\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n140.83333\n61\nHispanic\nMen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n131.33333\n58\nHispanic\nMen\n30 to &lt;35\nCurrent\nYes\n\n\nNo\n128.00000\n59\nNon-Hispanic White\nWomen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n89.33333\n22\nNon-Hispanic White\nWomen\n35+\nCurrent\nNo\n\n\nNo\n101.33333\n39\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n121.33333\n26\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n114.66667\n37\nNon-Hispanic White\nWomen\n35+\nCurrent\nNo\n\n\nNo\n117.50000\n46\nOther\nMen\n&lt;25\nNever\nNo\n\n\nNo\n138.00000\n59\nOther\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n127.33333\n34\nNon-Hispanic Black\nWomen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n92.00000\n76\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n94.66667\n18\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n117.33333\n71\nNon-Hispanic Asian\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n107.33333\n53\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n105.50000\n57\nNon-Hispanic Asian\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n127.33333\n59\nNon-Hispanic Black\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n100.66667\n62\nNon-Hispanic Black\nMen\n35+\nNever\nYes\n\n\nNo\n106.66667\n22\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n96.66667\n42\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n124.00000\n28\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n112.66667\n63\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n131.33333\n36\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n110.66667\n21\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n138.00000\n61\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n127.33333\n62\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n108.83333\n33\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n99.33333\n24\nNon-Hispanic White\nWomen\n&lt;25\nFormer\nNo\n\n\nNo\n131.00000\n55\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n106.00000\n43\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n104.66667\n51\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n114.00000\n57\nHispanic\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n134.00000\n72\nHispanic\nMen\n35+\nFormer\nYes\n\n\nNo\n121.33333\n61\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nYes\n\n\nNo\n106.50000\n49\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n167.83333\n52\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nYes\n\n\nNo\n108.00000\n18\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n113.50000\n72\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n109.33333\n44\nHispanic\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n111.33333\n38\nNon-Hispanic Asian\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n111.33333\n23\nHispanic\nWomen\n35+\nFormer\nNo\n\n\nNo\n128.00000\n62\nHispanic\nMen\n&lt;25\nNever\nYes\n\n\nNo\n120.66667\n73\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n103.33333\n27\nOther\nWomen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n136.16667\n67\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n130.00000\n24\nHispanic\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n104.66667\n30\nHispanic\nWomen\n35+\nNever\nNo\n\n\nNo\n124.66667\n24\nHispanic\nWomen\n35+\nFormer\nNo\n\n\nNo\n122.66667\n44\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n121.33333\n41\nHispanic\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n122.00000\n44\nNon-Hispanic White\nWomen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n114.00000\n48\nNon-Hispanic Asian\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n120.66667\n45\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n107.33333\n42\nHispanic\nMen\n&lt;25\nNever\nNo\n\n\nNo\n105.50000\n25\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n119.33333\n45\nNon-Hispanic Black\nWomen\n35+\nNever\nYes\n\n\nNo\n119.33333\n58\nNon-Hispanic Asian\nMen\n&lt;25\nNever\nNo\n\n\nNo\n146.00000\n41\nNon-Hispanic Asian\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n126.00000\n34\nNon-Hispanic Black\nWomen\n35+\nNever\nNo\n\n\nNo\n125.33333\n30\nNon-Hispanic Black\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n100.00000\n29\nHispanic\nWomen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n98.66667\n29\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n126.00000\n51\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n116.83333\n45\nNon-Hispanic Black\nMen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n132.66667\n46\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n142.16667\n39\nNon-Hispanic Black\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n121.00000\n21\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n203.83333\n80\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n155.50000\n57\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n127.33333\n56\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n122.00000\n43\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n108.00000\n32\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n107.33333\n42\nNon-Hispanic Black\nWomen\n35+\nNever\nYes\n\n\nNo\n96.66667\n25\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n121.50000\n61\nNon-Hispanic White\nWomen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n171.33333\n67\nOther\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n134.66667\n22\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n107.83333\n57\nNon-Hispanic Black\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n132.00000\n60\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n136.00000\n77\nNon-Hispanic Black\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n111.16667\n34\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n113.33333\n51\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n93.33333\n47\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n123.33333\n55\nNon-Hispanic Black\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n122.00000\n45\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n144.00000\n72\nHispanic\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n114.00000\n39\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n146.16667\n49\nNon-Hispanic Black\nWomen\n35+\nCurrent\nNo\n\n\nNo\n100.66667\n39\nNon-Hispanic White\nWomen\n35+\nCurrent\nNo\n\n\nNo\n80.00000\n38\nHispanic\nWomen\n35+\nNever\nNo\n\n\nNo\n105.33333\n22\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n136.00000\n80\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n140.83333\n72\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n115.00000\n24\nNon-Hispanic Black\nWomen\n35+\nCurrent\nNo\n\n\nNo\n96.66667\n46\nHispanic\nMen\n&lt;25\nCurrent\nYes\n\n\nNo\n156.00000\n67\nNon-Hispanic White\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n106.66667\n26\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n110.66667\n38\nNon-Hispanic Black\nWomen\n35+\nNever\nNo\n\n\nNo\n130.00000\n45\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n140.00000\n80\nHispanic\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n136.66667\n68\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n128.66667\n59\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n96.00000\n38\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n117.16667\n24\nNon-Hispanic Asian\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n152.00000\n80\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n127.33333\n33\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n110.66667\n37\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n108.00000\n72\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nYes\n\n\nNo\n113.33333\n32\nNon-Hispanic White\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n130.00000\n24\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n164.66667\n77\nNon-Hispanic White\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n116.50000\n33\nNon-Hispanic Black\nWomen\n35+\nCurrent\nNo\n\n\nNo\n120.66667\n22\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n96.00000\n20\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n117.33333\n60\nHispanic\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n120.00000\n55\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n141.33333\n72\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n103.16667\n37\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n136.66667\n38\nNon-Hispanic Black\nMen\n&lt;25\nNever\nYes\n\n\nNo\n126.50000\n40\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n120.00000\n62\nOther\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n161.50000\n80\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n121.33333\n53\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n123.33333\n69\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n130.66667\n36\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nNo\n127.33333\n80\nNon-Hispanic White\nWomen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n114.66667\n53\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n110.66667\n31\nNon-Hispanic Black\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n130.83333\n51\nHispanic\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n104.00000\n35\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n124.66667\n53\nNon-Hispanic Asian\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n109.33333\n33\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n112.00000\n26\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n114.66667\n24\nNon-Hispanic Asian\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n98.66667\n47\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n131.16667\n19\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n166.66667\n55\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n114.00000\n80\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n117.33333\n40\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n111.00000\n21\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n110.66667\n24\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n128.66667\n35\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n130.66667\n51\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n122.66667\n62\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n123.33333\n34\nOther\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n127.33333\n43\nHispanic\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n125.16667\n70\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n106.00000\n23\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n200.00000\n77\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n133.33333\n69\nNon-Hispanic Black\nWomen\n35+\nNever\nYes\n\n\nNo\n127.33333\n56\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n105.33333\n58\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n121.16667\n70\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nNo\n120.50000\n45\nHispanic\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n129.33333\n78\nHispanic\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n106.00000\n37\nNon-Hispanic White\nWomen\n35+\nNever\nNo\n\n\nNo\n134.16667\n55\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n118.66667\n22\nOther\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n102.66667\n55\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n111.00000\n30\nHispanic\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n122.00000\n41\nHispanic\nWomen\n35+\nNever\nYes\n\n\nNo\n117.33333\n35\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n112.00000\n48\nNon-Hispanic Black\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n156.66667\n80\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n107.33333\n44\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n118.50000\n46\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n127.33333\n26\nNon-Hispanic Black\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n179.16667\n80\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n107.33333\n77\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n168.50000\n66\nNon-Hispanic Black\nWomen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n149.00000\n51\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n128.66667\n44\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n114.00000\n31\nHispanic\nWomen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n122.66667\n39\nNon-Hispanic White\nWomen\n35+\nNever\nNo\n\n\nNo\n106.83333\n20\nHispanic\nWomen\n35+\nNever\nNo\n\n\nNo\n140.00000\n47\nNon-Hispanic Black\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n116.66667\n34\nNon-Hispanic White\nWomen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n135.33333\n62\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n108.66667\n63\nNon-Hispanic Black\nMen\n&lt;25\nCurrent\nYes\n\n\nNo\n112.66667\n36\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n140.00000\n27\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n97.00000\n22\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n112.00000\n45\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n110.00000\n32\nNon-Hispanic Black\nWomen\n35+\nNever\nNo\n\n\nNo\n106.00000\n32\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n122.00000\n56\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n115.33333\n53\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n112.00000\n43\nOther\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n122.16667\n37\nNon-Hispanic Black\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n131.16667\n36\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n112.66667\n80\nHispanic\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n122.00000\n49\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nYes\n\n\nNo\n157.33333\n76\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n124.66667\n47\nNon-Hispanic Black\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n108.66667\n56\nNon-Hispanic Black\nMen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n116.00000\n49\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n110.00000\n21\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n111.00000\n73\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nYes\n\n\nNo\n109.33333\n21\nNon-Hispanic Asian\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n160.66667\n44\nHispanic\nMen\n30 to &lt;35\nNever\nYes\n\n\nNo\n112.00000\n47\nNon-Hispanic Black\nWomen\n35+\nCurrent\nYes\n\n\nNo\n142.00000\n56\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n100.00000\n33\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n94.66667\n24\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n110.66667\n41\nOther\nMen\n30 to &lt;35\nNever\nYes\n\n\nNo\n149.33333\n67\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n135.00000\n43\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n115.33333\n34\nHispanic\nMen\n&lt;25\nNever\nNo\n\n\nNo\n135.33333\n46\nNon-Hispanic White\nWomen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n136.00000\n30\nNon-Hispanic Black\nMen\n35+\nCurrent\nNo\n\n\nNo\n127.33333\n65\nHispanic\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n98.00000\n46\nOther\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n100.00000\n18\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n107.33333\n36\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n114.66667\n21\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n122.00000\n49\nHispanic\nWomen\n35+\nNever\nNo\n\n\nNo\n100.00000\n60\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n104.00000\n39\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n116.66667\n20\nNon-Hispanic White\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n112.16667\n19\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n109.33333\n41\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n108.00000\n22\nOther\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n112.16667\n32\nHispanic\nWomen\n35+\nCurrent\nNo\n\n\nNo\n136.00000\n60\nNon-Hispanic Black\nMen\n&lt;25\nNever\nNo\n\n\nNo\n136.00000\n63\nNon-Hispanic Black\nWomen\n30 to &lt;35\nCurrent\nYes\n\n\nNo\n112.00000\n26\nNon-Hispanic White\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n116.16667\n42\nNon-Hispanic White\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n163.33333\n59\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n168.66667\n60\nNon-Hispanic White\nWomen\n&lt;25\nFormer\nNo\n\n\nNo\n111.33333\n42\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n122.00000\n63\nOther\nWomen\n35+\nNever\nNo\n\n\nNo\n128.16667\n74\nNon-Hispanic Black\nWomen\n&lt;25\nCurrent\nYes\n\n\nNo\n108.00000\n25\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n116.66667\n36\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nNo\n122.66667\n20\nNon-Hispanic Black\nWomen\n35+\nNever\nNo\n\n\nNo\n100.00000\n25\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n128.66667\n44\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n152.00000\n80\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n158.66667\n62\nHispanic\nWomen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n131.33333\n58\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n108.66667\n35\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n106.66667\n25\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n134.66667\n30\nHispanic\nMen\n&lt;25\nNever\nNo\n\n\nNo\n120.00000\n45\nHispanic\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n105.33333\n27\nNon-Hispanic White\nWomen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n113.33333\n44\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n111.16667\n45\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n102.50000\n20\nOther\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n121.33333\n45\nNon-Hispanic White\nMen\n35+\nNever\nYes\n\n\nNo\n156.00000\n77\nNon-Hispanic White\nWomen\n35+\nFormer\nYes\n\n\nNo\n125.33333\n29\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nNo\n114.66667\n20\nOther\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n137.33333\n78\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n120.00000\n23\nNon-Hispanic White\nMen\n35+\nCurrent\nNo\n\n\nNo\n111.33333\n28\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n126.00000\n34\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n125.33333\n54\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n128.66667\n23\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n121.83333\n22\nNon-Hispanic Black\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n106.83333\n28\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n106.00000\n42\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n149.83333\n64\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n127.33333\n23\nHispanic\nMen\n&lt;25\nNever\nNo\n\n\nNo\n110.66667\n52\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n107.33333\n38\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n98.66667\n35\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n118.00000\n55\nHispanic\nWomen\n35+\nNever\nYes\n\n\nNo\n120.00000\n24\nNon-Hispanic Asian\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n118.66667\n60\nNon-Hispanic White\nMen\n35+\nFormer\nNo\n\n\nNo\n142.00000\n60\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n123.33333\n54\nNon-Hispanic White\nWomen\n&lt;25\nFormer\nNo\n\n\nNo\n128.00000\n56\nNon-Hispanic Black\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n124.66667\n80\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n112.00000\n45\nNon-Hispanic Asian\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n123.33333\n25\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n124.00000\n53\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n100.66667\n40\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n107.50000\n43\nNon-Hispanic Black\nWomen\n35+\nNever\nNo\n\n\nNo\n118.00000\n41\nNon-Hispanic White\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n121.33333\n36\nNon-Hispanic White\nWomen\n35+\nNever\nYes\n\n\nNo\n94.00000\n55\nNon-Hispanic White\nWomen\n&lt;25\nFormer\nNo\n\n\nNo\n113.33333\n42\nHispanic\nMen\n&lt;25\nNever\nNo\n\n\nNo\n92.66667\n25\nNon-Hispanic White\nMen\n&lt;25\nNever\nNo\n\n\nNo\n116.00000\n38\nHispanic\nMen\n35+\nFormer\nNo\n\n\nNo\n114.66667\n39\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n125.33333\n51\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n112.00000\n53\nHispanic\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n95.83333\n24\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n106.00000\n37\nOther\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n150.00000\n64\nHispanic\nMen\n&lt;25\nNever\nYes\n\n\nNo\n102.66667\n43\nNon-Hispanic White\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n105.33333\n46\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n130.00000\n41\nNon-Hispanic White\nMen\n35+\nFormer\nYes\n\n\nNo\n106.00000\n35\nOther\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n116.66667\n32\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n130.00000\n46\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n113.33333\n18\nHispanic\nMen\n35+\nNever\nNo\n\n\nNo\n122.00000\n26\nNon-Hispanic White\nWomen\n35+\nNever\nNo\n\n\nNo\n116.66667\n55\nNon-Hispanic Black\nMen\n35+\nCurrent\nYes\n\n\nNo\n116.83333\n80\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n134.16667\n40\nNon-Hispanic White\nMen\n35+\nNever\nNo\n\n\nNo\n132.66667\n58\nHispanic\nWomen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n137.50000\n51\nNon-Hispanic Black\nWomen\n35+\nNever\nYes\n\n\nNo\n108.50000\n68\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n144.66667\n60\nOther\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n120.66667\n31\nNon-Hispanic White\nWomen\n35+\nNever\nNo\n\n\nNo\n180.00000\n80\nNon-Hispanic White\nMen\n&lt;25\nNever\nYes\n\n\nNo\n116.66667\n61\nHispanic\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n116.00000\n73\nNon-Hispanic Asian\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n112.66667\n70\nHispanic\nMen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n128.66667\n23\nNon-Hispanic White\nWomen\n35+\nCurrent\nNo\n\n\nNo\n158.00000\n80\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n118.66667\n24\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n113.33333\n33\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n98.66667\n26\nNon-Hispanic Asian\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n157.33333\n63\nNon-Hispanic Black\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n126.50000\n54\nHispanic\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n128.66667\n80\nNon-Hispanic White\nWomen\n35+\nFormer\nYes\n\n\nNo\n106.50000\n19\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n110.00000\n25\nHispanic\nMen\n&lt;25\nNever\nNo\n\n\nNo\n104.66667\n44\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n156.66667\n66\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n149.33333\n63\nHispanic\nMen\n25 to &lt;30\nNever\nYes\n\n\nNo\n138.66667\n57\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n118.66667\n47\nNon-Hispanic White\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n134.00000\n55\nNon-Hispanic White\nMen\n30 to &lt;35\nCurrent\nYes\n\n\nNo\n115.50000\n31\nNon-Hispanic Black\nMen\n35+\nCurrent\nNo\n\n\nNo\n108.00000\n22\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n102.66667\n19\nOther\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n123.33333\n30\nNon-Hispanic Black\nWomen\n35+\nNever\nNo\n\n\nNo\n128.66667\n80\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n131.83333\n66\nNon-Hispanic Black\nMen\n35+\nNever\nYes\n\n\nNo\n188.66667\n80\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n122.00000\n36\nNon-Hispanic White\nWomen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n132.00000\n62\nNon-Hispanic White\nWomen\n25 to &lt;30\nCurrent\nYes\n\n\nNo\n108.16667\n23\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n147.33333\n61\nHispanic\nMen\n30 to &lt;35\nNever\nNo\n\n\nNo\n124.00000\n55\nNon-Hispanic White\nMen\n35+\nNever\nYes\n\n\nNo\n110.00000\n58\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n115.33333\n30\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n117.33333\n35\nNon-Hispanic Black\nWomen\n35+\nCurrent\nNo\n\n\nNo\n126.66667\n53\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n133.00000\n22\nNon-Hispanic Black\nMen\n35+\nNever\nNo\n\n\nNo\n174.00000\n80\nNon-Hispanic White\nWomen\n&lt;25\nNever\nYes\n\n\nNo\n140.00000\n66\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n107.33333\n20\nNon-Hispanic White\nWomen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n125.33333\n64\nNon-Hispanic White\nMen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n155.50000\n63\nNon-Hispanic Asian\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n118.00000\n64\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n125.00000\n21\nHispanic\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n124.66667\n80\nHispanic\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n129.33333\n50\nHispanic\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n98.66667\n45\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n94.66667\n23\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n114.00000\n44\nHispanic\nWomen\n35+\nNever\nNo\n\n\nNo\n127.33333\n44\nHispanic\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n125.16667\n79\nNon-Hispanic Asian\nMen\n&lt;25\nNever\nNo\n\n\nNo\n119.33333\n60\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n98.00000\n43\nNon-Hispanic Black\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n138.00000\n49\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nNo\n\n\nNo\n126.66667\n63\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n118.66667\n36\nNon-Hispanic Asian\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n111.33333\n30\nHispanic\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n110.66667\n39\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n104.83333\n26\nNon-Hispanic Asian\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n149.33333\n61\nHispanic\nMen\n30 to &lt;35\nCurrent\nYes\n\n\nNo\n143.00000\n73\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n130.66667\n45\nNon-Hispanic White\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n103.83333\n62\nHispanic\nWomen\n35+\nNever\nYes\n\n\nNo\n127.50000\n42\nNon-Hispanic White\nMen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n104.16667\n30\nNon-Hispanic Black\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n110.66667\n23\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n115.50000\n43\nOther\nWomen\n30 to &lt;35\nFormer\nNo\n\n\nNo\n134.00000\n68\nHispanic\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n136.00000\n79\nNon-Hispanic Black\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n145.83333\n69\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n109.33333\n24\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n135.33333\n35\nNon-Hispanic White\nWomen\n35+\nFormer\nNo\n\n\nNo\n126.00000\n43\nHispanic\nWomen\n35+\nCurrent\nNo\n\n\nNo\n115.33333\n51\nNon-Hispanic Black\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n116.00000\n25\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n123.33333\n23\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nNo\n\n\nNo\n88.00000\n28\nNon-Hispanic Black\nWomen\n35+\nNever\nNo\n\n\nNo\n136.00000\n52\nNon-Hispanic White\nWomen\n30 to &lt;35\nNever\nYes\n\n\nNo\n118.66667\n31\nNon-Hispanic Black\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n130.83333\n74\nNon-Hispanic White\nWomen\n25 to &lt;30\nFormer\nYes\n\n\nNo\n114.66667\n20\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n141.33333\n41\nNon-Hispanic White\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n125.33333\n44\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n118.00000\n19\nHispanic\nMen\n35+\nNever\nNo\n\n\nNo\n181.33333\n61\nNon-Hispanic Black\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n130.16667\n31\nNon-Hispanic White\nMen\n25 to &lt;30\nNever\nNo\n\n\nNo\n114.00000\n46\nNon-Hispanic White\nMen\n25 to &lt;30\nCurrent\nNo\n\n\nNo\n137.00000\n60\nHispanic\nWomen\n&lt;25\nNever\nNo\n\n\nNo\n160.00000\n63\nHispanic\nWomen\n35+\nNever\nYes\n\n\nNo\n120.00000\n66\nNon-Hispanic White\nWomen\n&lt;25\nFormer\nYes\n\n\nNo\n123.33333\n40\nHispanic\nMen\n&lt;25\nFormer\nNo\n\n\nNo\n126.66667\n59\nNon-Hispanic Asian\nMen\n&lt;25\nCurrent\nNo\n\n\nNo\n104.00000\n33\nNon-Hispanic Asian\nWomen\n25 to &lt;30\nNever\nNo\n\n\nNo\n105.33333\n27\nNon-Hispanic Black\nWomen\n&lt;25\nNever\nNo\n\n\n\n\n\nsimple_diab_model_subset &lt;- glm(cc_diabetes ~ bp_sys_mean , data = clean_subset, family = binomial)\n\nsummary(simple_diab_model_subset)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean, family = binomial, data = clean_subset)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.777250   0.787205  -7.339 2.15e-13 ***\nbp_sys_mean  0.030330   0.005911   5.131 2.89e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 437.53  on 598  degrees of freedom\nAIC: 441.53\n\nNumber of Fisher Scoring iterations: 5\n\nknitr::kable(tidy(simple_diab_model_subset, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.003\n0.787\n-7.339\n0\n0.001\n0.014\n\n\nbp_sys_mean\n1.031\n0.006\n5.131\n0\n1.019\n1.043\n\n\n\n\n#simple_diab_model_dia &lt;- glm(cc_diabetes ~ bp_dia_mean, data = clean_nhanes, family = binomial)\n\n#summary(simple_diab_model_dia)\n#knitr::kable(tidy(simple_diab_model_dia, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n4.1.0.1 Model Explanation:\nFor the logistic regression using systolic blood pressure, we can see that the odds ratio beta parameter is 1.024. This implies that a higher systolic blood pressure corresponds to increased chances of observing diabetes.\nA more exact interpretation would be that: for one additional unit increase in systolic blood pressure, the estimated risk of having diabetes increases by 2.4%.\nThis value may not seem extremely high, yet it still has a p value evaluated to be 0 by R. We can also see that the 95% confidence interval of this parameter ranges between 1.022 and 1.024, meaning that the model predicts that the true relationship falls within this interval with a 95% certainty, since the true value of the parameter is most likely within this interval.\nThe opposite is true with diastolic blood pressure: the beta parameter is 0.996, implying that higher diastolic blood pressure corresponds to a lower chance of observing diabetes. For an additional unit increase in diastolic blood pressure, the estimated risk of having diabetes decreases by 0.04%.\nNote: systolic blood pressure is a better predictor of cardiovascular disease, so I chose to consider systolic rather than diastolic in future models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#demographic-model-1",
    "href": "initial_modeling.html#demographic-model-1",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "4.2 Demographic Model",
    "text": "4.2 Demographic Model\nNext, we build a model including the demographic variables as well. This will hopefully provide a more accurate model, since it will have access to the further information in order to make predictions.\n\ndemo_diab_model_subset &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender,data = clean_subset, family = binomial)\n\nsummary (demo_diab_model_subset)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender, family = binomial, data = clean_subset)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -6.542316   0.898829  -7.279 3.37e-13 ***\nbp_sys_mean                  0.014810   0.006876   2.154  0.03124 *  \ndemo_age_years               0.042030   0.009080   4.629 3.67e-06 ***\ndemo_raceNon-Hispanic Black  1.060715   0.345794   3.067  0.00216 ** \ndemo_raceNon-Hispanic Asian  0.333315   0.675457   0.493  0.62168    \ndemo_raceHispanic            1.216336   0.329225   3.695  0.00022 ***\ndemo_raceOther               0.267046   0.803168   0.332  0.73952    \ndemo_genderWomen            -0.383040   0.262182  -1.461  0.14402    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 396.40  on 592  degrees of freedom\nAIC: 412.4\n\nNumber of Fisher Scoring iterations: 5\n\nknitr::kable(tidy(demo_diab_model_subset, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.001\n0.899\n-7.279\n0.000\n0.000\n0.008\n\n\nbp_sys_mean\n1.015\n0.007\n2.154\n0.031\n1.001\n1.029\n\n\ndemo_age_years\n1.043\n0.009\n4.629\n0.000\n1.025\n1.062\n\n\ndemo_raceNon-Hispanic Black\n2.888\n0.346\n3.067\n0.002\n1.470\n5.741\n\n\ndemo_raceNon-Hispanic Asian\n1.396\n0.675\n0.493\n0.622\n0.304\n4.681\n\n\ndemo_raceHispanic\n3.375\n0.329\n3.695\n0.000\n1.785\n6.527\n\n\ndemo_raceOther\n1.306\n0.803\n0.332\n0.740\n0.193\n5.255\n\n\ndemo_genderWomen\n0.682\n0.262\n-1.461\n0.144\n0.406\n1.138\n\n\n\n\n\n\n4.2.0.1 Model Explanation\nIn this model, we can still see a slight upwards trend with systolic blood pressure, although it is a bit weaker (1.024 &gt; 1.003). With this parameter, the estimated risk of having diabetes increases only by 0.3%. Although the effect is smaller, we can see that the confidence interval is between 1.003 and 1.005, which does not include 1. So, although small, the positive relationship is most likely significant.\n\n\n4.2.0.2 Demographics\nAge:\nThe model also tells us that age is positively correlated with the observation of diabetes. With a log odds ratio of 1.054, it seems that every year increases the risk of diabetes occurrence by 5.4%.\nRace:\nThe log odds ratio for categorical variables compares the other variables to the baseline “reference group”. Here, the “reference group” for the race variable is Non-Hispanic White. We can see that, in comparison to this group, all other races have significantly higher risk of diabetes: for example, the Hispanic population’s risk of diabetes occurrence is 2.36 times higher than the Non-Hispanic White population.\nGender:\nWith this variable, the reference group is men. We can see that women have a lower odds of having diabetes compared to men. Specifically, the risk of diabetes in women is about 85.6% of that of men.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#full-model-1",
    "href": "initial_modeling.html#full-model-1",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "4.3 Full Model",
    "text": "4.3 Full Model\nLastly, we want to create a model including confounding variables. To achieve this, we must first determine which other variables are confounding, meaning they have significant associations with diabetes.\nWe can achieve this by using chi squared test, which compares whether or not the observed ratios of diabetes and confounding variables matches the ratios expected by random chance. If the chi squared test determines significance, then diabetes and the other variables commonly occur together and therefore are confounding.\n\n4.3.0.1 Perform Chi Squared Tests:\n\n#Testing for BMI\nnhanes_bmi_diab_subset &lt;- clean_subset %&gt;% select(cc_diabetes, cc_bmi) %&gt;% drop_na(cc_bmi) %&gt;% drop_na(cc_diabetes)\nnhanes_bmi_diab_subset &lt;- table(nhanes_bmi_diab_subset)\n#nhanes_bmi_diab\nchisq.test(nhanes_bmi_diab_subset)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_diab_subset\nX-squared = 17.898, df = 3, p-value = 0.0004616\n\n#Testing for Smoking\nnhanes_smoke_diab_subset &lt;- clean_subset %&gt;% select(cc_diabetes, cc_smoke) %&gt;% drop_na(cc_smoke) %&gt;% drop_na(cc_diabetes)\nnhanes_smoke_diab_subset &lt;- table(nhanes_smoke_diab_subset)\n#nhanes_smoke_diab\nchisq.test(nhanes_smoke_diab_subset)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_diab_subset\nX-squared = 6.2815, df = 2, p-value = 0.04325\n\n#Testing for Hypertensive Medication use\nnhanes_med_diab_subset &lt;- clean_subset %&gt;% select(cc_diabetes, bp_med_use) %&gt;% drop_na(bp_med_use) %&gt;% drop_na(cc_diabetes)\nnhanes_med_diab_subset &lt;- table(nhanes_med_diab_subset)\n#nhanes_med_diab\nchisq.test(nhanes_med_diab_subset)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_med_diab_subset\nX-squared = 42.751, df = 1, p-value = 6.217e-11\n\n\nAfter this analysis, we can see that all three variables, BMI, Smoking, and Medication Use, are all confounding. We can include all of them in the next model, in addition to systolic blood pressure and the demographic variables:\n\nfull_diab_model_subset &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender+ cc_bmi + cc_smoke + bp_med_use, data = clean_subset, family = binomial)\n\nsummary(full_diab_model_subset)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender + cc_bmi + cc_smoke + bp_med_use, family = binomial, \n    data = clean_subset)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -8.374715   1.157486  -7.235 4.65e-13 ***\nbp_sys_mean                  0.017214   0.007388   2.330 0.019811 *  \ndemo_age_years               0.042340   0.010993   3.851 0.000117 ***\ndemo_raceNon-Hispanic Black  0.882174   0.365983   2.410 0.015934 *  \ndemo_raceNon-Hispanic Asian  1.236127   0.725126   1.705 0.088249 .  \ndemo_raceHispanic            1.348695   0.346960   3.887 0.000101 ***\ndemo_raceOther               0.877061   0.821270   1.068 0.285551    \ndemo_genderWomen            -0.514349   0.288090  -1.785 0.074200 .  \ncc_bmi25 to &lt;30              0.706520   0.420936   1.678 0.093260 .  \ncc_bmi30 to &lt;35              1.285068   0.447034   2.875 0.004045 ** \ncc_bmi35+                    1.994383   0.466486   4.275 1.91e-05 ***\ncc_smokeFormer               0.435102   0.326010   1.335 0.181998    \ncc_smokeCurrent              0.522143   0.365577   1.428 0.153213    \nbp_med_useYes                0.661943   0.308302   2.147 0.031788 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 360.71  on 586  degrees of freedom\nAIC: 388.71\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(full_diab_model_subset, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.000\n1.157\n-7.235\n0.000\n0.000\n0.002\n\n\nbp_sys_mean\n1.017\n0.007\n2.330\n0.020\n1.003\n1.032\n\n\ndemo_age_years\n1.043\n0.011\n3.851\n0.000\n1.021\n1.067\n\n\ndemo_raceNon-Hispanic Black\n2.416\n0.366\n2.410\n0.016\n1.181\n4.993\n\n\ndemo_raceNon-Hispanic Asian\n3.442\n0.725\n1.705\n0.088\n0.697\n12.982\n\n\ndemo_raceHispanic\n3.852\n0.347\n3.887\n0.000\n1.971\n7.724\n\n\ndemo_raceOther\n2.404\n0.821\n1.068\n0.286\n0.348\n10.201\n\n\ndemo_genderWomen\n0.598\n0.288\n-1.785\n0.074\n0.338\n1.048\n\n\ncc_bmi25 to &lt;30\n2.027\n0.421\n1.678\n0.093\n0.905\n4.771\n\n\ncc_bmi30 to &lt;35\n3.615\n0.447\n2.875\n0.004\n1.534\n8.959\n\n\ncc_bmi35+\n7.348\n0.466\n4.275\n0.000\n3.031\n19.065\n\n\ncc_smokeFormer\n1.545\n0.326\n1.335\n0.182\n0.810\n2.921\n\n\ncc_smokeCurrent\n1.686\n0.366\n1.428\n0.153\n0.812\n3.427\n\n\nbp_med_useYes\n1.939\n0.308\n2.147\n0.032\n1.062\n3.566\n\n\n\n\n\n\n\n4.3.0.2 Model Explanation\nThe previous variables in this model continue to show the same patterns, although again, the effect of systolic blood pressure is again reduced due to a lower log odds ratio. Now, the p value seems to be much higher at 0.02 (which is still significant, but much less so). The demographic variables also have much the same pattern, although Non-Hispanic Asians seem to have a much higher odds ratio than in the previous model.\n\n\n4.3.0.3 Covariates\nBMI:\nIn this variable, the baseline reference level is bmi &lt;25. In comparison, those with higher bmi have increased risk of having diabetes, with the risk increasing the higher the bmi becomes. For example, those with bmi from 25-30 have a 1.8 times higher risk, while those with a bmi of 35+ have a 5.8 times higher risk.\nSmoking:\nWith a baseline level of nonsmoking, former smokers may have about a 6% higher risk of diabetes. This may not be significant, however, given that the p value is only 0.067 and the odds ratio of 1 falls within the confidence interval. Current smokers, on the other hand, have about a 20% higher risk, this time with a much lower p value of 4*10^-6\nBlood Pressure Medication Use:\nCompared to those who do not use blood pressure medication, individuals who do have about a 2.5 times higher risk of experiencing diabetes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#model-selection-1",
    "href": "initial_modeling.html#model-selection-1",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "4.4 Model Selection",
    "text": "4.4 Model Selection\nIt is possible to find an even better model by modifying which variables we include in our logistic regression model. We can achieve this using model selection, which will selectively add or subtract our explanatory variables from the model and evaluate its performance to choose the final best set of variables.\nExplanation of model selection and or AIC?\n\n4.4.0.1 Backwards Selection:\n\nbackwards = step(full_diab_model_subset)\n\nStart:  AIC=388.71\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n                 Df Deviance    AIC\n- cc_smoke        2   363.63 387.63\n&lt;none&gt;                360.71 388.71\n- demo_gender     1   363.93 389.93\n- bp_med_use      1   365.35 391.35\n- bp_sys_mean     1   366.10 392.10\n- demo_race       4   377.67 397.67\n- demo_age_years  1   376.47 402.47\n- cc_bmi          3   383.05 405.05\n\nStep:  AIC=387.63\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + bp_med_use\n\n                 Df Deviance    AIC\n&lt;none&gt;                363.63 387.63\n- demo_gender     1   368.53 390.53\n- bp_med_use      1   368.62 390.62\n- bp_sys_mean     1   368.96 390.96\n- demo_race       4   379.88 395.88\n- demo_age_years  1   380.29 402.29\n- cc_bmi          3   385.97 403.97\n\nformula(backwards)\n\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + bp_med_use\n\n\nIt looks like the backwards selection model returned the same full model. In other words, removing variables does not improve its AIC, and therefore does not improve its performance.\n\n\n4.4.0.2 Forward Selection\n\n#start from a model without any predictors\nnothing &lt;- glm(cc_diabetes ~ 1, data = subset_nhanes, family=binomial)\nsummary(nothing)\n\n\nCall:\nglm(formula = cc_diabetes ~ 1, family = binomial, data = subset_nhanes)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.9010     0.1214  -15.66   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 463.66  on 599  degrees of freedom\nAIC: 465.66\n\nNumber of Fisher Scoring iterations: 4\n\nforwards = step(nothing,\nscope=list(lower=formula(nothing),upper=formula(full_diab_model_subset)), direction=\"forward\")\n\nStart:  AIC=465.66\ncc_diabetes ~ 1\n\n                 Df Deviance    AIC\n+ demo_age_years  1   421.07 425.07\n+ bp_med_use      1   423.90 427.90\n+ bp_sys_mean     1   437.53 441.53\n+ cc_bmi          3   445.01 453.01\n+ demo_race       4   447.81 457.81\n+ cc_smoke        2   457.72 463.72\n+ demo_gender     1   460.78 464.78\n&lt;none&gt;                463.66 465.66\n\nStep:  AIC=425.07\ncc_diabetes ~ demo_age_years\n\n              Df Deviance    AIC\n+ cc_bmi       3   396.85 406.85\n+ bp_med_use   1   407.64 413.64\n+ demo_race    4   402.84 414.84\n+ bp_sys_mean  1   416.24 422.24\n&lt;none&gt;             421.07 425.07\n+ demo_gender  1   419.20 425.20\n+ cc_smoke     2   418.19 426.19\n\nStep:  AIC=406.85\ncc_diabetes ~ demo_age_years + cc_bmi\n\n              Df Deviance    AIC\n+ demo_race    4   378.39 396.39\n+ bp_med_use   1   390.28 402.28\n+ bp_sys_mean  1   390.48 402.48\n+ demo_gender  1   393.36 405.36\n&lt;none&gt;             396.85 406.85\n+ cc_smoke     2   393.19 407.19\n\nStep:  AIC=396.39\ncc_diabetes ~ demo_age_years + cc_bmi + demo_race\n\n              Df Deviance    AIC\n+ bp_sys_mean  1   372.48 392.48\n+ bp_med_use   1   373.46 393.46\n+ demo_gender  1   375.00 395.00\n+ cc_smoke     2   373.62 395.62\n&lt;none&gt;             378.39 396.39\n\nStep:  AIC=392.48\ncc_diabetes ~ demo_age_years + cc_bmi + demo_race + bp_sys_mean\n\n              Df Deviance    AIC\n+ bp_med_use   1   368.53 390.53\n+ demo_gender  1   368.62 390.62\n+ cc_smoke     2   367.76 391.76\n&lt;none&gt;             372.48 392.48\n\nStep:  AIC=390.53\ncc_diabetes ~ demo_age_years + cc_bmi + demo_race + bp_sys_mean + \n    bp_med_use\n\n              Df Deviance    AIC\n+ demo_gender  1   363.63 387.63\n+ cc_smoke     2   363.93 389.93\n&lt;none&gt;             368.53 390.53\n\nStep:  AIC=387.63\ncc_diabetes ~ demo_age_years + cc_bmi + demo_race + bp_sys_mean + \n    bp_med_use + demo_gender\n\n           Df Deviance    AIC\n&lt;none&gt;          363.63 387.63\n+ cc_smoke  2   360.71 388.71\n\n\nThe Forward Selection process again selects the full model.\n\n\n4.4.1 Forward-Backward Selection\n\nbothways = step(nothing, list(lower=formula(nothing),upper=formula(full_diab_model_subset)),\ndirection=\"both\",trace=0)\nformula(bothways)\n\ncc_diabetes ~ demo_age_years + cc_bmi + demo_race + bp_sys_mean + \n    bp_med_use + demo_gender\n\n\nThe Forward-Backward algorithm also selects all of the variables.\nIn this case, the best model (as determined by the AIC) includes all of the variables (systolic blood pressure, age, race, sex, smoking status, BMI, and medication use). In other situations, it may have returned just a few of these variables, but for this example, we can proceed with the full model.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#section",
    "href": "initial_modeling.html#section",
    "title": "3  Modeling Diabetes Occurrence",
    "section": "4.5 ",
    "text": "4.5",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modeling Diabetes Occurrence</span>"
    ]
  },
  {
    "objectID": "diagnostics.html",
    "href": "diagnostics.html",
    "title": "4  Model Diagnostics",
    "section": "",
    "text": "4.1 Likelihood Ratio Test\nThe likelihood ratio test involves comparing whether two models are significantly different. Here, we will compare our full model with the null model (no covariates):\nThe null hypothesis is that there is no significant difference between the null model \\(H_0\\) and the full model \\(H_1\\).\nThe test compares the predicted likelihood of an observed outcome under the null model vs the predicted likelihood of the outcome under the model. In this case, the outcome will be diabetes. The test statistic will be calculated \\(\\lambda = -2 log(\\frac{L(H_0)}{L(H_1)})\\), where L denotes the likelihood of diabetes evaluated under each model. If the likelihood is much higher in the full model than in the null model, it means that additional parameters improve the model fit. As a result, \\(\\lambda\\) and its corresponding p value will be a much smaller, providing stronger evidence that we may need to reject the null hypothesis.\nlrtest(full_diab_model_sys, null_model)\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n14\n-16527.27\nNA\nNA\nNA\n\n\n1\n-20638.95\n-13\n8223.36\n0\nAs expected, we can see that the full model is significant compared to the null hypothesis. We can also compare it to the simple model which uses only systolic blood pressure as a variable.\nlrtest(full_diab_model_sys, simple_diab_model_sys)\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n14\n-16527.27\nNA\nNA\nNA\n\n\n2\n-19943.85\n-12\n6833.152\n0",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "diagnostics.html#model-fit",
    "href": "diagnostics.html#model-fit",
    "title": "4  Model Diagnostics",
    "section": "4.2 Model Fit",
    "text": "4.2 Model Fit\nLet’s evaluate the accuracy of our model: We first calculate the predicted probabilities using a cutoff probability of 0.5 with our model. Then, we compare these predictions to the references and find our accuracy.\n\npred_probs &lt;- predict(full_diab_model_sys, type=\"response\")\npred_ys &lt;- ifelse(pred_probs &gt;0.5, 1, 0)\nclean_nhanes$cc_diabetes_num &lt;- ifelse(clean_nhanes$cc_diabetes == \"Yes\", 1, 0)\ntable(clean_nhanes$cc_diabetes_num, pred_ys)\n\n   pred_ys\n        0     1\n  0 44302   859\n  1  6167   869\n\nconfusionMatrix(as.factor(pred_ys),as.factor(clean_nhanes$cc_diabetes_num), positive = '1')\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1\n         0 44302  6167\n         1   859   869\n                                          \n               Accuracy : 0.8654          \n                 95% CI : (0.8624, 0.8683)\n    No Information Rate : 0.8652          \n    P-Value [Acc &gt; NIR] : 0.4522          \n                                          \n                  Kappa : 0.1533          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.12351         \n            Specificity : 0.98098         \n         Pos Pred Value : 0.50289         \n         Neg Pred Value : 0.87781         \n             Prevalence : 0.13480         \n         Detection Rate : 0.01665         \n   Detection Prevalence : 0.03311         \n      Balanced Accuracy : 0.55224         \n                                          \n       'Positive' Class : 1               \n                                          \n\n\n\npred_probs_simple &lt;- predict(simple_diab_model_sys, type=\"response\")\npred_ys &lt;- ifelse(pred_probs &gt;0.5, 1, 0)\nclean_nhanes$cc_diabetes_num &lt;- ifelse(clean_nhanes$cc_diabetes == \"Yes\", 1, 0)\ntable(clean_nhanes$cc_diabetes_num, pred_ys)\n\n   pred_ys\n        0     1\n  0 44302   859\n  1  6167   869\n\nconfusionMatrix(as.factor(pred_ys),as.factor(clean_nhanes$cc_diabetes_num), positive = '1')\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1\n         0 44302  6167\n         1   859   869\n                                          \n               Accuracy : 0.8654          \n                 95% CI : (0.8624, 0.8683)\n    No Information Rate : 0.8652          \n    P-Value [Acc &gt; NIR] : 0.4522          \n                                          \n                  Kappa : 0.1533          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.12351         \n            Specificity : 0.98098         \n         Pos Pred Value : 0.50289         \n         Neg Pred Value : 0.87781         \n             Prevalence : 0.13480         \n         Detection Rate : 0.01665         \n   Detection Prevalence : 0.03311         \n      Balanced Accuracy : 0.55224         \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nOur model has a final accuracy of about 86%, and mostly misclassifies those with diabetes as without (false negatives).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "diagnostics.html#calibration-plot",
    "href": "diagnostics.html#calibration-plot",
    "title": "4  Model Diagnostics",
    "section": "4.3 Calibration Plot",
    "text": "4.3 Calibration Plot\nThe calibration plot compares predicted probabilities to observed probabilities. Essentially, it will compare the data points for which the model predicted probabilities in a certain range and the true observed proportion of these data points which were predicted positives. Ideally, a model will fit close to the line x=y: this would imply that the model’s predictions align with the actual outcome. For example, if our model assigns 100 data points a predicted probability value between 0 and 0.1, and 10 of those points is a positive, then our model fits the data quite well.\n\nclean_nhanes$pred &lt;- pred_probs\ncalibration_plot(data = clean_nhanes, obs = \"cc_diabetes_num\", pred = \"pred\")\n\n$calibration_plot\n\n\n\n\n\n\n\n\nclean_nhanes$pred_simple &lt;- pred_probs_simple\ncalibration_plot(data = clean_nhanes, obs = \"cc_diabetes_num\", pred = \"pred_simple\")\n\n$calibration_plot\n\n\n\n\n\n\n\n\n\nBrier Test\nThe Brier Score is a value which measures the accuracy of the model to the data. In this case, it is equal to mean-squared error.\n\nmean((clean_nhanes$cc_diabetes_num - pred_probs)^2)\n\n[1] 0.09791126\n\nmean((clean_nhanes$cc_diabetes_num - pred_probs_simple)^2)\n\n[1] 0.1137431",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "diagnostics.html#hosmer-lemeshow-test",
    "href": "diagnostics.html#hosmer-lemeshow-test",
    "title": "4  Model Diagnostics",
    "section": "4.4 Hosmer-Lemeshow Test",
    "text": "4.4 Hosmer-Lemeshow Test\nThe Homser-Lemeshow test divides the data into 10 different subgroups of equal size, each with increasing risk for positive prediction, or diabetes in our case. The observed number of those with diabetes in the each group is compared with the expected number based on the model’s prediction.\n\nhltest(full_diab_model_sys)\n\n\n   The Hosmer-Lemeshow goodness-of-fit test\n\n Group Size Observed   Expected\n     1 5220       29   47.93194\n     2 5220       44   96.09769\n     3 5220       99  156.96748\n     4 5220      183  236.32193\n     5 5220      347  341.67554\n     6 5220      529  485.18466\n     7 5220      848  696.01150\n     8 5220     1112 1009.00717\n     9 5220     1554 1507.32695\n    10 5217     2291 2459.47515\n\n         Statistic =  150.6378 \ndegrees of freedom =  8 \n           p-value =  &lt; 2.22e-16 \n\nhltest(simple_diab_model_sys)\n\n\n   The Hosmer-Lemeshow goodness-of-fit test\n\n Group Size Observed    Expected\n     1 5310      320  392.900614\n     2 5205      336  455.497648\n     3 4905      382  472.429670\n     4 5211      470  544.366735\n     5 5159      547  583.643016\n     6 5283      707  652.225758\n     7 5229      818  710.886418\n     8 5410     1057  830.456544\n     9 5260     1129  962.117074\n    10 5220     1269 1427.789578\n    11    5        1    3.686982\n\n         Statistic =  246.1812 \ndegrees of freedom =  9 \n           p-value =  &lt; 2.22e-16 \n\n\nIn our model, we can see that the expected values are somewhat higher than the observed values in the lower proportion groups, however the fit seems to generally be accurate.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "diagnostics.html#roc-curve",
    "href": "diagnostics.html#roc-curve",
    "title": "4  Model Diagnostics",
    "section": "4.5 ROC Curve",
    "text": "4.5 ROC Curve\nThe Receiver Operating Curve shows the performance of a model by plotting sensitivity vs specificity at different threshold values.\nSensitivity (AKA True Positive Rate) measures the proportion of true positives (samples correctly predicted as diabetes positive) to all the observed positives in the data. This can be written as \\[\\text{Sensitivity} = \\frac{\\text{True Positives}}{\\text{True Positives + False Negatives}}\\]\nSpecificity (AKA True Negative Rate) measures the proportion of true negatives (samples correctly predicted as diabetes negative) to all the observed negatives in the data. This can be written as \\[\\text{Specificity} = \\frac{\\text{True Negativites}}{\\text{True Negativites + False Positives}}\\]\nAs a model’s sensitivity increases, specificity will tend to decrease.\nAt different threshold values (for example, we typically use 0.5 for prediction, but could use any value from 0 to 1), we can calculate both sensitivity and specificity and plot these values on a curve.\nThe baseline curve used for comparison is just the line y=x. This is essentially modeling random prediction. The closer the curve is to the left and top edge, the better its performance, since it shows a high sensitivity without a huge drop off in specificity.\nThe AUC, or area under the curve, provides a single number to quantify this curve. The higher the performance of a model, the closer the ROC to the top left and the bigger the area under the curve. The ideal AUC, with both measurements always at 1 due to perfect predictions, would be 1. In practice, AUCs are typically in the range of 80-90.\n\nroc_mod &lt;- roc(predictor=pred_probs, response=clean_nhanes$cc_diabetes_num)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nplot(roc_mod, print.auc = TRUE)\n\n\n\n\n\n\n\nroc_mod &lt;- roc(predictor=pred_probs_simple, response=clean_nhanes$cc_diabetes_num)\n\nSetting levels: control = 0, case = 1\nSetting direction: controls &lt; cases\n\nplot(roc_mod, print.auc = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "diagnostics.html#residuals-histogram",
    "href": "diagnostics.html#residuals-histogram",
    "title": "4  Model Diagnostics",
    "section": "4.6 Residuals Histogram",
    "text": "4.6 Residuals Histogram\nA histogram of residuals should resemble a standard normal distribution, ideally. The histogram will plot the frequency of each pearson residual value. In an ideal model, the error between the predictions and observations (residuals) will be a result of random noise, creating a Gaussian shape. Skewness and irregularities may be a sign that the model is not fit properly.\n\nhist(resid(full_diab_model_sys, type=\"pearson\"), breaks = 20) #specify shape\n\n\n\n\n\n\n\nlev &lt;- hatvalues(full_diab_model_sys)\ntop_10 &lt;- sort(lev, decreasing=TRUE)[1:10]\nclean_nhanes[as.numeric(names(top_10))] %&gt;% select(all_of(used_vars)) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncc_diabetes\nbp_sys_mean\ndemo_age_years\ndemo_race\ndemo_gender\ncc_bmi\ncc_smoke\nbp_med_use\n\n\n\n\nNo\n217.3333\n51\nOther\nWomen\n35+\nCurrent\nYes\n\n\nNo\n266.0000\n64\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n125.3333\n79\nOther\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n102.0000\n73\nOther\nWomen\n30 to &lt;35\nCurrent\nYes\n\n\nYes\n201.3333\n80\nOther\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n270.0000\n80\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nYes\n\n\nNo\n128.0000\n78\nOther\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nYes\n188.0000\n61\nOther\nWomen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n198.0000\n69\nOther\nMen\n&lt;25\nCurrent\nYes\n\n\nYes\n173.8333\n60\nOther\nWomen\n30 to &lt;35\nCurrent\nYes\n\n\n\n\n\n\nhist(resid(simple_diab_model_sys, type=\"pearson\"), breaks = 20) #specify shape\n\n\n\n\n\n\n\nlev &lt;- hatvalues(full_diab_model_sys)\ntop_10 &lt;- sort(lev, decreasing=TRUE)[1:10]\nclean_nhanes[as.numeric(names(top_10))] %&gt;% select(all_of(used_vars)) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncc_diabetes\nbp_sys_mean\ndemo_age_years\ndemo_race\ndemo_gender\ncc_bmi\ncc_smoke\nbp_med_use\n\n\n\n\nNo\n217.3333\n51\nOther\nWomen\n35+\nCurrent\nYes\n\n\nNo\n266.0000\n64\nNon-Hispanic Black\nWomen\n25 to &lt;30\nNever\nYes\n\n\nNo\n125.3333\n79\nOther\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nNo\n102.0000\n73\nOther\nWomen\n30 to &lt;35\nCurrent\nYes\n\n\nYes\n201.3333\n80\nOther\nMen\n25 to &lt;30\nFormer\nNo\n\n\nNo\n270.0000\n80\nNon-Hispanic White\nWomen\n&lt;25\nCurrent\nYes\n\n\nNo\n128.0000\n78\nOther\nMen\n30 to &lt;35\nCurrent\nNo\n\n\nYes\n188.0000\n61\nOther\nWomen\n30 to &lt;35\nFormer\nYes\n\n\nNo\n198.0000\n69\nOther\nMen\n&lt;25\nCurrent\nYes\n\n\nYes\n173.8333\n60\nOther\nWomen\n30 to &lt;35\nCurrent\nYes",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "diagnostics.html#ignore",
    "href": "diagnostics.html#ignore",
    "title": "4  Model Diagnostics",
    "section": "4.7 Ignore///",
    "text": "4.7 Ignore///\nI followed a guide online but I don’t really know what this is doing:\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"demo_age_years\"]*demo_age_years + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = demo_age_years, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"bp_sys_mean\"]*bp_sys_mean + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = bp_sys_mean, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nTest for Multicollinearity\n\nvif(full_diab_model_sys)\n\n                   GVIF Df GVIF^(1/(2*Df))\nbp_sys_mean    1.169212  1        1.081301\ndemo_age_years 1.528167  1        1.236191\ndemo_race      1.207663  4        1.023866\ndemo_gender    1.091056  1        1.044536\ncc_bmi         1.182024  3        1.028263\ncc_smoke       1.173951  2        1.040908\nbp_med_use     1.235766  1        1.111650\n\n\nOutliers\n\noutlier_nhanes &lt;-\n  clean_nhanes %&gt;% \n  mutate(dffits = dffits(full_diab_model_sys))\n\noutlier_nhanes %&gt;% \n  mutate(obs_number = row_number(),\n         large = ifelse(abs(dffits) &gt; 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)),\n                        \"red\", \"black\")) %&gt;% \n  ggplot(aes(obs_number, dffits, color = large)) +\n  geom_point() + \n  geom_hline(yintercept = c(-1,1) * 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)), color = \"red\") +\n  scale_color_identity()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "add_noise.html",
    "href": "add_noise.html",
    "title": "5  Creating “Noisy” Data",
    "section": "",
    "text": "library(dplyr)\nlibrary(tidyverse)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(hrbrthemes)\nlibrary(viridis)\n\nlibrary(devtools)\n#using data specified in this github repository:\ninstall_github(\"jhs-hwg/cardioStatsUSA\")\nlibrary(cardioStatsUSA)\n\n\n#to prevent errors, exclude the rows with na\nused_vars = c('cc_diabetes', 'bp_sys_mean', 'demo_age_years', 'demo_race', 'demo_gender', 'cc_bmi', 'cc_smoke', 'bp_med_use')\nclean_nhanes &lt;- nhanes_data[complete.cases(nhanes_data[,..used_vars]), ]\n\nIn normal usage of measurement error techniques, the data is assumed to have systematic error arising from measurement of the variables which we aim to remedy. In our case, we believe that the NHANES data has no measurement error, so we will instead simulate error by adding in random noise to the existing data to create a “noisy” dataset.\nFirst, let’s remind ourselves the relationship between blood pressure and diabetes visually:\n\nclean_nhanes %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_diabetes)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with Diabetes Histogram\")\n\n\n\n\n\n\n\nclean_nhanes %&gt;%\n  ggplot(aes(x=cc_diabetes, y=bp_sys_mean, fill=cc_diabetes)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Diabetes Status\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nWith this much data, the true true statistic (in this case, the mean blood pressure values for both groups) will be clear no matter how much noise we add. However, in normal circumstances we would not have this much data. We can instead mimic more realistic scenarios by taking a smaller subset of this data to examine. The goal will be to add noise to obscure the relationship between diabetes and blood pressure, and then use measurement error correction to rediscover the true relationship.\nLet’s start by taking a subset of n=150. Since in the total data set, about 13% of individuals had diabetes, we will keep this ratio similar here.\n\nset.seed(19)\n#original: seed 52, subset yes = 20, subset no = 130\n\nsubset_diab_yes &lt;- subset(clean_nhanes, cc_diabetes == \"Yes\") \nsubset_diab_no &lt;- subset(clean_nhanes, cc_diabetes == \"No\")\n\nsample_diab_yes &lt;- subset_diab_yes[sample(1:nrow(subset_diab_yes), 78, replace=FALSE),]\nsample_diab_no &lt;- subset_diab_no[sample(1:nrow(subset_diab_no), 522, replace=FALSE),]\n\nsubset_nhanes &lt;- rbind(sample_diab_yes, sample_diab_no)\nhead(subset_nhanes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsvy_id\nsvy_weight_mec\nsvy_psu\nsvy_strata\nsvy_year\nsvy_subpop_htn\nsvy_subpop_chol\ndemo_age_cat\ndemo_race\ndemo_race_black\ndemo_age_years\ndemo_pregnant\ndemo_gender\nbp_sys_mean\nbp_dia_mean\nbp_cat_meds_excluded\nbp_cat_meds_included\nbp_control_jnc7\nbp_control_accaha\nbp_control_escesh_1\nbp_control_escesh_2\nbp_control_140_90\nbp_control_130_80\nbp_uncontrolled_jnc7\nbp_uncontrolled_accaha\nbp_uncontrolled_escesh_1\nbp_uncontrolled_escesh_2\nbp_uncontrolled_140_90\nbp_uncontrolled_130_80\nbp_med_use\nbp_med_recommended_jnc7\nbp_med_recommended_accaha\nbp_med_recommended_escesh\nbp_med_n_class\nbp_med_n_pills\nbp_med_combination\nbp_med_pills_gteq_2\nbp_med_ace\nbp_med_aldo\nbp_med_alpha\nbp_med_angioten\nbp_med_beta\nbp_med_central\nbp_med_ccb\nbp_med_ccb_dh\nbp_med_ccb_ndh\nbp_med_diur_Ksparing\nbp_med_diur_loop\nbp_med_diur_thz\nbp_med_renin_inhibitors\nbp_med_vasod\nhtn_jnc7\nhtn_accaha\nhtn_escesh\nhtn_aware\nhtn_resistant_jnc7\nhtn_resistant_accaha\nhtn_resistant_jnc7_thz\nhtn_resistant_accaha_thz\nchol_measured_never\nchol_measured_last\nchol_total\nchol_total_gteq_200\nchol_total_gteq_240\nchol_hdl\nchol_hdl_low\nchol_trig\nchol_trig_gteq_150\nchol_ldl\nchol_ldl_5cat\nchol_ldl_lt_70\nchol_ldl_gteq_70\nchol_ldl_lt_100\nchol_ldl_gteq_100\nchol_ldl_gteq_190\nchol_ldl_persistent\nchol_nonhdl\nchol_nonhdl_5cat\nchol_nonhdl_lt_100\nchol_nonhdl_gteq_100\nchol_nonhdl_gteq_220\nchol_med_use\nchol_med_use_sr\nchol_med_statin\nchol_med_ezetimibe\nchol_med_pcsk9i\nchol_med_bile\nchol_med_fibric_acid\nchol_med_atorvastatin\nchol_med_simvastatin\nchol_med_rosuvastatin\nchol_med_pravastatin\nchol_med_pitavastatin\nchol_med_fluvastatin\nchol_med_lovastatin\nchol_med_other\nchol_med_addon_use\nchol_med_addon_recommended_ahaacc\nchol_med_statin_recommended_ahaacc\nchol_med_recommended_ever\nascvd_risk_vh_ahaacc\ncc_smoke\ncc_bmi\ncc_diabetes\ncc_ckd\ncc_acr\ncc_egfr\ncc_hba1c\ncc_egfr_lt60\ncc_acr_gteq30\ncc_cvd_mi\ncc_cvd_chd\ncc_cvd_stroke\ncc_cvd_ascvd\ncc_cvd_hf\ncc_cvd_any\n\n\n\n\n37436\n22062.121\n2\n47\n2005-2006\n1\n1\n75+\nNon-Hispanic White\nNo\n77\nNo\nMen\n134.0000\n60.66667\nSBP of 130 to &lt;140 or DBP 80 to &lt;90 mm Hg\ntaking antihypertensive medications\nNo\nNo\nYes\nYes\nYes\nNo\nYes\nYes\nNo\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nThree\nThree\nNo\nYes\nYes\nNo\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nNo\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nYes\nNo\nNo\nCholesterol has been measured previously\nIn the past year\n136\nNo\nNo\n23\nYes\n154\nYes\n84.21057\n70 to &lt;100 mg/dL\nNo\nYes\nYes\nNo\nNo\nNo\n113\n100 to &lt;130 mg/dL\nNo\nYes\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nYes\nYes\nNever\n35+\nYes\nYes\n95.873016\n59.00152\n6.6\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\n\n\n74375\n12536.217\n1\n111\n2013-2014\n1\n0\n45 to 64\nHispanic\nNo\n63\nNo\nWomen\n171.3333\n72.66667\nSBP 160+ or DBP 100+ mm Hg\ntaking antihypertensive medications\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nOne\nOne\nNo\nNo\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nFormer\n&lt;25\nYes\nYes\n141.176471\n108.03135\n11.2\nNo\nYes\nNo\nNo\nNo\nNo\nNo\nNo\n\n\n124796\n4667.865\n1\n167\n2017-2020\n1\n0\n45 to 64\nNon-Hispanic Black\nYes\n61\nNo\nWomen\n133.1667\n75.70000\nSBP of 130 to &lt;140 or DBP 80 to &lt;90 mm Hg\ntaking antihypertensive medications\nNo\nNo\nYes\nNo\nYes\nNo\nYes\nYes\nNo\nYes\nNo\nYes\nYes\nYes\nYes\nYes\nFour or more\nThree\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nNo\nNo\nNo\nYes\nNo\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNever\n35+\nYes\nNo\n4.666667\n85.04965\n6.9\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\n\n\n56088\n24882.496\n2\n75\n2009-2010\n1\n0\n18 to 44\nHispanic\nNo\n40\nNo\nWomen\n136.6667\n70.00000\nSBP of 130 to &lt;140 or DBP 80 to &lt;90 mm Hg\ntaking antihypertensive medications\nNo\nNo\nYes\nNo\nYes\nNo\nYes\nYes\nNo\nYes\nNo\nYes\nYes\nYes\nYes\nYes\nTwo\nTwo\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nNo\nNo\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNever\n35+\nYes\nNo\n4.696356\n115.83310\n6.7\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\n\n\n74958\n17328.399\n1\n108\n2013-2014\n1\n0\n75+\nHispanic\nNo\n76\nNo\nWomen\n177.3333\n48.00000\nSBP 160+ or DBP 100+ mm Hg\ntaking antihypertensive medications\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nTwo\nTwo\nNo\nYes\nNo\nNo\nNo\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nFormer\n25 to &lt;30\nYes\nNo\n9.871795\n65.38231\n6.9\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\n\n\n89925\n11090.360\n1\n128\n2015-2016\n1\n0\n65 to 74\nHispanic\nNo\n68\nNo\nWomen\n132.0000\n66.00000\nSBP of 130 to &lt;140 or DBP 80 to &lt;90 mm Hg\ntaking antihypertensive medications\nNo\nNo\nYes\nYes\nYes\nNo\nYes\nYes\nNo\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nFour or more\nFour or more\nNo\nYes\nYes\nNo\nNo\nNo\nYes\nNo\nYes\nYes\nNo\nNo\nNo\nYes\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNever\n35+\nYes\nNo\n12.426778\n79.01981\n7.5\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\n\n\n\n\n\n\n\nsubset_nhanes %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_diabetes)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 12) +\n    ggtitle(\"Blood Pressure with Diabetes Histogram\")\n\n\n\n\n\n\n\nsubset_nhanes%&gt;%\n  ggplot(aes(x=cc_diabetes, y=bp_sys_mean, fill=cc_diabetes)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Diabetes Status\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nWe can use a t-test to evaluate whether or not the two populations (diabetes and non-diabetes) have significantly different distributions of blood pressures:\n\nnhanes_sys_diabetes &lt;- subset_nhanes %&gt;% select(cc_diabetes, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_diabetes)\ndiabetes_test &lt;- t.test(bp_sys_mean ~ cc_diabetes, data = subset_nhanes)\ndiabetes_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_diabetes\nt = -5.1725, df = 97.158, p-value = 1.24e-06\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -17.043266  -7.591128\nsample estimates:\n mean in group No mean in group Yes \n         122.2213          134.5385 \n\n\nHere we can see that with a p-value of 0.007, there is a significant difference between the two populations. The diabetes group has a mean blood pressure of about 137, while the non-diabetes group has a mean of about 124.\nNow we want to add in noise to the data to simulate making the measurements less accurate. We can achieve this by sampling from a normal distribution centered on 0 and adding the resulting value to the original data measurement. This will mask the patient’s true blood pressure value.\nWe will experiment with 3 values for “reliability”: the higher the value, the lower the variance of the distribution from which we sample noise, and the closer to the original data the noisy data tends to be.\nFirst, let’s try a value of 0.3:\n\n    reliability &lt;- 0.3  ### Set up measurement error with 0.5 Attenuation coef\n    sigma_u_sq &lt;- 1/reliability - 1\n    \n    sigma_u_sq\n\n[1] 2.333333\n\n    sigma_u_sq^0.5\n\n[1] 1.527525\n\n\nWe can see that a low reliability value results in a variance of 2.33 and a standard deviation of about 1.53. Next, let’s increase reliability to 0.5\n\n    reliability &lt;- 0.5\n    sigma_u_sq &lt;- 1/reliability - 1\n    \n    sigma_u_sq\n\n[1] 1\n\n    sigma_u_sq^0.5\n\n[1] 1\n\n\nWhen we increase the reliability, the variance and standard deviation both decrease to 1. This will ultimately result in a bit less change to the original data.\nFinally, let’s look at reliability of 0.7\n\n    reliability &lt;- 0.7\n    sigma_u_sq &lt;- 1/reliability - 1\n    \n    sigma_u_sq\n\n[1] 0.4285714\n\n    sigma_u_sq^0.5\n\n[1] 0.6546537\n\n\nWith a variance of 0.43 and standard deviation of 0.65, this reliability value creates the least noise compared to 0.3 and 0.5.\nNow, let’s actually transform the data we have and visualize:\n\nset.seed(105)\nn = nrow(subset_nhanes)\n\nreliability &lt;- 0.0005   ### Set up measurement error with 0.5 Attenuation coef\nsigma_u_sq &lt;- 1/reliability - 1\nsubset_nhanes$bp_sys_mean_noise_low &lt;- subset_nhanes$bp_sys_mean + rnorm(n, sd=sigma_u_sq^0.5)\nsubset_nhanes$bp_sys_mean_noise_low &lt;- abs(subset_nhanes$bp_sys_mean_noise_low)\n\nreliability &lt;- 0.005\nsigma_u_sq &lt;- 1/reliability - 1\nsubset_nhanes$bp_sys_mean_noise_med &lt;- subset_nhanes$bp_sys_mean + rnorm(n, sd=sigma_u_sq^0.5)\n\nreliability &lt;- 0.1\nsigma_u_sq &lt;- 1/reliability - 1\nsubset_nhanes$bp_sys_mean_noise_high &lt;- subset_nhanes$bp_sys_mean + rnorm(n, sd=sigma_u_sq^0.5)\n\nLet’s visualize the difference between the raw BP measurements and the measurements with new error added in:\n\n#X axis = Blood Pressure\n#Y axis = BP + Noise\n#Title = Low, Moderate, High Reliability (0.25), for example\nscatterplot &lt;- ggplot(subset_nhanes, aes(x=bp_sys_mean, y=bp_sys_mean_noise_low)) + \n    geom_point(size=0.5) +\n    ggtitle(\"Low Reliability\") +\n    xlab(\"Blood Pressure\") +\n    ylab(\"BP + Noise\")\n    \nscatterplot + annotate(\"segment\", x = 75, xend = 200, y = 75, yend = 200,\n  colour = \"red\")\n\n\n\n\n\n\n\nscatterplot &lt;- ggplot(subset_nhanes, aes(x=bp_sys_mean, y=bp_sys_mean_noise_med)) + \n    geom_point(size=0.5) +\n    ggtitle(\"Medium Reliability\") +\n    xlab(\"Blood Pressure\") +\n    ylab(\"BP + Error\")\n    \nscatterplot + annotate(\"segment\", x = 75, xend = 200, y = 75, yend = 200,\n  colour = \"red\")\n\n\n\n\n\n\n\nscatterplot &lt;- ggplot(subset_nhanes, aes(x=bp_sys_mean, y=bp_sys_mean_noise_high)) + \n    geom_point(size=0.5) +\n    ggtitle(\"High Reliability\") +\n    xlab(\"Blood Pressure\") +\n    ylab(\"BP + Error\")\n    \nscatterplot + annotate(\"segment\", x = 75, xend = 200, y = 75, yend = 200,\n  colour = \"red\")\n\n\n\n\n\n\n\n\nComparing the values created by setting reliability to 0.025 and 0.25, we can see that the spread of the scatter plot is much different. The added amount of noise in the high reliability case does not shift the data points very far off from their original positions compared to the low reliability case.\nWe can also measure the “spread” of the noise by calculating the correlation coefficient. This will give us a numerical value for how linked the two variables are:\nIn some cases:\nNotice that in the low reliability case, so much noise here is added that there are a few data points with a blood pressure value below 0. Data with this much error in it obviously wouldn’t be used in the real world, but for the sake of demonstrating the effectiveness of measurement error correction, we will continue to use this data.\n\nprint(paste(\"Reliability Low Correlation Coefficient:\", cor(subset_nhanes$bp_sys_mean, subset_nhanes$bp_sys_mean_noise_low))) \n\n[1] \"Reliability Low Correlation Coefficient: 0.371898162992643\"\n\nprint(paste(\"Reliability Medium Correlation Coefficient:\", cor(subset_nhanes$bp_sys_mean, subset_nhanes$bp_sys_mean_noise_med))) \n\n[1] \"Reliability Medium Correlation Coefficient: 0.789073180735782\"\n\nprint(paste(\"Reliability High Correlation Coefficient:\", cor(subset_nhanes$bp_sys_mean, subset_nhanes$bp_sys_mean_noise_high)))\n\n[1] \"Reliability High Correlation Coefficient: 0.987158951684439\"\n\n\nFinally, let’s look again at a t-test to see if the relationship between diabetes status and noisy blood pressure is any different than the non-noisy data.\n\nnhanes_sys_diabetes &lt;- subset_nhanes %&gt;% select(cc_diabetes, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_diabetes)\ndiabetes_test &lt;- t.test(bp_sys_mean_noise_low ~ cc_diabetes, data = subset_nhanes)\ndiabetes_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean_noise_low by cc_diabetes\nt = -1.8332, df = 101.26, p-value = 0.06971\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -21.4872072   0.8470414\nsample estimates:\n mean in group No mean in group Yes \n         123.0366          133.3566 \n\nnhanes_sys_diabetes &lt;- subset_nhanes %&gt;% select(cc_diabetes, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_diabetes)\ndiabetes_test &lt;- t.test(bp_sys_mean_noise_med ~ cc_diabetes, data = subset_nhanes)\ndiabetes_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean_noise_med by cc_diabetes\nt = -4.3257, df = 105.5, p-value = 3.462e-05\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -16.502997  -6.129374\nsample estimates:\n mean in group No mean in group Yes \n         122.4257          133.7419 \n\nnhanes_sys_diabetes &lt;- subset_nhanes %&gt;% select(cc_diabetes, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_diabetes)\ndiabetes_test &lt;- t.test(bp_sys_mean_noise_high ~ cc_diabetes, data = subset_nhanes)\ndiabetes_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean_noise_high by cc_diabetes\nt = -5.0414, df = 96.81, p-value = 2.152e-06\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -16.935141  -7.367393\nsample estimates:\n mean in group No mean in group Yes \n         122.3786          134.5299 \n\n\nWe can see that in the low reliability case, enough noise was added that the results of the t-test are no longer significant, as the p-value is higher than 0.05. In the medium reliability case, the results are still significant, but much less so, with the p-value doubling from 0.02 to 0.04. Finally, in the high reliability case, the results of the t-test are not much different than when using the raw data. This is because the amount of noise added was quite low.\nNow, we will try to fit a linear regression model to estimate the raw measurement from the “error”-full measurement.\n\nerror_model_0.3 &lt;- glm(bp_sys_mean ~ bp_sys_mean_noise_low, data = subset_nhanes, family = 'gaussian')\nsummary(error_model_0.3)\n\n\nCall:\nglm(formula = bp_sys_mean ~ bp_sys_mean_noise_low, family = \"gaussian\", \n    data = subset_nhanes)\n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           105.08228    2.04124  51.480   &lt;2e-16 ***\nbp_sys_mean_noise_low   0.15067    0.01538   9.797   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 304.6497)\n\n    Null deviance: 211422  on 599  degrees of freedom\nResidual deviance: 182181  on 598  degrees of freedom\nAIC: 5138.2\n\nNumber of Fisher Scoring iterations: 2\n\nerror_model_0.5 &lt;- glm(bp_sys_mean ~ bp_sys_mean_noise_med, data = subset_nhanes, family = 'gaussian')\nsummary(error_model_0.5)\n\n\nCall:\nglm(formula = bp_sys_mean ~ bp_sys_mean_noise_med, family = \"gaussian\", \n    data = subset_nhanes)\n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           44.15721    2.57965   17.12   &lt;2e-16 ***\nbp_sys_mean_noise_med  0.64300    0.02047   31.41   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 133.4162)\n\n    Null deviance: 211422  on 599  degrees of freedom\nResidual deviance:  79783  on 598  degrees of freedom\nAIC: 4642.8\n\nNumber of Fisher Scoring iterations: 2\n\nerror_model_0.7 &lt;- glm(bp_sys_mean ~ bp_sys_mean_noise_high, data = subset_nhanes, family = 'gaussian')\nsummary(error_model_0.7)\n\n\nCall:\nglm(formula = bp_sys_mean ~ bp_sys_mean_noise_high, family = \"gaussian\", \n    data = subset_nhanes)\n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              2.0698     0.8149    2.54   0.0113 *  \nbp_sys_mean_noise_high   0.9822     0.0065  151.12   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 9.021565)\n\n    Null deviance: 211421.9  on 599  degrees of freedom\nResidual deviance:   5394.9  on 598  degrees of freedom\nAIC: 3026.5\n\nNumber of Fisher Scoring iterations: 2\n\n\n\nsubset_nhanes %&gt;%\n  ggplot(aes(x=bp_sys_mean_noise_low, color=cc_diabetes)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 12) +\n    ggtitle(\"Blood Pressure with Diabetes Histogram\")\n\n\n\n\n\n\n\nsubset_nhanes %&gt;%\n  ggplot(aes(x=cc_diabetes, y=bp_sys_mean_noise_low, fill=cc_diabetes)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Diabetes Status\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nWe can see in both the histogram and especially in the box plot, the noise has made it so that the two group’s distributions are virtually indistinguishable. This mimics what may happen in the real world: although the underlying distribution of two groups may be different, error in measurement may mask this fact so that the data given looks very similar. Had we been given the noisy data and performed a t-test without accounting for this error, we would come to the incorrect conclusion that diabetes and blood pressure are not linked.\nThis is the main issue that measurement error seeks to correct. By using it, we can avoid drawing incorrect conclusions about our data.\n\n#Store our dataframe:\nsaveRDS(subset_nhanes, \"nhanes_subset.rds\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating \"Noisy\" Data</span>"
    ]
  },
  {
    "objectID": "reg_cal.html",
    "href": "reg_cal.html",
    "title": "6  Regression Calibration",
    "section": "",
    "text": "7 Simple Regression",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression Calibration</span>"
    ]
  },
  {
    "objectID": "reg_cal.html#naive-analysis",
    "href": "reg_cal.html#naive-analysis",
    "title": "6  Regression Calibration",
    "section": "7.1 Naive Analysis",
    "text": "7.1 Naive Analysis\nBefore starting with regression calibration, we first want to see what a model that only uses our noisy data looks like. We’ll use the same model formula as before (including age, race, smoking status etc.), the only difference being that we will use our error-full data, specifically the low reliability case.\n\nnaive.model=glm(cc_diabetes ~ bp_sys_mean_noise_low, family=\"binomial\", data=subset_nhanes)\nsummary(naive.model)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean_noise_low, family = \"binomial\", \n    data = subset_nhanes)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -2.519646   0.369018  -6.828 8.61e-12 ***\nbp_sys_mean_noise_low  0.004826   0.002639   1.828   0.0675 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 460.29  on 598  degrees of freedom\nAIC: 464.29\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(naive.model, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.080\n0.369\n-6.828\n0.000\n0.038\n0.162\n\n\nbp_sys_mean_noise_low\n1.005\n0.003\n1.828\n0.067\n1.000\n1.010\n\n\n\n\n\nLooking at the summary above, the significant coefficients, and therefore the variables which the model finds most useful in diabetes status prediction, are age, Non-Hispanic Black racial status, and BMI status, specifically for those in the 25 to 30 range. Note that our p value for our blood pressure variable is quite high, showing non-significance in the model.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression Calibration</span>"
    ]
  },
  {
    "objectID": "reg_cal.html#gold-standard-analysis",
    "href": "reg_cal.html#gold-standard-analysis",
    "title": "6  Regression Calibration",
    "section": "7.2 Gold Standard Analysis",
    "text": "7.2 Gold Standard Analysis\nNext, we’ll look at our “true” model, the model which uses our unbiased, non-error blood pressure values:\n\ntrue.model=glm(cc_diabetes ~ bp_sys_mean, family=\"binomial\", data=subset_nhanes)\nsummary(true.model)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean, family = \"binomial\", \n    data = subset_nhanes)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.777250   0.787205  -7.339 2.15e-13 ***\nbp_sys_mean  0.030330   0.005911   5.131 2.89e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 437.53  on 598  degrees of freedom\nAIC: 441.53\n\nNumber of Fisher Scoring iterations: 5\n\nknitr::kable(tidy(true.model, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.003\n0.787\n-7.339\n0\n0.001\n0.014\n\n\nbp_sys_mean\n1.031\n0.006\n5.131\n0\n1.019\n1.043\n\n\n\n\n\nFor this subset of the data, the true beta value for the systolic mean is … This is much higher than the model which we looked at previously, using all ~50,000 subjects, although it is to be expected since we restricted the data to n=150 samples. Also notice that the significance level",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression Calibration</span>"
    ]
  },
  {
    "objectID": "reg_cal.html#regression-calibration",
    "href": "reg_cal.html#regression-calibration",
    "title": "6  Regression Calibration",
    "section": "7.3 Regression Calibration",
    "text": "7.3 Regression Calibration\n\n#Create a model with predicts the true BP value based on the noisy BP data\nrcfit&lt;-lm(bp_sys_mean ~ bp_sys_mean_noise_low, data=subset_nhanes)\nsummary(rcfit)\n\n\nCall:\nlm(formula = bp_sys_mean ~ bp_sys_mean_noise_low, data = subset_nhanes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-40.512 -12.063  -1.631   8.883  71.880 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           105.08228    2.04124  51.480   &lt;2e-16 ***\nbp_sys_mean_noise_low   0.15067    0.01538   9.797   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.45 on 598 degrees of freedom\nMultiple R-squared:  0.1383,    Adjusted R-squared:  0.1369 \nF-statistic: 95.98 on 1 and 598 DF,  p-value: &lt; 2.2e-16\n\nsubset_nhanes$bp_hat &lt;- predict(rcfit, newdata=subset_nhanes) \n\nfinal.model = glm(cc_diabetes ~ bp_hat, family=\"binomial\",data=subset_nhanes)\nsummary(final.model)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_hat, family = \"binomial\", data = subset_nhanes)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept) -5.88548    2.19259  -2.684  0.00727 **\nbp_hat       0.03203    0.01752   1.828  0.06749 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 460.29  on 598  degrees of freedom\nAIC: 464.29\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(final.model, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.003\n2.193\n-2.684\n0.007\n0.000\n0.196\n\n\nbp_hat\n1.033\n0.018\n1.828\n0.067\n0.998\n1.069\n\n\n\n\n\n\nprint(paste(\"Correlation between BP_noise and BP_hat:\", cor(subset_nhanes$bp_sys_mean_noise_low, subset_nhanes$bp_hat)))\n\n[1] \"Correlation between BP_noise and BP_hat: 0.999999999999997\"\n\n\nFix Standard Errors:\n\n#warning = False\nset.seed(43)\n\nbootstrap.functionV2&lt;-function(dat,inds){\n    subset_nhanes.boot&lt;-dat[inds,]\n    rcfit.boot&lt;-lm(bp_sys_mean ~ bp_sys_mean_noise_low, data=subset_nhanes.boot)\n    subset_nhanes.boot$bp_hat&lt;-predict(rcfit.boot,newdata=subset_nhanes.boot)\n    final.model= glm(cc_diabetes ~ bp_hat, family=\"binomial\", data=subset_nhanes.boot)\n    return(final.model$coef)\n}\n\nmy.boot&lt;-boot(subset_nhanes, bootstrap.functionV2, R=500)\nbsSD &lt;- apply(my.boot$t,2,sd)\nbsSD\n\n[1] 2.08979580 0.01666782\n\nt.stat&lt;-coef(final.model)/bsSD\nt.stat\n\n(Intercept)      bp_hat \n  -2.816292    1.921693 \n\n\nNow we can recalculate the p value for the bp_hat intercept using the t statistic calculated above. We can do this using the pt() function, which returns a p value based on a t statistic and degrees of freedom.\nSince our alternative hypothesis in this case is ____ we set the lower.tail parameter to false?.\n\np.value.bp &lt;- 2 * (1 - pnorm(t.stat['bp_hat']))\nprint(p.value.bp)\n\n    bp_hat \n0.05464444 \n\n\nHere, while we don’t recover a significant p value, we do have a lower p value compared to the naive analysis (0.055 vs 0.067). Therefore, we are more confident in our conclusion that blood pressure has a correlation to diabetes risk. In this case, we can interpret the results that for one additional unit increase in systolic blood pressure, the estimated risk of having diabetes increases by 3.3%.\nWe can also recalculate the confidence intervals: using the log odds value for the bp_hat intercept 1.033 and the recalculated standard errors, we can perform a simple calculation to construct the confidence interval at a level of 95%.\n\nconf.low &lt;- 1.033 - 1.96*0.01666782\nconf.high &lt;- 1.033 + 1.96*0.01666782\nconf.low\n\n[1] 1.000331\n\nconf.high\n\n[1] 1.065669\n\n\nWe see that the confidence interval does not cover 1, indicating that there is a strong evidence that a positive correlation between blood pressure and diabetes exists with a 95% confidence level.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression Calibration</span>"
    ]
  },
  {
    "objectID": "reg_cal.html#naive-analysis-1",
    "href": "reg_cal.html#naive-analysis-1",
    "title": "6  Regression Calibration",
    "section": "8.1 Naive Analysis",
    "text": "8.1 Naive Analysis\nBefore starting with regression calibration, we first want to see what a model that only uses our noisy data looks like. We’ll use the same model formula as before (including age, race, smoking status etc.), the only difference being that we will use our error-full data, specifically the low reliability case.\n\nnaive.model=glm(cc_diabetes ~ bp_sys_mean_noise_low + demo_age_years + demo_gender + demo_race + cc_bmi + bp_med_use, family=\"binomial\", data=subset_nhanes)\nsummary(naive.model)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean_noise_low + demo_age_years + \n    demo_gender + demo_race + cc_bmi + bp_med_use, family = \"binomial\", \n    data = subset_nhanes)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -6.360537   0.810700  -7.846 4.30e-15 ***\nbp_sys_mean_noise_low        0.001768   0.002926   0.604 0.545658    \ndemo_age_years               0.047772   0.010231   4.669 3.02e-06 ***\ndemo_genderWomen            -0.593300   0.278581  -2.130 0.033195 *  \ndemo_raceNon-Hispanic Black  0.861090   0.365695   2.355 0.018539 *  \ndemo_raceNon-Hispanic Asian  1.151863   0.708336   1.626 0.103917    \ndemo_raceHispanic            1.286503   0.341675   3.765 0.000166 ***\ndemo_raceOther               0.780841   0.814489   0.959 0.337716    \ncc_bmi25 to &lt;30              0.650462   0.412058   1.579 0.114435    \ncc_bmi30 to &lt;35              1.234393   0.436396   2.829 0.004675 ** \ncc_bmi35+                    1.861836   0.453735   4.103 4.07e-05 ***\nbp_med_useYes                0.771081   0.308493   2.500 0.012437 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 368.59  on 588  degrees of freedom\nAIC: 392.59\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(naive.model, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.002\n0.811\n-7.846\n0.000\n0.000\n0.008\n\n\nbp_sys_mean_noise_low\n1.002\n0.003\n0.604\n0.546\n0.996\n1.008\n\n\ndemo_age_years\n1.049\n0.010\n4.669\n0.000\n1.029\n1.071\n\n\ndemo_genderWomen\n0.553\n0.279\n-2.130\n0.033\n0.318\n0.950\n\n\ndemo_raceNon-Hispanic Black\n2.366\n0.366\n2.355\n0.019\n1.157\n4.884\n\n\ndemo_raceNon-Hispanic Asian\n3.164\n0.708\n1.626\n0.104\n0.659\n11.522\n\n\ndemo_raceHispanic\n3.620\n0.342\n3.765\n0.000\n1.871\n7.181\n\n\ndemo_raceOther\n2.183\n0.814\n0.959\n0.338\n0.319\n9.110\n\n\ncc_bmi25 to &lt;30\n1.916\n0.412\n1.579\n0.114\n0.870\n4.434\n\n\ncc_bmi30 to &lt;35\n3.436\n0.436\n2.829\n0.005\n1.488\n8.340\n\n\ncc_bmi35+\n6.436\n0.454\n4.103\n0.000\n2.715\n16.253\n\n\nbp_med_useYes\n2.162\n0.308\n2.500\n0.012\n1.184\n3.982\n\n\n\n\n\nLooking at the summary above, the significant coefficients, and therefore the variables which the model finds most useful in diabetes status prediction, are age, Non-Hispanic Black racial status, and BMI status, specifically for those in the 25 to 30 range. Note that our p value for our blood pressure variable is quite high, showing non-significance in the model.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression Calibration</span>"
    ]
  },
  {
    "objectID": "reg_cal.html#gold-standard-analysis-1",
    "href": "reg_cal.html#gold-standard-analysis-1",
    "title": "6  Regression Calibration",
    "section": "8.2 Gold Standard Analysis",
    "text": "8.2 Gold Standard Analysis\nNext, we’ll look at our “true” model, the model which uses our unbiased, non-error blood pressure values:\n\ntrue.model=glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_gender + demo_race + cc_bmi + bp_med_use, family=\"binomial\", data=subset_nhanes)\nsummary(true.model)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_gender + \n    demo_race + cc_bmi + bp_med_use, family = \"binomial\", data = subset_nhanes)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -8.03913    1.12566  -7.142 9.22e-13 ***\nbp_sys_mean                  0.01700    0.00734   2.316 0.020570 *  \ndemo_age_years               0.04199    0.01058   3.969 7.21e-05 ***\ndemo_genderWomen            -0.61506    0.28041  -2.193 0.028273 *  \ndemo_raceNon-Hispanic Black  0.88094    0.36250   2.430 0.015091 *  \ndemo_raceNon-Hispanic Asian  1.19350    0.71337   1.673 0.094321 .  \ndemo_raceHispanic            1.29849    0.34264   3.790 0.000151 ***\ndemo_raceOther               0.83248    0.82019   1.015 0.310114    \ncc_bmi25 to &lt;30              0.70851    0.41714   1.699 0.089413 .  \ncc_bmi30 to &lt;35              1.28751    0.44345   2.903 0.003692 ** \ncc_bmi35+                    1.97864    0.46266   4.277 1.90e-05 ***\nbp_med_useYes                0.68256    0.30655   2.227 0.025973 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 363.63  on 588  degrees of freedom\nAIC: 387.63\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(true.model, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.000\n1.126\n-7.142\n0.000\n0.000\n0.003\n\n\nbp_sys_mean\n1.017\n0.007\n2.316\n0.021\n1.003\n1.032\n\n\ndemo_age_years\n1.043\n0.011\n3.969\n0.000\n1.022\n1.065\n\n\ndemo_genderWomen\n0.541\n0.280\n-2.193\n0.028\n0.309\n0.932\n\n\ndemo_raceNon-Hispanic Black\n2.413\n0.362\n2.430\n0.015\n1.188\n4.951\n\n\ndemo_raceNon-Hispanic Asian\n3.299\n0.713\n1.673\n0.094\n0.682\n12.160\n\n\ndemo_raceHispanic\n3.664\n0.343\n3.790\n0.000\n1.889\n7.279\n\n\ndemo_raceOther\n2.299\n0.820\n1.015\n0.310\n0.333\n9.724\n\n\ncc_bmi25 to &lt;30\n2.031\n0.417\n1.699\n0.089\n0.914\n4.749\n\n\ncc_bmi30 to &lt;35\n3.624\n0.443\n2.903\n0.004\n1.550\n8.925\n\n\ncc_bmi35+\n7.233\n0.463\n4.277\n0.000\n3.006\n18.630\n\n\nbp_med_useYes\n1.979\n0.307\n2.227\n0.026\n1.088\n3.629\n\n\n\n\n\nFor this subset of the data, the true beta value for the systolic mean is … This is much higher than the model which we looked at previously, using all ~50,000 subjects, although it is to be expected since we restricted the data to n=150 samples. Also notice that the significance level",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression Calibration</span>"
    ]
  },
  {
    "objectID": "reg_cal.html#regression-calibration-1",
    "href": "reg_cal.html#regression-calibration-1",
    "title": "6  Regression Calibration",
    "section": "8.3 Regression Calibration",
    "text": "8.3 Regression Calibration\n\n#Create a model with predicts the true BP value based on the noisy BP data\nrcfit&lt;-lm(bp_sys_mean ~ bp_sys_mean_noise_low + demo_age_years + demo_gender + demo_race + cc_bmi + bp_med_use, data=subset_nhanes)\nsummary(rcfit)\n\n\nCall:\nlm(formula = bp_sys_mean ~ bp_sys_mean_noise_low + demo_age_years + \n    demo_gender + demo_race + cc_bmi + bp_med_use, data = subset_nhanes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-38.474  -9.810  -1.711   8.647  63.218 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 89.56535    2.78350  32.177  &lt; 2e-16 ***\nbp_sys_mean_noise_low        0.11877    0.01382   8.596  &lt; 2e-16 ***\ndemo_age_years               0.40142    0.04192   9.575  &lt; 2e-16 ***\ndemo_genderWomen            -1.72991    1.27718  -1.354 0.176102    \ndemo_raceNon-Hispanic Black  0.63160    1.69938   0.372 0.710275    \ndemo_raceNon-Hispanic Asian -1.84153    2.77735  -0.663 0.507557    \ndemo_raceHispanic           -0.75026    1.56330  -0.480 0.631462    \ndemo_raceOther              -0.91382    3.07167  -0.297 0.766191    \ncc_bmi25 to &lt;30             -0.60550    1.62407  -0.373 0.709408    \ncc_bmi30 to &lt;35              0.23627    1.78558   0.132 0.894777    \ncc_bmi35+                   -0.85737    1.93105  -0.444 0.657214    \nbp_med_useYes                5.62935    1.68476   3.341 0.000887 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.27 on 588 degrees of freedom\nMultiple R-squared:  0.3519,    Adjusted R-squared:  0.3397 \nF-statistic: 29.02 on 11 and 588 DF,  p-value: &lt; 2.2e-16\n\nsubset_nhanes$bp_hat &lt;- predict(rcfit, newdata=subset_nhanes) \n\nfinal.model = glm(cc_diabetes ~ bp_hat + demo_age_years + demo_gender + demo_race + cc_bmi + bp_med_use, family=\"binomial\",data=subset_nhanes)\nsummary(final.model)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_hat + demo_age_years + demo_gender + \n    demo_race + cc_bmi + bp_med_use, family = \"binomial\", data = subset_nhanes)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -7.69381    2.60474  -2.954  0.00314 ** \nbp_hat                       0.01489    0.02463   0.604  0.54566    \ndemo_age_years               0.04180    0.01532   2.729  0.00635 ** \ndemo_genderWomen            -0.56755    0.27962  -2.030  0.04238 *  \ndemo_raceNon-Hispanic Black  0.85169    0.36838   2.312  0.02078 *  \ndemo_raceNon-Hispanic Asian  1.17928    0.71127   1.658  0.09732 .  \ndemo_raceHispanic            1.29767    0.34073   3.809  0.00014 ***\ndemo_raceOther               0.79444    0.81493   0.975  0.32963    \ncc_bmi25 to &lt;30              0.65948    0.41242   1.599  0.10981    \ncc_bmi30 to &lt;35              1.23088    0.43622   2.822  0.00478 ** \ncc_bmi35+                    1.87460    0.45404   4.129 3.65e-05 ***\nbp_med_useYes                0.68728    0.32203   2.134  0.03282 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 463.66  on 599  degrees of freedom\nResidual deviance: 368.59  on 588  degrees of freedom\nAIC: 392.59\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(final.model, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.000\n2.605\n-2.954\n0.003\n0.000\n0.071\n\n\nbp_hat\n1.015\n0.025\n0.604\n0.546\n0.967\n1.065\n\n\ndemo_age_years\n1.043\n0.015\n2.729\n0.006\n1.012\n1.075\n\n\ndemo_genderWomen\n0.567\n0.280\n-2.030\n0.042\n0.325\n0.976\n\n\ndemo_raceNon-Hispanic Black\n2.344\n0.368\n2.312\n0.021\n1.140\n4.864\n\n\ndemo_raceNon-Hispanic Asian\n3.252\n0.711\n1.658\n0.097\n0.674\n11.916\n\n\ndemo_raceHispanic\n3.661\n0.341\n3.809\n0.000\n1.895\n7.248\n\n\ndemo_raceOther\n2.213\n0.815\n0.975\n0.330\n0.323\n9.243\n\n\ncc_bmi25 to &lt;30\n1.934\n0.412\n1.599\n0.110\n0.877\n4.478\n\n\ncc_bmi30 to &lt;35\n3.424\n0.436\n2.822\n0.005\n1.484\n8.308\n\n\ncc_bmi35+\n6.518\n0.454\n4.129\n0.000\n2.749\n16.476\n\n\nbp_med_useYes\n1.988\n0.322\n2.134\n0.033\n1.060\n3.758\n\n\n\n\n\n\ndiabetes_test &lt;- t.test(bp_hat ~ cc_diabetes, data = subset_nhanes)\ndiabetes_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_hat by cc_diabetes\nt = -7.6016, df = 110, p-value = 1.047e-11\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -11.246486  -6.595121\nsample estimates:\n mean in group No mean in group Yes \n         122.6628          131.5836 \n\n\n\nprint(paste(\"Correlation between BP_noise and BP_hat:\", cor(subset_nhanes$bp_sys_mean_noise_low, subset_nhanes$bp_hat)))\n\n[1] \"Correlation between BP_noise and BP_hat: 0.626950413178945\"\n\n\nFix Standard Errors:\n\n#warning = False\nset.seed(43)\n\nbootstrap.functionV2&lt;-function(dat,inds){\n    subset_nhanes.boot&lt;-dat[inds,]\n    rcfit.boot&lt;-lm(bp_sys_mean ~ bp_sys_mean_noise_low + demo_age_years + demo_gender + demo_race + cc_bmi + bp_med_use, data=subset_nhanes.boot)\n    subset_nhanes.boot$bp_hat&lt;-predict(rcfit.boot,newdata=subset_nhanes.boot)\n    final.model= glm(cc_diabetes ~ bp_hat, family=\"binomial\", data=subset_nhanes.boot)\n    return(final.model$coef)\n}\n\nmy.boot&lt;-boot(subset_nhanes, bootstrap.functionV2, R=500)\nbsSD &lt;- apply(my.boot$t,2,sd)\nbsSD\n\n[1] 1.70784464 0.01331138\n\nt.stat&lt;-coef(final.model)/bsSD\nt.stat\n\n                (Intercept)                      bp_hat \n                -4.50498173                  1.11829331 \n             demo_age_years            demo_genderWomen \n                 0.02447299                -42.63630869 \ndemo_raceNon-Hispanic Black demo_raceNon-Hispanic Asian \n                 0.49869177                 88.59155106 \n          demo_raceHispanic              demo_raceOther \n                 0.75983012                 59.68157177 \n            cc_bmi25 to &lt;30             cc_bmi30 to &lt;35 \n                 0.38614475                 92.46793953 \n                  cc_bmi35+               bp_med_useYes \n                 1.09764009                 51.63115902 \n\n\n\np.value.bp &lt;- 2 * (1 - pnorm(t.stat['bp_hat']))\nprint(p.value.bp)\n\n   bp_hat \n0.2634417 \n\n\n\nconf.low &lt;- 1.015 - 1.96*0.01331138\nconf.high &lt;- 1.015 + 1.96*0.01331138\nconf.low\n\n[1] 0.9889097\n\nconf.high\n\n[1] 1.04109",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression Calibration</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]