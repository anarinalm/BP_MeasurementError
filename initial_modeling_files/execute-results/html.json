{
  "hash": "623584329f7bc439fac9b774e55b31ff",
  "result": {
    "engine": "knitr",
    "markdown": "# Modeling Diabetes Occurence\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(data.table)\nlibrary(DT)\nlibrary(broom)\nlibrary(devtools)\nlibrary(viridis)\nlibrary(knitr)\nlibrary(hrbrthemes)\nlibrary(car)\n#using data specified in this github repository:\ninstall_github(\"jhs-hwg/cardioStatsUSA\")\nlibrary(cardioStatsUSA)\n```\n:::\n\n\n## Simple Diabetes Modeling\n\nWe are choosing Diabetes as the co-morbidity for modeling. We will try to predict the occurrence of diabetes as a function of blood pressure as well as other covariates.\n\nThe most basic model possible is a simple logistic regression model predicting diabetes status based on blood pressure:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_diab_model_sys <- glm(cc_diabetes ~ bp_sys_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_sys)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -4.9404827  0.0770324  -64.14   <2e-16 ***\nbp_sys_mean  0.0238141  0.0005811   40.98   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 41987  on 56532  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 41991\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nknitr::kable(tidy(simple_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept) |    0.007|     0.077|   -64.135|       0|    0.006|     0.008|\n|bp_sys_mean |    1.024|     0.001|    40.982|       0|    1.023|     1.025|\n\n\n:::\n\n```{.r .cell-code}\nsimple_diab_model_dia <- glm(cc_diabetes ~ bp_dia_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_dia)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cc_diabetes ~ bp_dia_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.652673   0.073728 -22.416  < 2e-16 ***\nbp_dia_mean -0.003651   0.001039  -3.514 0.000441 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43309  on 56285  degrees of freedom\nResidual deviance: 43297  on 56284  degrees of freedom\n  (3513 observations deleted due to missingness)\nAIC: 43301\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nknitr::kable(tidy(simple_diab_model_dia, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept) |    0.192|     0.074|   -22.416|       0|    0.166|     0.221|\n|bp_dia_mean |    0.996|     0.001|    -3.514|       0|    0.994|     0.998|\n\n\n:::\n:::\n\n\n#### Model Explanation:\n\nFor the logistic regression using systolic blood pressure, we can see that the odds ratio beta parameter is 1.024. This implies that a higher systolic blood pressure corresponds to increased chances of observing diabetes.\n\nA more exact interpretation would be that: for one additional unit increase in systolic blood pressure, the estimated risk of having diabetes increases by 2.4%.\n\nThis value may not seem extremely high, yet it still has a p value evaluated to be 0 by R. We can also see that the 95% confidence interval of this parameter ranges between 1.0229 and 1.0253, meaning that the model predicts that the true relationship falls within this interval with a 95% certainty, since the true value of the parameter is most likely within this interval.\n\nThe opposite is true with diastolic blood pressure: the beta parameter is 0.996, implying that higher diastolic blood pressure corresponds to a lower chance of observing diabetes. For an additional unit increase in diastolic blood pressure, the estimated risk of having diabetes decreases by 0.04%.\n\nNote: systolic blood pressure is a better predictor of cardiovascular disease, so I chose to consider systolic rather than diastolic in future models.\n\n## Demographic Model\n\nNext, we build a model including the demographic variables as well. This will hopefully provide a more accurate model, since it will have access to the further information in order to make predictions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_diab_model_sys <- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender,data = nhanes_data, family = binomial)\n\nsummary (demo_diab_model_sys)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender, family = binomial, data = nhanes_data)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                 -5.6927561  0.0885174 -64.312  < 2e-16 ***\nbp_sys_mean                  0.0037581  0.0006792   5.533 3.14e-08 ***\ndemo_age_years               0.0529545  0.0009161  57.806  < 2e-16 ***\ndemo_raceNon-Hispanic Black  0.9034242  0.0350353  25.786  < 2e-16 ***\ndemo_raceNon-Hispanic Asian  0.8093210  0.0606852  13.336  < 2e-16 ***\ndemo_raceHispanic            0.8592775  0.0343392  25.023  < 2e-16 ***\ndemo_raceOther               0.7478892  0.0718834  10.404  < 2e-16 ***\ndemo_genderWomen            -0.1547613  0.0265581  -5.827 5.63e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 37780  on 56526  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 37796\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n\n```{.r .cell-code}\nknitr::kable(tidy(demo_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term                        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:---------------------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)                 |    0.003|     0.089|   -64.312|       0|    0.003|     0.004|\n|bp_sys_mean                 |    1.004|     0.001|     5.533|       0|    1.002|     1.005|\n|demo_age_years              |    1.054|     0.001|    57.806|       0|    1.052|     1.056|\n|demo_raceNon-Hispanic Black |    2.468|     0.035|    25.786|       0|    2.304|     2.643|\n|demo_raceNon-Hispanic Asian |    2.246|     0.061|    13.336|       0|    1.993|     2.528|\n|demo_raceHispanic           |    2.361|     0.034|    25.023|       0|    2.208|     2.526|\n|demo_raceOther              |    2.113|     0.072|    10.404|       0|    1.832|     2.429|\n|demo_genderWomen            |    0.857|     0.027|    -5.827|       0|    0.813|     0.902|\n\n\n:::\n:::\n\n\n#### Model Explanation\n\nIn this model, we can still see a slight upwards trend with systolic blood pressure, although it is a bit weaker (1.024 \\> 1.003). With this parameter, the estimated risk of having diabetes increases only by 0.3%. Although the effect is smaller, we can see that the confidence interval is between 1.0024 and 1.0051, which does not include 1. So, although small, the positive relationship is most likely significant.\n\n#### Demographics\n\n**Age:**\n\nThe model also tells us that age is positively correlated with the observation of diabetes. With a log odds ratio of 1.054, it seems that every year increases the risk of diabetes occurrence by 5.4%.\n\n**Race:**\n\nThe log odds ratio for categorical variables compares the other variables to the baseline \"reference group\". Here, the \"reference group\" for the race variable is Non-Hispanic White. We can see that, in comparison to this group, all other races have significantly higher risk of diabetes: for example, the Hispanic population's risk of diabetes occurrence is 2.36 times higher than the Non-Hispanic White population.\n\n**Gender:**\n\nWith this variable, the reference group is men. We can see that women have a lower odds of having diabetes compared to men. Specifically, the risk of diabetes in women is about 85.6% of that of men.\n\n## Full Model\n\nLastly, we want to create a model including confounding variables. To achieve this, we must first determine which other variables are confounding, meaning they have significant associations with diabetes.\n\nWe can achieve this by using chi squared test, which compares whether or not the observed ratios of diabetes and confounding variables matches the ratios expected by random chance. If the chi squared test determines significance, then diabetes and the other variables commonly occur together and therefore are confounding.\n\n#### Perform Chi Squared Tests:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Testing for BMI\nnhanes_bmi_diab <- nhanes_data %>% select(cc_diabetes, cc_bmi) %>% drop_na(cc_bmi) %>% drop_na(cc_diabetes)\nnhanes_bmi_diab <- table(nhanes_bmi_diab)\n#nhanes_bmi_diab\nchisq.test(nhanes_bmi_diab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  nhanes_bmi_diab\nX-squared = 2368.3, df = 3, p-value < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n#Testing for Smoking\nnhanes_smoke_diab <- nhanes_data %>% select(cc_diabetes, cc_smoke) %>% drop_na(cc_smoke) %>% drop_na(cc_diabetes)\nnhanes_smoke_diab <- table(nhanes_smoke_diab)\n#nhanes_smoke_diab\nchisq.test(nhanes_smoke_diab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  nhanes_smoke_diab\nX-squared = 435.81, df = 2, p-value < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n#Testing for Hypertensive Medication use\nnhanes_med_diab <- nhanes_data %>% select(cc_diabetes, bp_med_use) %>% drop_na(bp_med_use) %>% drop_na(cc_diabetes)\nnhanes_med_diab <- table(nhanes_med_diab)\n#nhanes_med_diab\nchisq.test(nhanes_med_diab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_med_diab\nX-squared = 5807.1, df = 1, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n\nAfter this analysis, we can see that all three variables, BMI, Smoking, and Medication Use, are all confounding. We can include all of them in the next model, in addition to systolic blood pressure and the demographic variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#to prevent errors down the line, exclude the rows with na:\nused_vars = c('cc_diabetes', 'bp_sys_mean', 'demo_age_years', 'demo_race', 'demo_gender', 'cc_bmi', 'cc_smoke', 'bp_med_use')\nclean_nhanes <- nhanes_data[complete.cases(nhanes_data[,..used_vars]), ]\n\nfull_diab_model_sys <- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender+ cc_bmi + cc_smoke + bp_med_use, data = clean_nhanes, family = binomial)\n\nsummary(full_diab_model_sys)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender + cc_bmi + cc_smoke + bp_med_use, family = binomial, \n    data = clean_nhanes)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                 -6.3003463  0.1112295 -56.643  < 2e-16 ***\nbp_sys_mean                  0.0017066  0.0007373   2.315   0.0206 *  \ndemo_age_years               0.0470354  0.0011312  41.579  < 2e-16 ***\ndemo_raceNon-Hispanic Black  0.6987360  0.0374745  18.646  < 2e-16 ***\ndemo_raceNon-Hispanic Asian  1.3022903  0.0660355  19.721  < 2e-16 ***\ndemo_raceHispanic            0.8889260  0.0366792  24.235  < 2e-16 ***\ndemo_raceOther               0.8913458  0.0763522  11.674  < 2e-16 ***\ndemo_genderWomen            -0.3082492  0.0295124 -10.445  < 2e-16 ***\ncc_bmi25 to <30              0.5927344  0.0444524  13.334  < 2e-16 ***\ncc_bmi30 to <35              1.1736075  0.0463565  25.317  < 2e-16 ***\ncc_bmi35+                    1.7702868  0.0480051  36.877  < 2e-16 ***\ncc_smokeFormer               0.0614704  0.0335729   1.831   0.0671 .  \ncc_smokeCurrent              0.1853436  0.0403687   4.591 4.41e-06 ***\nbp_med_useYes                0.9121351  0.0314064  29.043  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 33055  on 52183  degrees of freedom\nAIC: 33083\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n\n```{.r .cell-code}\nknitr::kable(tidy(full_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term                        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:---------------------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)                 |    0.002|     0.111|   -56.643|   0.000|    0.001|     0.002|\n|bp_sys_mean                 |    1.002|     0.001|     2.315|   0.021|    1.000|     1.003|\n|demo_age_years              |    1.048|     0.001|    41.579|   0.000|    1.046|     1.050|\n|demo_raceNon-Hispanic Black |    2.011|     0.037|    18.646|   0.000|    1.869|     2.164|\n|demo_raceNon-Hispanic Asian |    3.678|     0.066|    19.721|   0.000|    3.229|     4.183|\n|demo_raceHispanic           |    2.433|     0.037|    24.235|   0.000|    2.264|     2.614|\n|demo_raceOther              |    2.438|     0.076|    11.674|   0.000|    2.096|     2.828|\n|demo_genderWomen            |    0.735|     0.030|   -10.445|   0.000|    0.693|     0.778|\n|cc_bmi25 to <30             |    1.809|     0.044|    13.334|   0.000|    1.659|     1.974|\n|cc_bmi30 to <35             |    3.234|     0.046|    25.317|   0.000|    2.954|     3.542|\n|cc_bmi35+                   |    5.873|     0.048|    36.877|   0.000|    5.347|     6.454|\n|cc_smokeFormer              |    1.063|     0.034|     1.831|   0.067|    0.996|     1.136|\n|cc_smokeCurrent             |    1.204|     0.040|     4.591|   0.000|    1.112|     1.302|\n|bp_med_useYes               |    2.490|     0.031|    29.043|   0.000|    2.341|     2.648|\n\n\n:::\n:::\n\n\n#### Model Explanation\n\nThe previous variables in this model continue to show the same patterns, although again, the effect of systolic blood pressure is again reduced due to a lower log odds ratio. Now, the p value seems to be much higher at 0.02 (which is still significant, but much less so). The demographic variables also have much the same pattern, although Non-Hispanic Asians seem to have a much higher odds ratio than in the previous model.\n\n#### Covariates\n\n**BMI**:\n\nIn this variable, the baseline reference level is bmi \\<25. In comparison, those with higher bmi have increased risk of having diabetes, with the risk increasing the higher the bmi becomes. For example, those with bmi from 25-30 have a 1.8 times higher risk, while those with a bmi of 35+ have a 5.8 times higher risk.\n\n**Smoking:**\n\nWith a baseline level of nonsmoking, former smokers may have about a 6% higher risk of diabetes. This may not be significant, however, given that the p value is only 0.067 and the odds ratio of 1 falls within the confidence interval. Current smokers, on the other hand, have about a 20% higher risk, this time with a much lower p value of 4\\*10\\^-6\n\n**Blood Pressure Medication Use**:\n\nCompared to those who do not use blood pressure medication, individuals who do have about a 2.5 times higher risk of experiencing diabetes.\n\n## Model Selection\n\nIt is possible to find an even better model by modifying which variables we include in our logistic regression model. We can achieve this using model selection, which will selectively add or subtract our explanatory variables from the model and evaluate its performance to choose the final best set of variables.\n\nExplanation of model selection and or AIC?\n\n#### Backwards Selection:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbackwards = step(full_diab_model_sys)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStart:  AIC=33082.55\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n                 Df Deviance   AIC\n<none>                 33055 33083\n- bp_sys_mean     1    33060 33086\n- cc_smoke        2    33076 33100\n- demo_gender     1    33164 33190\n- bp_med_use      1    33909 33935\n- demo_race       4    33930 33950\n- cc_bmi          3    34756 34778\n- demo_age_years  1    34931 34957\n```\n\n\n:::\n\n```{.r .cell-code}\nformula(backwards)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n```\n\n\n:::\n:::\n\n\nIt looks like the backwards selection model returned the same full model. In other words, removing variables does not improve its AIC, and therefore does not improve its performance.\n\n#### Forward Selection\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#start from a model without any predictors\nnothing <- glm(cc_diabetes ~ 1, data = clean_nhanes, family=binomial)\nsummary(nothing)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cc_diabetes ~ 1, family = binomial, data = clean_nhanes)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.85919    0.01282  -145.1   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 41278  on 52196  degrees of freedom\nAIC: 41280\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nforwards = step(nothing,\nscope=list(lower=formula(nothing),upper=formula(full_diab_model_sys)), direction=\"forward\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStart:  AIC=41279.9\ncc_diabetes ~ 1\n\n                 Df Deviance   AIC\n+ bp_med_use      1    37076 37080\n+ demo_age_years  1    37252 37256\n+ cc_bmi          3    39218 39226\n+ bp_sys_mean     1    39888 39892\n+ demo_race       4    40891 40901\n+ cc_smoke        2    40911 40917\n+ demo_gender     1    41242 41246\n<none>                 41278 41280\n\nStep:  AIC=37079.85\ncc_diabetes ~ bp_med_use\n\n                 Df Deviance   AIC\n+ demo_age_years  1    35675 35681\n+ cc_bmi          3    35907 35917\n+ demo_race       4    36597 36609\n+ bp_sys_mean     1    36788 36794\n+ cc_smoke        2    36968 36976\n+ demo_gender     1    37009 37015\n<none>                 37076 37080\n\nStep:  AIC=35681.48\ncc_diabetes ~ bp_med_use + demo_age_years\n\n              Df Deviance   AIC\n+ cc_bmi       3    34070 34082\n+ demo_race    4    34834 34848\n+ demo_gender  1    35624 35632\n+ bp_sys_mean  1    35654 35662\n+ cc_smoke     2    35670 35680\n<none>              35675 35681\n\nStep:  AIC=34082.43\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi\n\n              Df Deviance   AIC\n+ demo_race    4    33213 33233\n+ demo_gender  1    33963 33977\n+ bp_sys_mean  1    34050 34064\n+ cc_smoke     2    34054 34070\n<none>              34070 34082\n\nStep:  AIC=33232.52\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race\n\n              Df Deviance   AIC\n+ demo_gender  1    33081 33103\n+ cc_smoke     2    33170 33194\n+ bp_sys_mean  1    33208 33230\n<none>              33213 33233\n\nStep:  AIC=33102.89\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender\n\n              Df Deviance   AIC\n+ cc_smoke     2    33060 33086\n+ bp_sys_mean  1    33076 33100\n<none>              33081 33103\n\nStep:  AIC=33085.88\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke\n\n              Df Deviance   AIC\n+ bp_sys_mean  1    33055 33083\n<none>              33060 33086\n\nStep:  AIC=33082.55\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n```\n\n\n:::\n:::\n\n\nThe Forward Selection process again selects the full model.\n\n### Forward-Backward Selection\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbothways = step(nothing, list(lower=formula(nothing),upper=formula(full_diab_model_sys)),\ndirection=\"both\",trace=0)\nformula(bothways)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n```\n\n\n:::\n:::\n\n\nThe Forward-Backward algorithm also selects all of the variables.\n\nIn this case, the best model (as determined by the AIC) includes all of the variables (systolic blood pressure, age, race, sex, smoking status, BMI, and medication use). In other situations, it may have returned just a few of these variables, but for this example, we can proceed with the full model.\n\n# Model Diagnostics\n\nThe next step will be to evaluate the model to determine its \\_\\_\\_\\_\\_.\n\n## Likelihood Ratio Test\n\n## Model Fit\n\n## Calibration Plot\n\n## Homsler-Lemeshow Test\n\n## ROC Curve\n\n## Residuals Histogram\n\n## Ignore///\n\nI followed a guide online but I don't really know what this is doing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_nhanes %>% \n  mutate(comp_res = coef(full_diab_model_sys)[\"demo_age_years\"]*demo_age_years + residuals(full_diab_model_sys, type = \"working\")) %>% \n  ggplot(aes(x = demo_age_years, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](initial_modeling_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nclean_nhanes %>% \n  mutate(comp_res = coef(full_diab_model_sys)[\"bp_sys_mean\"]*bp_sys_mean + residuals(full_diab_model_sys, type = \"working\")) %>% \n  ggplot(aes(x = bp_sys_mean, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](initial_modeling_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\nTest for Multicollinearity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(full_diab_model_sys)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                   GVIF Df GVIF^(1/(2*Df))\nbp_sys_mean    1.169212  1        1.081301\ndemo_age_years 1.528167  1        1.236191\ndemo_race      1.207663  4        1.023866\ndemo_gender    1.091056  1        1.044536\ncc_bmi         1.182024  3        1.028263\ncc_smoke       1.173951  2        1.040908\nbp_med_use     1.235766  1        1.111650\n```\n\n\n:::\n:::\n\n\nOutliers\n\n\n::: {.cell}\n\n```{.r .cell-code}\noutlier_nhanes <-\n  clean_nhanes %>% \n  mutate(dffits = dffits(full_diab_model_sys))\n\noutlier_nhanes %>% \n  mutate(obs_number = row_number(),\n         large = ifelse(abs(dffits) > 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)),\n                        \"red\", \"black\")) %>% \n  ggplot(aes(obs_number, dffits, color = large)) +\n  geom_point() + \n  geom_hline(yintercept = c(-1,1) * 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)), color = \"red\") +\n  scale_color_identity()\n```\n\n::: {.cell-output-display}\n![](initial_modeling_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "initial_modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}