# Model Diagnostics

```{r message = FALSE, warning= FALSE}
library(dplyr)
library(tidyverse)
library(tibble)
library(ggplot2)
library(lmtest)
# library(caret)
# library(glmtoolbox) 
# library(predtools)
# library(pROC)
#using data specified in this github repository:
install_github("jhs-hwg/cardioStatsUSA")
library(cardioStatsUSA)
```

```{r}
null_model <- glm(cc_diabetes ~ 1, data = clean_nhanes, family=binomial)

simple_diab_model_sys <- glm(cc_diabetes ~ bp_sys_mean, data = nhanes_data, family = binomial)

full_diab_model_sys <- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender+ cc_bmi + cc_smoke + bp_med_use, data = clean_nhanes, family = binomial)
```

The next step will be to evaluate the model to determine its \_\_\_\_\_.

## Likelihood Ratio Test

The likelihood ratio test involves comparing whether two models are significantly different. Here, we will compare our full model with the null model (no covariates):

The null hypothesis is that there is no significant difference between the null model $H_0$ and the full model $H_1$.

The test compares the predicted likelihood of an observed outcome under the null model vs the predicted likelihood of the outcome under the model. In this case, the outcome will be diabetes. The test statistic will be calculated $\lambda = -2 log(\frac{L(H_0)}{L(H_1)})$, where L denotes the likelihood of diabetes evaluated under each model. If the likelihood is much higher in the full model than in the null model, it means that additional parameters improve the model fit. As a result, $\lambda$ and its corresponding p value will be a much smaller, providing stronger evidence that we may need to reject the null hypothesis.

```{r}
lrtest(full_diab_model_sys, null_model)
```

As expected, we can see that the full model is significant compared to the null hypothesis. We can also compare it to the simple model which uses only systolic blood pressure as a variable.

```{r}
lrtest(full_diab_model_sys, simple_diab_model_sys)
```

## Model Fit

## Calibration Plot

## Homsler-Lemeshow Test

## ROC Curve

## Residuals Histogram

## Ignore///

I followed a guide online but I don't really know what this is doing:

```{r}
clean_nhanes %>% 
  mutate(comp_res = coef(full_diab_model_sys)["demo_age_years"]*demo_age_years + residuals(full_diab_model_sys, type = "working")) %>% 
  ggplot(aes(x = demo_age_years, y = comp_res)) +
  geom_point() +
  geom_smooth(color = "red", method = "lm", linetype = 2, se = F) +
  geom_smooth(se = F)

clean_nhanes %>% 
  mutate(comp_res = coef(full_diab_model_sys)["bp_sys_mean"]*bp_sys_mean + residuals(full_diab_model_sys, type = "working")) %>% 
  ggplot(aes(x = bp_sys_mean, y = comp_res)) +
  geom_point() +
  geom_smooth(color = "red", method = "lm", linetype = 2, se = F) +
  geom_smooth(se = F)
```

Test for Multicollinearity

```{r}
vif(full_diab_model_sys)
```

Outliers

```{r}
outlier_nhanes <-
  clean_nhanes %>% 
  mutate(dffits = dffits(full_diab_model_sys))

outlier_nhanes %>% 
  mutate(obs_number = row_number(),
         large = ifelse(abs(dffits) > 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)),
                        "red", "black")) %>% 
  ggplot(aes(obs_number, dffits, color = large)) +
  geom_point() + 
  geom_hline(yintercept = c(-1,1) * 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)), color = "red") +
  scale_color_identity()
```
