[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Measurement Error",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Preparing the NHANES Data",
    "section": "",
    "text": "2.1 Identify Data Tables of Interest\nLook at the diet, examination, and demographic info for the 2011-2012 cycle of NHANES\n#Note DR1TOT_G and DR2TOT_G\ndatatable(nhanesTables('DIET', 2012))\n\n\n\n\n#Note BPX_G: Blood Pressure (may also need BMX_G/body measures)\ndatatable(nhanesTables('EXAM', 2012))\n\n\n\n\n#Note DEMO_G: Demographic Info (the only table)\ndatatable(nhanesTables('DEMO', 2012))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preparing the NHANES Data</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "summary.html#identify-required-data-tables",
    "href": "summary.html#identify-required-data-tables",
    "title": "2  Download NHANES Data",
    "section": "",
    "text": "Dietary Measure\nVariable Name\n\n\n\n\nSodium (mg)\nDR1TSODI\n\n\nPotassium (mg)\nDR1TPOTA\n\n\nCalcium (mg)\nDR1TCALC\n\n\nMagnesium (mg)\nDR1TMAGN\n\n\nProtein (gm)\nDR1TPROT\n\n\nAlcohol (gm)\nDR1TALCO\n\n\nEnergy (kcal)\nDR1TKCAL",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Download NHANES Data</span>"
    ]
  },
  {
    "objectID": "summary.html#merge-data-together",
    "href": "summary.html#merge-data-together",
    "title": "2  Preparing the NHANES Data",
    "section": "2.3 Merge Data Together",
    "text": "2.3 Merge Data Together\nTake the diet data: there are two separate tables for measurements taken on different days. We can combine this using the merge() function.\n\nd1_diet_d &lt;- nhanes('DR1TOT_G')\nd2_diet_d &lt;- nhanes('DR2TOT_G')\n\n#concatenate the diet data for two days together\ndiet_d &lt;- merge(d1_diet_d, d2_diet_d, )\ndatatable(head(diet_d))\n\n\n\n\n\nFor this example, we take only the day 1 diet measures to create the “nutrients” dataframe:\n\nselect_cols &lt;- c('SEQN', 'DR1TSODI', 'DR1TPOTA', 'DR1TCALC', 'DR1TMAGN', 'DR1TPROT', 'DR1TALCO', 'DR1TKCAL')\nnutrients &lt;- diet_d[, select_cols]\ndatatable(head(nutrients))\n\n\n\n\n\n\ndemo &lt;- nhanes('DEMO_G')\ndatatable(head(demo))\n\n\n\n\n\nSimliarly, we select the systolic and diastolic blood pressure measures from the blood pressure table ‘BPX_G’:\n\nBP_cols &lt;- c('SEQN', 'BPXSY1','BPXDI1')\nBP_data &lt;- nhanes('BPX_G')[, BP_cols]\ndatatable(head(BP_data))\n\n\n\n\n\nCombine all tables together:\n\ntotal_df &lt;- merge(nutrients, BP_data, by = 'SEQN')\n#get rid of any column with NA\ntotal_df &lt;- na.omit(total_df)\n\ntotal_df &lt;- merge(total_df, demo)\ndatatable(head(total_df))\n\n\n\n\n\nThis one uses all the variables (but have to adjust for collinearity)\n\nall_v_diastolic_model = lm(formula = BPXDI1 ~ DR1TSODI + DR1TPOTA + DR1TCALC + DR1TMAGN + DR1TPROT + DR1TALCO + DR1TKCAL, data = total_df)\n\nsummary(all_v_diastolic_model)\n\n\nCall:\nlm(formula = BPXDI1 ~ DR1TSODI + DR1TPOTA + DR1TCALC + DR1TMAGN + \n    DR1TPROT + DR1TALCO + DR1TKCAL, data = total_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-73.401  -7.930   0.942   9.150  54.845 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 64.4747517  0.4821333 133.728  &lt; 2e-16 ***\nDR1TSODI     0.0007118  0.0001956   3.639 0.000276 ***\nDR1TPOTA     0.0005132  0.0003053   1.681 0.092828 .  \nDR1TCALC    -0.0033001  0.0004268  -7.732 1.22e-14 ***\nDR1TMAGN     0.0119998  0.0024313   4.936 8.20e-07 ***\nDR1TPROT     0.0182241  0.0089809   2.029 0.042480 *  \nDR1TALCO     0.0639439  0.0080577   7.936 2.46e-15 ***\nDR1TKCAL    -0.0017357  0.0003982  -4.359 1.33e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.9 on 6244 degrees of freedom\nMultiple R-squared:  0.03444,   Adjusted R-squared:  0.03335 \nF-statistic: 31.81 on 7 and 6244 DF,  p-value: &lt; 2.2e-16\n\n\nNote for later:\nCan use the save(dataframe, “file_name.Rdata”) function and then in another qmd file load using load(“file_name.Rdata”)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preparing the NHANES Data</span>"
    ]
  },
  {
    "objectID": "summary.html#identify-variables-of-interest",
    "href": "summary.html#identify-variables-of-interest",
    "title": "2  Preparing the NHANES Data",
    "section": "2.2 Identify Variables of Interest",
    "text": "2.2 Identify Variables of Interest\nNow that we have identified the tables we need, first take a look at the required variables in the table of dietary information:\n\ndatatable(nhanesTableVars('DIET', 'DR1TOT_G'))\n\n\n\n\n\nWe can then identify the variables corresponding to each dietary measure of interest:\n\n\n\nDietary Measure\nVariable Name\n\n\n\n\nSodium (mg)\nDR1TSODI\n\n\nPotassium (mg)\nDR1TPOTA\n\n\nCalcium (mg)\nDR1TCALC\n\n\nMagnesium (mg)\nDR1TMAGN\n\n\nProtein (gm)\nDR1TPROT\n\n\nAlcohol (gm)\nDR1TALCO\n\n\nEnergy (kcal)\nDR1TKCAL\n\n\n\nWe will also need to include SEQN, which corresponds to to the respondent ID number. This will be the column used for combining the different tables together.\nLet’s next look at the variables in the blood pressure table:\n\ndatatable(nhanesTableVars('EXAM', 'BPX_G'))\n\n\n\n\n\nWe are interested in BPXSY1 and BPXDI1 for systolic and diastolic blood pressure, respectively",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preparing the NHANES Data</span>"
    ]
  },
  {
    "objectID": "cleaning.html",
    "href": "cleaning.html",
    "title": "3  Data Examination",
    "section": "",
    "text": "3.1 Descriptive Graphs",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "cleaning.html#descriptive-graphs",
    "href": "cleaning.html#descriptive-graphs",
    "title": "3  Data Examination",
    "section": "",
    "text": "3.1.1 Demographic Histograms (Blood Pressure vs Demographic Variables)\nSystolic vs Age and Systolic vs Gender are very clear\n\nnhanes_data %&gt;% drop_na(bp_dia_mean) %&gt;%\n  ggplot(aes(x=bp_dia_mean, color=demo_age_cat)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Diastolic) with Age\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_age_cat)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Age\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_race)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Race\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_gender)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Gender\")\n\n\n\n\n\n\n\nnhanes_female &lt;- nhanes_data[nhanes_data$demo_gender == \"Women\", ]\nnhanes_female %&gt;% drop_na(demo_pregnant) %&gt;% \n    ggplot(aes(x=bp_sys_mean, color=demo_pregnant)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Pregnancy (Men Excluded)\")\n\nWarning: Removed 1678 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_female %&gt;% drop_na(demo_pregnant) %&gt;% \n    ggplot(aes(x=bp_dia_mean, color=demo_pregnant)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Diastolic) with Pregnancy (Men Excluded)\")\n\nWarning: Removed 1809 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Comorbidities Box Plots (Blood Pressure vs Covariate)\n\nnhanes_data %&gt;% drop_na(cc_smoke) %&gt;%\n  ggplot(aes(x=cc_smoke, y=bp_sys_mean, fill=cc_smoke)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Smoking Status\") +\n    xlab(\"\")\n\nWarning: Removed 3111 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_bmi) %&gt;%\n  ggplot(aes(x=cc_bmi, y=bp_sys_mean, fill=cc_bmi)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS BMI Status\") +\n    xlab(\"\")\n\nWarning: Removed 2867 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_cvd_chd) %&gt;%\n  ggplot(aes(x=cc_cvd_chd, y=bp_sys_mean, fill=cc_cvd_chd)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Chronic Heart Disease Status\") +\n    xlab(\"\")\n\nWarning: Removed 3049 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_ckd) %&gt;%\n  ggplot(aes(x=cc_ckd, y=bp_sys_mean, fill=cc_ckd)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Chronic Kidney Disease Status\") +\n    xlab(\"\")\n\nWarning: Removed 3265 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n3.1.3 Comorbidities Histograms (Blood Pressure vs Covariate)\n\nnhanes_data %&gt;% drop_na(cc_smoke) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_smoke)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins= 80) +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    ggtitle(\"Blood Pressure with Smoking Histogram\")\n\nWarning: Removed 3111 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_bmi) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_bmi)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with BMI Histogram\")\n\nWarning: Removed 2867 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_cvd_stroke) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_cvd_stroke)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with Stroke Histogram\")\n\nWarning: Removed 3050 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_diabetes) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_diabetes)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with Diabetes Histogram\")\n\nWarning: Removed 3265 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n3.1.4 Chi Squared Tests (Testing difference between covariates and hypertension status)\nI realize this isn’t very useful (of course the result will be significant) but I left them in anyways\n\n#Body Mass Index\nnhanes_bmi_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_bmi) %&gt;% drop_na(cc_bmi)\nnhanes_bmi_df &lt;- table(nhanes_bmi_df$htn_accaha, nhanes_bmi_df$cc_bmi)\nchisq.test(nhanes_bmi_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_df\nX-squared = 2576, df = 3, p-value &lt; 2.2e-16\n\n#Smoking \nnhanes_smoke_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_smoke) %&gt;% drop_na(cc_smoke)\nnhanes_smoke_df &lt;- table(nhanes_smoke_df$htn_accaha, nhanes_smoke_df$cc_smoke)\nchisq.test(nhanes_smoke_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_df\nX-squared = 991.83, df = 2, p-value &lt; 2.2e-16\n\n#Chronic Heart Disease\nnhanes_chd_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_cvd_chd) %&gt;% drop_na(cc_cvd_chd)\nnhanes_chd_df &lt;- table(nhanes_chd_df$htn_accaha, nhanes_chd_df$cc_cvd_chd)\nchisq.test(nhanes_chd_df)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_chd_df\nX-squared = 1357.9, df = 1, p-value &lt; 2.2e-16\n\n#Chronic Kidney Disease\nnhanes_ckd_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_ckd) %&gt;% drop_na(cc_ckd)\nnhanes_ckd_df &lt;- table(nhanes_ckd_df$htn_accaha, nhanes_ckd_df$cc_ckd)\nchisq.test(nhanes_ckd_df)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_ckd_df\nX-squared = 3702.1, df = 1, p-value &lt; 2.2e-16\n\n\n\n\n3.1.5 Two Sample T Tests\n(Testing the Difference in blood pressure between comorbidities)\nShould I extend to demographic data?\n\n#Don't know if this is the idea but:\nnhanes_dia_df &lt;- nhanes_data %&gt;% select(htn_accaha, bp_dia_mean) %&gt;% drop_na(bp_dia_mean)\nt_test &lt;- t.test(bp_dia_mean ~ htn_accaha, data=nhanes_dia_df)\nt_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_dia_mean by htn_accaha\nt = -96.487, df = 45747, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -9.443644 -9.067610\nsample estimates:\n mean in group No mean in group Yes \n         65.87311          75.12873 \n\n#Smoking T Test (Excludes Former):\nnhanes_sys_smoke &lt;- nhanes_data[nhanes_data$cc_smoke != \"Former\", ] %&gt;% select(cc_smoke, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_smoke)\nsmoke_test &lt;- t.test(bp_sys_mean ~ cc_smoke, data = nhanes_sys_smoke)\nsmoke_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_smoke\nt = 0.85479, df = 20379, p-value = 0.3927\nalternative hypothesis: true difference in means between group Never and group Current is not equal to 0\n95 percent confidence interval:\n -0.2343734  0.5968840\nsample estimates:\n  mean in group Never mean in group Current \n             123.6788              123.4975 \n\n#BMI T Test (Compares &lt;25 and 35+):\nnhanes_sys_bmi &lt;- nhanes_data[nhanes_data$cc_bmi %in% c(\"&lt;25\", \"35+\"), ] %&gt;% select(cc_bmi, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_bmi)\nbmi_test &lt;- t.test(bp_sys_mean ~ cc_bmi, data = nhanes_sys_bmi)\nbmi_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_bmi\nt = -26.614, df = 18857, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group &lt;25 and group 35+ is not equal to 0\n95 percent confidence interval:\n -6.963786 -6.008393\nsample estimates:\nmean in group &lt;25 mean in group 35+ \n          120.332           126.818 \n\n#Diabetes T Test:\nnhanes_sys_diabetes &lt;- nhanes_data %&gt;% select(cc_diabetes, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_diabetes)\ndiabetes_test &lt;- t.test(bp_sys_mean ~ cc_diabetes, data = nhanes_sys_diabetes)\ndiabetes_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_diabetes\nt = -40.314, df = 9221.3, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -10.84351  -9.83791\nsample estimates:\n mean in group No mean in group Yes \n         122.7845          133.1252",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "cleaning.html#simple-diabetes-modeling",
    "href": "cleaning.html#simple-diabetes-modeling",
    "title": "3  Data Examination",
    "section": "3.2 Simple Diabetes Modeling",
    "text": "3.2 Simple Diabetes Modeling\nWe are choosing Diabetes as the co-morbidity for modeling. We will try to predict the occurrence of diabetes as a function of blood pressure as well as other covariates.\nThe most basic model possible is a simple logistic regression model predicting diabetes status based on blood pressure:\n\nsimple_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.9404827  0.0770324  -64.14   &lt;2e-16 ***\nbp_sys_mean  0.0238141  0.0005811   40.98   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 41987  on 56532  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 41991\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0071511\n0.0770324\n-64.13512\n0\n0.0061477\n0.0083151\n\n\nbp_sys_mean\n1.0240999\n0.0005811\n40.98151\n0\n1.0229344\n1.0252673\n\n\n\n\nsimple_diab_model_dia &lt;- glm(cc_diabetes ~ bp_dia_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_dia)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_dia_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.652673   0.073728 -22.416  &lt; 2e-16 ***\nbp_dia_mean -0.003651   0.001039  -3.514 0.000441 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43309  on 56285  degrees of freedom\nResidual deviance: 43297  on 56284  degrees of freedom\n  (3513 observations deleted due to missingness)\nAIC: 43301\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_dia, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.1915372\n0.0737285\n-22.415661\n0.0000000\n0.1657332\n0.2212722\n\n\nbp_dia_mean\n0.9963553\n0.0010390\n-3.514294\n0.0004409\n0.9943280\n0.9983860\n\n\n\n\n\n\n3.2.0.1 Model Explanation:\nFor the logistic regression using systolic blood pressure, we can see that the odds ratio beta parameter is 1.024. This implies that a higher systolic blood pressure corresponds to increased chances of observing diabetes.\nA more exact interpretation would be that: for one additional unit increase in systolic blood pressure, the estimated risk of having diabetes increases by 2.4%.\nThis value may not seem extremely high, yet it still has a p value evaluated to be 0 by R. We can see that the 95% confidence interval of this parameter ranges between 1.0229 and 1.0253, meaning that the model predicts that the true relationship falls within this interval with a 95% certainty, since the true value of the parameter is most likely within this interval. (Not sure what wording is best here)\nThe opposite is true with diastolic blood pressure: the beta parameter is 0.996, implying that higher diastolic blood pressure corresponds to a lower chance of observing diabetes. For an additional unit increase in diastolic blood pressure, the estimated odds of having diabetes decreases by 0.04%.\nNote: systolic blood pressure is a better predictor of cardiovascular disease, so I chose to consider systolic rather than diastolic in future models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "cleaning.html#demographic-model",
    "href": "cleaning.html#demographic-model",
    "title": "3  Data Examination",
    "section": "3.3 Demographic Model",
    "text": "3.3 Demographic Model\nNext, we build a model including the demographic variables as well. This will hopefully provide a more accurate model, since it will have access to the further information in order to make predictions.\n\ndemo_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender,data = nhanes_data, family = binomial)\n\nsummary (demo_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender, family = binomial, data = nhanes_data)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -5.6927561  0.0885174 -64.312  &lt; 2e-16 ***\nbp_sys_mean                  0.0037581  0.0006792   5.533 3.14e-08 ***\ndemo_age_years               0.0529545  0.0009161  57.806  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.9034242  0.0350353  25.786  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  0.8093210  0.0606852  13.336  &lt; 2e-16 ***\ndemo_raceHispanic            0.8592775  0.0343392  25.023  &lt; 2e-16 ***\ndemo_raceOther               0.7478892  0.0718834  10.404  &lt; 2e-16 ***\ndemo_genderWomen            -0.1547613  0.0265581  -5.827 5.63e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 37780  on 56526  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 37796\n\nNumber of Fisher Scoring iterations: 5\n\nknitr::kable(tidy(demo_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0033703\n0.0885174\n-64.312318\n0\n0.0028326\n0.0040077\n\n\nbp_sys_mean\n1.0037652\n0.0006792\n5.533450\n0\n1.0024283\n1.0051008\n\n\ndemo_age_years\n1.0543817\n0.0009161\n57.805744\n0\n1.0524962\n1.0562830\n\n\ndemo_raceNon-Hispanic Black\n2.4680396\n0.0350353\n25.786107\n0\n2.3042427\n2.6434926\n\n\ndemo_raceNon-Hispanic Asian\n2.2463822\n0.0606852\n13.336382\n0\n1.9925692\n2.5278493\n\n\ndemo_raceHispanic\n2.3614540\n0.0343392\n25.023206\n0\n2.2077734\n2.5259187\n\n\ndemo_raceOther\n2.1125361\n0.0718834\n10.404206\n0\n1.8320999\n2.4286788\n\n\ndemo_genderWomen\n0.8566196\n0.0265581\n-5.827267\n0\n0.8131556\n0.9023806\n\n\n\n\n\n\n3.3.0.1 Model Explanation\nIn this model, we can still see a slight upwards trend with systolic blood pressure, although it is a bit weaker (1.024 &gt; 1.003). With this parameter, the estimated odds of having diabetes increases only by 0.3%. Although the effect is smaller, we can see that the confidence interval is between 1.0024 and 1.0051, which does not include 1. So, although small, the positive relationship is most likely significant.\n\n\n3.3.0.2 Demographics\nAge:\nThe model also tells us that age is positively correlated with the observation of diabetes. With a log odds ratio of 1.054, it seems that every year increases the risk of diabetes occurrence by 5.4%.\nRace:\nWith race, the “reference group” is Non-Hispanic White. The log odds ratio here compares the other variables to the baseline reference group. We can see that, in comparison to this group, all other races have significantly higher odds of diabetes. For example, the Hispanic population’s risk of diabetes occurrence is 2.36 times higher than the Non-Hispanic White population.\nGender:\nWith this variable, the reference group is men. We can see that women have a lower odds of having diabetes compared to men. Specifically, the odds of diabetes in women is about 85.6% of the risk in men.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "cleaning.html#full-model",
    "href": "cleaning.html#full-model",
    "title": "3  Data Examination",
    "section": "3.4 Full Model",
    "text": "3.4 Full Model\nLastly, we want to create a model including confounding variables. To achieve this, we must first determine which other variables are confounding, meaning they have significant associations with diabetes.\nWe can achieve this by using chi squared test, which compares whether or not the observed ratios of diabetes and confounding variables matches the ratios expected by random chance. If the chi squared test determines significance, then diabetes and the other variables commonly occur together and therefore are confounding.\n\n3.4.0.1 Perform Chi Squared Tests:\n\n#Testing for BMI\nnhanes_bmi_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_bmi) %&gt;% drop_na(cc_bmi) %&gt;% drop_na(cc_diabetes)\nnhanes_bmi_diab &lt;- table(nhanes_bmi_diab)\nnhanes_bmi_diab\n\n           cc_bmi\ncc_diabetes   &lt;25 25 to &lt;30 30 to &lt;35   35+\n        No  17390     16913      9476  6965\n        Yes   974      2173      2056  2274\n\nchisq.test(nhanes_bmi_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_df\nX-squared = 2576, df = 3, p-value &lt; 2.2e-16\n\n#Testing for Smoking\nnhanes_smoke_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_smoke) %&gt;% drop_na(cc_smoke) %&gt;% drop_na(cc_diabetes)\nnhanes_smoke_diab &lt;- table(nhanes_smoke_diab)\nnhanes_smoke_diab\n\n           cc_smoke\ncc_diabetes Never Former Current\n        No  27414  11107   10366\n        Yes  3917   2587    1249\n\nchisq.test(nhanes_smoke_diab)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_diab\nX-squared = 435.81, df = 2, p-value &lt; 2.2e-16\n\n#Testing for Hypertensive Medication use\nnhanes_med_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, bp_med_use) %&gt;% drop_na(bp_med_use) %&gt;% drop_na(cc_diabetes)\nnhanes_med_diab &lt;- table(nhanes_med_diab)\nnhanes_med_diab\n\n           bp_med_use\ncc_diabetes    No   Yes\n        No  41679 10079\n        Yes  3138  4611\n\nchisq.test(nhanes_med_diab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_med_diab\nX-squared = 5807.1, df = 1, p-value &lt; 2.2e-16\n\n\nAfter this analysis, we can see that all three variables, BMI, Smoking, and Medication Use, are all confounding. We can include all of them in the next model, in addition to systolic blood pressure and the demographic variables:\n\n#to prevent errors down the line, exclude the rows with na:\nused_vars = c('cc_diabetes', 'bp_sys_mean', 'demo_age_years', 'demo_race', 'demo_gender', 'cc_bmi', 'cc_smoke', 'bp_med_use')\nclean_nhanes &lt;- nhanes_data[complete.cases(nhanes_data[,..used_vars]), ]\n\nfull_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender+ cc_bmi + cc_smoke + bp_med_use, data = clean_nhanes, family = binomial)\n\nsummary(full_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender + cc_bmi + cc_smoke + bp_med_use, family = binomial, \n    data = clean_nhanes)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -6.3003463  0.1112295 -56.643  &lt; 2e-16 ***\nbp_sys_mean                  0.0017066  0.0007373   2.315   0.0206 *  \ndemo_age_years               0.0470354  0.0011312  41.579  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.6987360  0.0374745  18.646  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  1.3022903  0.0660355  19.721  &lt; 2e-16 ***\ndemo_raceHispanic            0.8889260  0.0366792  24.235  &lt; 2e-16 ***\ndemo_raceOther               0.8913458  0.0763522  11.674  &lt; 2e-16 ***\ndemo_genderWomen            -0.3082492  0.0295124 -10.445  &lt; 2e-16 ***\ncc_bmi25 to &lt;30              0.5927344  0.0444524  13.334  &lt; 2e-16 ***\ncc_bmi30 to &lt;35              1.1736075  0.0463565  25.317  &lt; 2e-16 ***\ncc_bmi35+                    1.7702868  0.0480051  36.877  &lt; 2e-16 ***\ncc_smokeFormer               0.0614704  0.0335729   1.831   0.0671 .  \ncc_smokeCurrent              0.1853436  0.0403687   4.591 4.41e-06 ***\nbp_med_useYes                0.9121351  0.0314064  29.043  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 33055  on 52183  degrees of freedom\nAIC: 33083\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(full_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0018357\n0.1112295\n-56.642782\n0.0000000\n0.0014752\n0.0022815\n\n\nbp_sys_mean\n1.0017080\n0.0007373\n2.314675\n0.0206307\n1.0002594\n1.0031545\n\n\ndemo_age_years\n1.0481591\n0.0011312\n41.579121\n0.0000000\n1.0458438\n1.0504919\n\n\ndemo_raceNon-Hispanic Black\n2.0112090\n0.0374745\n18.645645\n0.0000000\n1.8687584\n2.1644762\n\n\ndemo_raceNon-Hispanic Asian\n3.6777100\n0.0660355\n19.721057\n0.0000000\n3.2286139\n4.1827136\n\n\ndemo_raceHispanic\n2.4325157\n0.0366792\n24.235131\n0.0000000\n2.2638469\n2.6139232\n\n\ndemo_raceOther\n2.4384090\n0.0763522\n11.674130\n0.0000000\n2.0964731\n2.8282006\n\n\ndemo_genderWomen\n0.7347322\n0.0295124\n-10.444726\n0.0000000\n0.6934113\n0.7784570\n\n\ncc_bmi25 to &lt;30\n1.8089279\n0.0444524\n13.334145\n0.0000000\n1.6585185\n1.9742572\n\n\ncc_bmi30 to &lt;35\n3.2336368\n0.0463565\n25.316997\n0.0000000\n2.9536973\n3.5423428\n\n\ncc_bmi35+\n5.8725376\n0.0480051\n36.877031\n0.0000000\n5.3470462\n6.4542286\n\n\ncc_smokeFormer\n1.0633990\n0.0335729\n1.830951\n0.0671079\n0.9956021\n1.1356446\n\n\ncc_smokeCurrent\n1.2036319\n0.0403687\n4.591266\n0.0000044\n1.1117990\n1.3024331\n\n\nbp_med_useYes\n2.4896325\n0.0314064\n29.042966\n0.0000000\n2.3411270\n2.6478476\n\n\n\n\n\n\n\n3.4.0.2 Model Explanation\nThe previous variables in this model continue to show the same patterns, although again, the effect of systolic blood pressure is again reduced due to a lower log odds ratio. Now, the p value seems to be much higher at 0.02 (which is still significant, but much less so). The demographic variables also have much the same pattern, although Non-Hispanic Asians seem to have a much higher odds ratio than in the previous model.\n\n\n3.4.0.3 Covariates\nBMI:\nIn this variable, the baseline reference level is bmi &lt;25. In comparison, those with higher bmi have increased risk of having diabetes, with the risk increasing the higher the bmi becomes. For example, those with bmi from 25-30 have a 1.8 times higher risk, while those with a bmi of 35+ have a 5.8 times higher risk.\nSmoking:\nWith a baseline level of nonsmoking, former smokers may have about a 6% higher risk of diabetes. This may not be significant, however, given that the p value is only 0.067 and the odds ratio of 1 falls within the confidence interval. Current smokers, on the other hand, have about a 20% higher risk, this time with a much lower p value of 4*10^-6\nBlood Pressure Medication Use:\nCompared to those who do not use blood pressure medication, individuals who do have about a 2.5 times higher risk of experiencing diabetes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "cleaning.html#model-selection",
    "href": "cleaning.html#model-selection",
    "title": "3  Data Examination",
    "section": "3.5 Model Selection",
    "text": "3.5 Model Selection\nIt is possible to find an even better model by modifying which variables we include in our logistic regression model. We can achieve this using model selection, which will selectively add or subtract our explanatory variables from the model and evaluate its performance to choose the final best set of variables.\nExplanation of model selection and or AIC?\n\n3.5.0.1 Backwards Selection:\n\nbackwards = step(full_diab_model_sys)\n\nStart:  AIC=33082.55\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n                 Df Deviance   AIC\n&lt;none&gt;                 33055 33083\n- bp_sys_mean     1    33060 33086\n- cc_smoke        2    33076 33100\n- demo_gender     1    33164 33190\n- bp_med_use      1    33909 33935\n- demo_race       4    33930 33950\n- cc_bmi          3    34756 34778\n- demo_age_years  1    34931 34957\n\nformula(backwards)\n\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n\nIt looks like the backwards selection model returned the same full model. In other words, removing variables does not improve its AIC, and therefore does not improve its performance.\n\n\n3.5.0.2 Forward Selection\n\n#start from a model without any predictors\nnothing &lt;- glm(cc_diabetes ~ 1, data = clean_nhanes, family=binomial)\nsummary(nothing)\n\n\nCall:\nglm(formula = cc_diabetes ~ 1, family = binomial, data = clean_nhanes)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.85919    0.01282  -145.1   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 41278  on 52196  degrees of freedom\nAIC: 41280\n\nNumber of Fisher Scoring iterations: 4\n\nforwards = step(nothing,\nscope=list(lower=formula(nothing),upper=formula(full_diab_model_sys)), direction=\"forward\")\n\nStart:  AIC=41279.9\ncc_diabetes ~ 1\n\n                 Df Deviance   AIC\n+ bp_med_use      1    37076 37080\n+ demo_age_years  1    37252 37256\n+ cc_bmi          3    39218 39226\n+ bp_sys_mean     1    39888 39892\n+ demo_race       4    40891 40901\n+ cc_smoke        2    40911 40917\n+ demo_gender     1    41242 41246\n&lt;none&gt;                 41278 41280\n\nStep:  AIC=37079.85\ncc_diabetes ~ bp_med_use\n\n                 Df Deviance   AIC\n+ demo_age_years  1    35675 35681\n+ cc_bmi          3    35907 35917\n+ demo_race       4    36597 36609\n+ bp_sys_mean     1    36788 36794\n+ cc_smoke        2    36968 36976\n+ demo_gender     1    37009 37015\n&lt;none&gt;                 37076 37080\n\nStep:  AIC=35681.48\ncc_diabetes ~ bp_med_use + demo_age_years\n\n              Df Deviance   AIC\n+ cc_bmi       3    34070 34082\n+ demo_race    4    34834 34848\n+ demo_gender  1    35624 35632\n+ bp_sys_mean  1    35654 35662\n+ cc_smoke     2    35670 35680\n&lt;none&gt;              35675 35681\n\nStep:  AIC=34082.43\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi\n\n              Df Deviance   AIC\n+ demo_race    4    33213 33233\n+ demo_gender  1    33963 33977\n+ bp_sys_mean  1    34050 34064\n+ cc_smoke     2    34054 34070\n&lt;none&gt;              34070 34082\n\nStep:  AIC=33232.52\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race\n\n              Df Deviance   AIC\n+ demo_gender  1    33081 33103\n+ cc_smoke     2    33170 33194\n+ bp_sys_mean  1    33208 33230\n&lt;none&gt;              33213 33233\n\nStep:  AIC=33102.89\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender\n\n              Df Deviance   AIC\n+ cc_smoke     2    33060 33086\n+ bp_sys_mean  1    33076 33100\n&lt;none&gt;              33081 33103\n\nStep:  AIC=33085.88\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke\n\n              Df Deviance   AIC\n+ bp_sys_mean  1    33055 33083\n&lt;none&gt;              33060 33086\n\nStep:  AIC=33082.55\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward Selection process again selects the full model.\n\nbothways = step(nothing, list(lower=formula(nothing),upper=formula(full_diab_model_sys)),\ndirection=\"both\",trace=0)\nformula(bothways)\n\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward-Backward algorithm also selects all of the variables",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "cleaning.html#model-diagnostics",
    "href": "cleaning.html#model-diagnostics",
    "title": "3  Data Examination",
    "section": "3.6 Model Diagnostics",
    "text": "3.6 Model Diagnostics\nI followed a guide online but I don’t really know what this is doing:\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"demo_age_years\"]*demo_age_years + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = demo_age_years, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"bp_sys_mean\"]*bp_sys_mean + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = bp_sys_mean, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nTest for Multicollinearity\n\nvif(full_diab_model_sys)\n\n                   GVIF Df GVIF^(1/(2*Df))\nbp_sys_mean    1.169212  1        1.081301\ndemo_age_years 1.528167  1        1.236191\ndemo_race      1.207663  4        1.023866\ndemo_gender    1.091056  1        1.044536\ncc_bmi         1.182024  3        1.028263\ncc_smoke       1.173951  2        1.040908\nbp_med_use     1.235766  1        1.111650\n\n\nOutliers\n\noutlier_nhanes &lt;-\n  clean_nhanes %&gt;% \n  mutate(dffits = dffits(full_diab_model_sys))\n\noutlier_nhanes %&gt;% \n  mutate(obs_number = row_number(),\n         large = ifelse(abs(dffits) &gt; 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)),\n                        \"red\", \"black\")) %&gt;% \n  ggplot(aes(obs_number, dffits, color = large)) +\n  geom_point() + \n  geom_hline(yintercept = c(-1,1) * 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)), color = \"red\") +\n  scale_color_identity()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "3  Data Examination",
    "section": "",
    "text": "3.1 Descriptive Graphs",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "visualization.html#descriptive-graphs",
    "href": "visualization.html#descriptive-graphs",
    "title": "3  Data Examination",
    "section": "",
    "text": "3.1.1 Demographic Histograms (Blood Pressure vs Demographic Variables)\nSystolic vs Age and Systolic vs Gender are very clear\n\nnhanes_data %&gt;% drop_na(bp_dia_mean) %&gt;%\n  ggplot(aes(x=bp_dia_mean, color=demo_age_cat)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Diastolic) with Age\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_age_cat)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Age\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_race)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Race\")\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(bp_sys_mean) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=demo_gender)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Gender\")\n\n\n\n\n\n\n\nnhanes_female &lt;- nhanes_data[nhanes_data$demo_gender == \"Women\", ]\nnhanes_female %&gt;% drop_na(demo_pregnant) %&gt;% \n    ggplot(aes(x=bp_sys_mean, color=demo_pregnant)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Systolic) with Pregnancy (Men Excluded)\")\n\nWarning: Removed 1678 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_female %&gt;% drop_na(demo_pregnant) %&gt;% \n    ggplot(aes(x=bp_dia_mean, color=demo_pregnant)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure (Diastolic) with Pregnancy (Men Excluded)\")\n\nWarning: Removed 1809 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Comorbidities Box Plots (Blood Pressure vs Covariate)\n\nnhanes_data %&gt;% drop_na(cc_smoke) %&gt;%\n  ggplot(aes(x=cc_smoke, y=bp_sys_mean, fill=cc_smoke)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Smoking Status\") +\n    xlab(\"\")\n\nWarning: Removed 3111 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_bmi) %&gt;%\n  ggplot(aes(x=cc_bmi, y=bp_sys_mean, fill=cc_bmi)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS BMI Status\") +\n    xlab(\"\")\n\nWarning: Removed 2867 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_cvd_chd) %&gt;%\n  ggplot(aes(x=cc_cvd_chd, y=bp_sys_mean, fill=cc_cvd_chd)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Chronic Heart Disease Status\") +\n    xlab(\"\")\n\nWarning: Removed 3049 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_ckd) %&gt;%\n  ggplot(aes(x=cc_ckd, y=bp_sys_mean, fill=cc_ckd)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Blood Pressure VS Chronic Kidney Disease Status\") +\n    xlab(\"\")\n\nWarning: Removed 3265 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n3.1.3 Comorbidities Histograms (Blood Pressure vs Covariate)\n\nnhanes_data %&gt;% drop_na(cc_smoke) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_smoke)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins= 80) +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    ggtitle(\"Blood Pressure with Smoking Histogram\")\n\nWarning: Removed 3111 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_bmi) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_bmi)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with BMI Histogram\")\n\nWarning: Removed 2867 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_cvd_stroke) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_cvd_stroke)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with Stroke Histogram\")\n\nWarning: Removed 3050 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nnhanes_data %&gt;% drop_na(cc_diabetes) %&gt;%\n  ggplot(aes(x=bp_sys_mean, color=cc_diabetes)) +\n    geom_histogram(fill=\"white\", alpha=0.5, bins = 80) +\n    ggtitle(\"Blood Pressure with Diabetes Histogram\")\n\nWarning: Removed 3265 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n3.1.4 Chi Squared Tests (Testing difference between covariates and hypertension status)\nI realize this isn’t very useful (of course the result will be significant) but I left them in anyways\n\n#Body Mass Index\nnhanes_bmi_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_bmi) %&gt;% drop_na(cc_bmi)\nnhanes_bmi_df &lt;- table(nhanes_bmi_df$htn_accaha, nhanes_bmi_df$cc_bmi)\nchisq.test(nhanes_bmi_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_df\nX-squared = 2576, df = 3, p-value &lt; 2.2e-16\n\n#Smoking \nnhanes_smoke_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_smoke) %&gt;% drop_na(cc_smoke)\nnhanes_smoke_df &lt;- table(nhanes_smoke_df$htn_accaha, nhanes_smoke_df$cc_smoke)\nchisq.test(nhanes_smoke_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_df\nX-squared = 991.83, df = 2, p-value &lt; 2.2e-16\n\n#Chronic Heart Disease\nnhanes_chd_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_cvd_chd) %&gt;% drop_na(cc_cvd_chd)\nnhanes_chd_df &lt;- table(nhanes_chd_df$htn_accaha, nhanes_chd_df$cc_cvd_chd)\nchisq.test(nhanes_chd_df)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_chd_df\nX-squared = 1357.9, df = 1, p-value &lt; 2.2e-16\n\n#Chronic Kidney Disease\nnhanes_ckd_df &lt;- nhanes_data %&gt;% select(htn_accaha, cc_ckd) %&gt;% drop_na(cc_ckd)\nnhanes_ckd_df &lt;- table(nhanes_ckd_df$htn_accaha, nhanes_ckd_df$cc_ckd)\nchisq.test(nhanes_ckd_df)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_ckd_df\nX-squared = 3702.1, df = 1, p-value &lt; 2.2e-16\n\n\n\n\n3.1.5 Two Sample T Tests\n(Testing the Difference in blood pressure between comorbidities)\nShould I extend to demographic data?\n\n#Don't know if this is the idea but:\nnhanes_dia_df &lt;- nhanes_data %&gt;% select(htn_accaha, bp_dia_mean) %&gt;% drop_na(bp_dia_mean)\nt_test &lt;- t.test(bp_dia_mean ~ htn_accaha, data=nhanes_dia_df)\nt_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_dia_mean by htn_accaha\nt = -96.487, df = 45747, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -9.443644 -9.067610\nsample estimates:\n mean in group No mean in group Yes \n         65.87311          75.12873 \n\n#Smoking T Test (Excludes Former):\nnhanes_sys_smoke &lt;- nhanes_data[nhanes_data$cc_smoke != \"Former\", ] %&gt;% select(cc_smoke, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_smoke)\nsmoke_test &lt;- t.test(bp_sys_mean ~ cc_smoke, data = nhanes_sys_smoke)\nsmoke_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_smoke\nt = 0.85479, df = 20379, p-value = 0.3927\nalternative hypothesis: true difference in means between group Never and group Current is not equal to 0\n95 percent confidence interval:\n -0.2343734  0.5968840\nsample estimates:\n  mean in group Never mean in group Current \n             123.6788              123.4975 \n\n#BMI T Test (Compares &lt;25 and 35+):\nnhanes_sys_bmi &lt;- nhanes_data[nhanes_data$cc_bmi %in% c(\"&lt;25\", \"35+\"), ] %&gt;% select(cc_bmi, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_bmi)\nbmi_test &lt;- t.test(bp_sys_mean ~ cc_bmi, data = nhanes_sys_bmi)\nbmi_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_bmi\nt = -26.614, df = 18857, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group &lt;25 and group 35+ is not equal to 0\n95 percent confidence interval:\n -6.963786 -6.008393\nsample estimates:\nmean in group &lt;25 mean in group 35+ \n          120.332           126.818 \n\n#Diabetes T Test:\nnhanes_sys_diabetes &lt;- nhanes_data %&gt;% select(cc_diabetes, bp_sys_mean) %&gt;% drop_na(bp_sys_mean) %&gt;% drop_na(cc_diabetes)\ndiabetes_test &lt;- t.test(bp_sys_mean ~ cc_diabetes, data = nhanes_sys_diabetes)\ndiabetes_test\n\n\n    Welch Two Sample t-test\n\ndata:  bp_sys_mean by cc_diabetes\nt = -40.314, df = 9221.3, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -10.84351  -9.83791\nsample estimates:\n mean in group No mean in group Yes \n         122.7845          133.1252",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "visualization.html#simple-diabetes-modeling",
    "href": "visualization.html#simple-diabetes-modeling",
    "title": "3  Data Examination",
    "section": "3.2 Simple Diabetes Modeling",
    "text": "3.2 Simple Diabetes Modeling\nWe are choosing Diabetes as the co-morbidity for modeling. We will try to predict the occurrence of diabetes as a function of blood pressure as well as other covariates.\nThe most basic model possible is a simple logistic regression model predicting diabetes status based on blood pressure:\n\nsimple_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.9404827  0.0770324  -64.14   &lt;2e-16 ***\nbp_sys_mean  0.0238141  0.0005811   40.98   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 41987  on 56532  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 41991\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0071511\n0.0770324\n-64.13512\n0\n0.0061477\n0.0083151\n\n\nbp_sys_mean\n1.0240999\n0.0005811\n40.98151\n0\n1.0229344\n1.0252673\n\n\n\n\nsimple_diab_model_dia &lt;- glm(cc_diabetes ~ bp_dia_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_dia)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_dia_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.652673   0.073728 -22.416  &lt; 2e-16 ***\nbp_dia_mean -0.003651   0.001039  -3.514 0.000441 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43309  on 56285  degrees of freedom\nResidual deviance: 43297  on 56284  degrees of freedom\n  (3513 observations deleted due to missingness)\nAIC: 43301\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_dia, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.1915372\n0.0737285\n-22.415661\n0.0000000\n0.1657332\n0.2212722\n\n\nbp_dia_mean\n0.9963553\n0.0010390\n-3.514294\n0.0004409\n0.9943280\n0.9983860\n\n\n\n\n\n\n3.2.0.1 Model Explanation:\nFor the logistic regression using systolic blood pressure, we can see that the odds ratio beta parameter is 1.024. This implies that a higher systolic blood pressure corresponds to increased chances of observing diabetes.\nA more exact interpretation would be that: for one additional unit increase in systolic blood pressure, the estimated risk of having diabetes increases by 2.4%.\nThis value may not seem extremely high, yet it still has a p value evaluated to be 0 by R. We can also see that the 95% confidence interval of this parameter ranges between 1.0229 and 1.0253, meaning that the model predicts that the true relationship falls within this interval with a 95% certainty, since the true value of the parameter is most likely within this interval.\nThe opposite is true with diastolic blood pressure: the beta parameter is 0.996, implying that higher diastolic blood pressure corresponds to a lower chance of observing diabetes. For an additional unit increase in diastolic blood pressure, the estimated risk of having diabetes decreases by 0.04%.\nNote: systolic blood pressure is a better predictor of cardiovascular disease, so I chose to consider systolic rather than diastolic in future models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "visualization.html#demographic-model",
    "href": "visualization.html#demographic-model",
    "title": "3  Data Examination",
    "section": "3.3 Demographic Model",
    "text": "3.3 Demographic Model\nNext, we build a model including the demographic variables as well. This will hopefully provide a more accurate model, since it will have access to the further information in order to make predictions.\n\ndemo_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender,data = nhanes_data, family = binomial)\n\nsummary (demo_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender, family = binomial, data = nhanes_data)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -5.6927561  0.0885174 -64.312  &lt; 2e-16 ***\nbp_sys_mean                  0.0037581  0.0006792   5.533 3.14e-08 ***\ndemo_age_years               0.0529545  0.0009161  57.806  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.9034242  0.0350353  25.786  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  0.8093210  0.0606852  13.336  &lt; 2e-16 ***\ndemo_raceHispanic            0.8592775  0.0343392  25.023  &lt; 2e-16 ***\ndemo_raceOther               0.7478892  0.0718834  10.404  &lt; 2e-16 ***\ndemo_genderWomen            -0.1547613  0.0265581  -5.827 5.63e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 37780  on 56526  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 37796\n\nNumber of Fisher Scoring iterations: 5\n\nknitr::kable(tidy(demo_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0033703\n0.0885174\n-64.312318\n0\n0.0028326\n0.0040077\n\n\nbp_sys_mean\n1.0037652\n0.0006792\n5.533450\n0\n1.0024283\n1.0051008\n\n\ndemo_age_years\n1.0543817\n0.0009161\n57.805744\n0\n1.0524962\n1.0562830\n\n\ndemo_raceNon-Hispanic Black\n2.4680396\n0.0350353\n25.786107\n0\n2.3042427\n2.6434926\n\n\ndemo_raceNon-Hispanic Asian\n2.2463822\n0.0606852\n13.336382\n0\n1.9925692\n2.5278493\n\n\ndemo_raceHispanic\n2.3614540\n0.0343392\n25.023206\n0\n2.2077734\n2.5259187\n\n\ndemo_raceOther\n2.1125361\n0.0718834\n10.404206\n0\n1.8320999\n2.4286788\n\n\ndemo_genderWomen\n0.8566196\n0.0265581\n-5.827267\n0\n0.8131556\n0.9023806\n\n\n\n\n\n\n3.3.0.1 Model Explanation\nIn this model, we can still see a slight upwards trend with systolic blood pressure, although it is a bit weaker (1.024 &gt; 1.003). With this parameter, the estimated risk of having diabetes increases only by 0.3%. Although the effect is smaller, we can see that the confidence interval is between 1.0024 and 1.0051, which does not include 1. So, although small, the positive relationship is most likely significant.\n\n\n3.3.0.2 Demographics\nAge:\nThe model also tells us that age is positively correlated with the observation of diabetes. With a log odds ratio of 1.054, it seems that every year increases the risk of diabetes occurrence by 5.4%.\nRace:\nThe log odds ratio for categorical variables compares the other variables to the baseline “reference group”. Here, the “reference group” for the race variable is Non-Hispanic White. We can see that, in comparison to this group, all other races have significantly higher risk of diabetes: for example, the Hispanic population’s risk of diabetes occurrence is 2.36 times higher than the Non-Hispanic White population.\nGender:\nWith this variable, the reference group is men. We can see that women have a lower odds of having diabetes compared to men. Specifically, the risk of diabetes in women is about 85.6% of in men.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "visualization.html#full-model",
    "href": "visualization.html#full-model",
    "title": "3  Data Examination",
    "section": "3.4 Full Model",
    "text": "3.4 Full Model\nLastly, we want to create a model including confounding variables. To achieve this, we must first determine which other variables are confounding, meaning they have significant associations with diabetes.\nWe can achieve this by using chi squared test, which compares whether or not the observed ratios of diabetes and confounding variables matches the ratios expected by random chance. If the chi squared test determines significance, then diabetes and the other variables commonly occur together and therefore are confounding.\n\n3.4.0.1 Perform Chi Squared Tests:\n\n#Testing for BMI\nnhanes_bmi_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_bmi) %&gt;% drop_na(cc_bmi) %&gt;% drop_na(cc_diabetes)\nnhanes_bmi_diab &lt;- table(nhanes_bmi_diab)\nnhanes_bmi_diab\n\n           cc_bmi\ncc_diabetes   &lt;25 25 to &lt;30 30 to &lt;35   35+\n        No  17390     16913      9476  6965\n        Yes   974      2173      2056  2274\n\nchisq.test(nhanes_bmi_df)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_df\nX-squared = 2576, df = 3, p-value &lt; 2.2e-16\n\n#Testing for Smoking\nnhanes_smoke_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_smoke) %&gt;% drop_na(cc_smoke) %&gt;% drop_na(cc_diabetes)\nnhanes_smoke_diab &lt;- table(nhanes_smoke_diab)\nnhanes_smoke_diab\n\n           cc_smoke\ncc_diabetes Never Former Current\n        No  27414  11107   10366\n        Yes  3917   2587    1249\n\nchisq.test(nhanes_smoke_diab)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_diab\nX-squared = 435.81, df = 2, p-value &lt; 2.2e-16\n\n#Testing for Hypertensive Medication use\nnhanes_med_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, bp_med_use) %&gt;% drop_na(bp_med_use) %&gt;% drop_na(cc_diabetes)\nnhanes_med_diab &lt;- table(nhanes_med_diab)\nnhanes_med_diab\n\n           bp_med_use\ncc_diabetes    No   Yes\n        No  41679 10079\n        Yes  3138  4611\n\nchisq.test(nhanes_med_diab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_med_diab\nX-squared = 5807.1, df = 1, p-value &lt; 2.2e-16\n\n\nAfter this analysis, we can see that all three variables, BMI, Smoking, and Medication Use, are all confounding. We can include all of them in the next model, in addition to systolic blood pressure and the demographic variables:\n\n#to prevent errors down the line, exclude the rows with na:\nused_vars = c('cc_diabetes', 'bp_sys_mean', 'demo_age_years', 'demo_race', 'demo_gender', 'cc_bmi', 'cc_smoke', 'bp_med_use')\nclean_nhanes &lt;- nhanes_data[complete.cases(nhanes_data[,..used_vars]), ]\n\nfull_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender+ cc_bmi + cc_smoke + bp_med_use, data = clean_nhanes, family = binomial)\n\nsummary(full_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender + cc_bmi + cc_smoke + bp_med_use, family = binomial, \n    data = clean_nhanes)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -6.3003463  0.1112295 -56.643  &lt; 2e-16 ***\nbp_sys_mean                  0.0017066  0.0007373   2.315   0.0206 *  \ndemo_age_years               0.0470354  0.0011312  41.579  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.6987360  0.0374745  18.646  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  1.3022903  0.0660355  19.721  &lt; 2e-16 ***\ndemo_raceHispanic            0.8889260  0.0366792  24.235  &lt; 2e-16 ***\ndemo_raceOther               0.8913458  0.0763522  11.674  &lt; 2e-16 ***\ndemo_genderWomen            -0.3082492  0.0295124 -10.445  &lt; 2e-16 ***\ncc_bmi25 to &lt;30              0.5927344  0.0444524  13.334  &lt; 2e-16 ***\ncc_bmi30 to &lt;35              1.1736075  0.0463565  25.317  &lt; 2e-16 ***\ncc_bmi35+                    1.7702868  0.0480051  36.877  &lt; 2e-16 ***\ncc_smokeFormer               0.0614704  0.0335729   1.831   0.0671 .  \ncc_smokeCurrent              0.1853436  0.0403687   4.591 4.41e-06 ***\nbp_med_useYes                0.9121351  0.0314064  29.043  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 33055  on 52183  degrees of freedom\nAIC: 33083\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(full_diab_model_sys, exponentiate = TRUE, conf.int = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.0018357\n0.1112295\n-56.642782\n0.0000000\n0.0014752\n0.0022815\n\n\nbp_sys_mean\n1.0017080\n0.0007373\n2.314675\n0.0206307\n1.0002594\n1.0031545\n\n\ndemo_age_years\n1.0481591\n0.0011312\n41.579121\n0.0000000\n1.0458438\n1.0504919\n\n\ndemo_raceNon-Hispanic Black\n2.0112090\n0.0374745\n18.645645\n0.0000000\n1.8687584\n2.1644762\n\n\ndemo_raceNon-Hispanic Asian\n3.6777100\n0.0660355\n19.721057\n0.0000000\n3.2286139\n4.1827136\n\n\ndemo_raceHispanic\n2.4325157\n0.0366792\n24.235131\n0.0000000\n2.2638469\n2.6139232\n\n\ndemo_raceOther\n2.4384090\n0.0763522\n11.674130\n0.0000000\n2.0964731\n2.8282006\n\n\ndemo_genderWomen\n0.7347322\n0.0295124\n-10.444726\n0.0000000\n0.6934113\n0.7784570\n\n\ncc_bmi25 to &lt;30\n1.8089279\n0.0444524\n13.334145\n0.0000000\n1.6585185\n1.9742572\n\n\ncc_bmi30 to &lt;35\n3.2336368\n0.0463565\n25.316997\n0.0000000\n2.9536973\n3.5423428\n\n\ncc_bmi35+\n5.8725376\n0.0480051\n36.877031\n0.0000000\n5.3470462\n6.4542286\n\n\ncc_smokeFormer\n1.0633990\n0.0335729\n1.830951\n0.0671079\n0.9956021\n1.1356446\n\n\ncc_smokeCurrent\n1.2036319\n0.0403687\n4.591266\n0.0000044\n1.1117990\n1.3024331\n\n\nbp_med_useYes\n2.4896325\n0.0314064\n29.042966\n0.0000000\n2.3411270\n2.6478476\n\n\n\n\n\n\n\n3.4.0.2 Model Explanation\nThe previous variables in this model continue to show the same patterns, although again, the effect of systolic blood pressure is again reduced due to a lower log odds ratio. Now, the p value seems to be much higher at 0.02 (which is still significant, but much less so). The demographic variables also have much the same pattern, although Non-Hispanic Asians seem to have a much higher odds ratio than in the previous model.\n\n\n3.4.0.3 Covariates\nBMI:\nIn this variable, the baseline reference level is bmi &lt;25. In comparison, those with higher bmi have increased risk of having diabetes, with the risk increasing the higher the bmi becomes. For example, those with bmi from 25-30 have a 1.8 times higher risk, while those with a bmi of 35+ have a 5.8 times higher risk.\nSmoking:\nWith a baseline level of nonsmoking, former smokers may have about a 6% higher risk of diabetes. This may not be significant, however, given that the p value is only 0.067 and the odds ratio of 1 falls within the confidence interval. Current smokers, on the other hand, have about a 20% higher risk, this time with a much lower p value of 4*10^-6\nBlood Pressure Medication Use:\nCompared to those who do not use blood pressure medication, individuals who do have about a 2.5 times higher risk of experiencing diabetes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "visualization.html#model-selection",
    "href": "visualization.html#model-selection",
    "title": "3  Data Examination",
    "section": "3.5 Model Selection",
    "text": "3.5 Model Selection\nIt is possible to find an even better model by modifying which variables we include in our logistic regression model. We can achieve this using model selection, which will selectively add or subtract our explanatory variables from the model and evaluate its performance to choose the final best set of variables.\nExplanation of model selection and or AIC?\n\n3.5.0.1 Backwards Selection:\n\nbackwards = step(full_diab_model_sys)\n\nStart:  AIC=33082.55\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n                 Df Deviance   AIC\n&lt;none&gt;                 33055 33083\n- bp_sys_mean     1    33060 33086\n- cc_smoke        2    33076 33100\n- demo_gender     1    33164 33190\n- bp_med_use      1    33909 33935\n- demo_race       4    33930 33950\n- cc_bmi          3    34756 34778\n- demo_age_years  1    34931 34957\n\nformula(backwards)\n\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n\nIt looks like the backwards selection model returned the same full model. In other words, removing variables does not improve its AIC, and therefore does not improve its performance.\n\n\n3.5.0.2 Forward Selection\n\n#start from a model without any predictors\nnothing &lt;- glm(cc_diabetes ~ 1, data = clean_nhanes, family=binomial)\nsummary(nothing)\n\n\nCall:\nglm(formula = cc_diabetes ~ 1, family = binomial, data = clean_nhanes)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.85919    0.01282  -145.1   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 41278  on 52196  degrees of freedom\nAIC: 41280\n\nNumber of Fisher Scoring iterations: 4\n\nforwards = step(nothing,\nscope=list(lower=formula(nothing),upper=formula(full_diab_model_sys)), direction=\"forward\")\n\nStart:  AIC=41279.9\ncc_diabetes ~ 1\n\n                 Df Deviance   AIC\n+ bp_med_use      1    37076 37080\n+ demo_age_years  1    37252 37256\n+ cc_bmi          3    39218 39226\n+ bp_sys_mean     1    39888 39892\n+ demo_race       4    40891 40901\n+ cc_smoke        2    40911 40917\n+ demo_gender     1    41242 41246\n&lt;none&gt;                 41278 41280\n\nStep:  AIC=37079.85\ncc_diabetes ~ bp_med_use\n\n                 Df Deviance   AIC\n+ demo_age_years  1    35675 35681\n+ cc_bmi          3    35907 35917\n+ demo_race       4    36597 36609\n+ bp_sys_mean     1    36788 36794\n+ cc_smoke        2    36968 36976\n+ demo_gender     1    37009 37015\n&lt;none&gt;                 37076 37080\n\nStep:  AIC=35681.48\ncc_diabetes ~ bp_med_use + demo_age_years\n\n              Df Deviance   AIC\n+ cc_bmi       3    34070 34082\n+ demo_race    4    34834 34848\n+ demo_gender  1    35624 35632\n+ bp_sys_mean  1    35654 35662\n+ cc_smoke     2    35670 35680\n&lt;none&gt;              35675 35681\n\nStep:  AIC=34082.43\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi\n\n              Df Deviance   AIC\n+ demo_race    4    33213 33233\n+ demo_gender  1    33963 33977\n+ bp_sys_mean  1    34050 34064\n+ cc_smoke     2    34054 34070\n&lt;none&gt;              34070 34082\n\nStep:  AIC=33232.52\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race\n\n              Df Deviance   AIC\n+ demo_gender  1    33081 33103\n+ cc_smoke     2    33170 33194\n+ bp_sys_mean  1    33208 33230\n&lt;none&gt;              33213 33233\n\nStep:  AIC=33102.89\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender\n\n              Df Deviance   AIC\n+ cc_smoke     2    33060 33086\n+ bp_sys_mean  1    33076 33100\n&lt;none&gt;              33081 33103\n\nStep:  AIC=33085.88\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke\n\n              Df Deviance   AIC\n+ bp_sys_mean  1    33055 33083\n&lt;none&gt;              33060 33086\n\nStep:  AIC=33082.55\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward Selection process again selects the full model.\n\nbothways = step(nothing, list(lower=formula(nothing),upper=formula(full_diab_model_sys)),\ndirection=\"both\",trace=0)\nformula(bothways)\n\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward-Backward algorithm also selects all of the variables",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "visualization.html#model-diagnostics",
    "href": "visualization.html#model-diagnostics",
    "title": "3  Data Examination",
    "section": "3.6 Model Diagnostics",
    "text": "3.6 Model Diagnostics\nI followed a guide online but I don’t really know what this is doing:\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"demo_age_years\"]*demo_age_years + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = demo_age_years, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"bp_sys_mean\"]*bp_sys_mean + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = bp_sys_mean, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nTest for Multicollinearity\n\nvif(full_diab_model_sys)\n\n                   GVIF Df GVIF^(1/(2*Df))\nbp_sys_mean    1.169212  1        1.081301\ndemo_age_years 1.528167  1        1.236191\ndemo_race      1.207663  4        1.023866\ndemo_gender    1.091056  1        1.044536\ncc_bmi         1.182024  3        1.028263\ncc_smoke       1.173951  2        1.040908\nbp_med_use     1.235766  1        1.111650\n\n\nOutliers\n\noutlier_nhanes &lt;-\n  clean_nhanes %&gt;% \n  mutate(dffits = dffits(full_diab_model_sys))\n\noutlier_nhanes %&gt;% \n  mutate(obs_number = row_number(),\n         large = ifelse(abs(dffits) &gt; 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)),\n                        \"red\", \"black\")) %&gt;% \n  ggplot(aes(obs_number, dffits, color = large)) +\n  geom_point() + \n  geom_hline(yintercept = c(-1,1) * 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)), color = \"red\") +\n  scale_color_identity()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Examination</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html",
    "href": "initial_modeling.html",
    "title": "4  Modeling Diabetes Occurence",
    "section": "",
    "text": "4.1 Simple Diabetes Modeling\nWe are choosing Diabetes as the co-morbidity for modeling. We will try to predict the occurrence of diabetes as a function of blood pressure as well as other covariates.\nThe most basic model possible is a simple logistic regression model predicting diabetes status based on blood pressure:\nsimple_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.9404827  0.0770324  -64.14   &lt;2e-16 ***\nbp_sys_mean  0.0238141  0.0005811   40.98   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 41987  on 56532  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 41991\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.007\n0.077\n-64.135\n0\n0.006\n0.008\n\n\nbp_sys_mean\n1.024\n0.001\n40.982\n0\n1.023\n1.025\n\n\n\n\nsimple_diab_model_dia &lt;- glm(cc_diabetes ~ bp_dia_mean, data = nhanes_data, family = binomial)\n\nsummary(simple_diab_model_dia)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_dia_mean, family = binomial, data = nhanes_data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.652673   0.073728 -22.416  &lt; 2e-16 ***\nbp_dia_mean -0.003651   0.001039  -3.514 0.000441 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43309  on 56285  degrees of freedom\nResidual deviance: 43297  on 56284  degrees of freedom\n  (3513 observations deleted due to missingness)\nAIC: 43301\n\nNumber of Fisher Scoring iterations: 4\n\nknitr::kable(tidy(simple_diab_model_dia, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.192\n0.074\n-22.416\n0\n0.166\n0.221\n\n\nbp_dia_mean\n0.996\n0.001\n-3.514\n0\n0.994\n0.998",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#simple-diabetes-modeling",
    "href": "initial_modeling.html#simple-diabetes-modeling",
    "title": "4  Modeling Diabetes Occurence",
    "section": "",
    "text": "4.1.0.1 Model Explanation:\nFor the logistic regression using systolic blood pressure, we can see that the odds ratio beta parameter is 1.024. This implies that a higher systolic blood pressure corresponds to increased chances of observing diabetes.\nA more exact interpretation would be that: for one additional unit increase in systolic blood pressure, the estimated risk of having diabetes increases by 2.4%.\nThis value may not seem extremely high, yet it still has a p value evaluated to be 0 by R. We can also see that the 95% confidence interval of this parameter ranges between 1.0229 and 1.0253, meaning that the model predicts that the true relationship falls within this interval with a 95% certainty, since the true value of the parameter is most likely within this interval.\nThe opposite is true with diastolic blood pressure: the beta parameter is 0.996, implying that higher diastolic blood pressure corresponds to a lower chance of observing diabetes. For an additional unit increase in diastolic blood pressure, the estimated risk of having diabetes decreases by 0.04%.\nNote: systolic blood pressure is a better predictor of cardiovascular disease, so I chose to consider systolic rather than diastolic in future models.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#demographic-model",
    "href": "initial_modeling.html#demographic-model",
    "title": "4  Modeling Diabetes Occurence",
    "section": "4.2 Demographic Model",
    "text": "4.2 Demographic Model\nNext, we build a model including the demographic variables as well. This will hopefully provide a more accurate model, since it will have access to the further information in order to make predictions.\n\ndemo_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender,data = nhanes_data, family = binomial)\n\nsummary (demo_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender, family = binomial, data = nhanes_data)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -5.6927561  0.0885174 -64.312  &lt; 2e-16 ***\nbp_sys_mean                  0.0037581  0.0006792   5.533 3.14e-08 ***\ndemo_age_years               0.0529545  0.0009161  57.806  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.9034242  0.0350353  25.786  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  0.8093210  0.0606852  13.336  &lt; 2e-16 ***\ndemo_raceHispanic            0.8592775  0.0343392  25.023  &lt; 2e-16 ***\ndemo_raceOther               0.7478892  0.0718834  10.404  &lt; 2e-16 ***\ndemo_genderWomen            -0.1547613  0.0265581  -5.827 5.63e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43614  on 56533  degrees of freedom\nResidual deviance: 37780  on 56526  degrees of freedom\n  (3265 observations deleted due to missingness)\nAIC: 37796\n\nNumber of Fisher Scoring iterations: 5\n\nknitr::kable(tidy(demo_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.003\n0.089\n-64.312\n0\n0.003\n0.004\n\n\nbp_sys_mean\n1.004\n0.001\n5.533\n0\n1.002\n1.005\n\n\ndemo_age_years\n1.054\n0.001\n57.806\n0\n1.052\n1.056\n\n\ndemo_raceNon-Hispanic Black\n2.468\n0.035\n25.786\n0\n2.304\n2.643\n\n\ndemo_raceNon-Hispanic Asian\n2.246\n0.061\n13.336\n0\n1.993\n2.528\n\n\ndemo_raceHispanic\n2.361\n0.034\n25.023\n0\n2.208\n2.526\n\n\ndemo_raceOther\n2.113\n0.072\n10.404\n0\n1.832\n2.429\n\n\ndemo_genderWomen\n0.857\n0.027\n-5.827\n0\n0.813\n0.902\n\n\n\n\n\n\n4.2.0.1 Model Explanation\nIn this model, we can still see a slight upwards trend with systolic blood pressure, although it is a bit weaker (1.024 &gt; 1.003). With this parameter, the estimated risk of having diabetes increases only by 0.3%. Although the effect is smaller, we can see that the confidence interval is between 1.0024 and 1.0051, which does not include 1. So, although small, the positive relationship is most likely significant.\n\n\n4.2.0.2 Demographics\nAge:\nThe model also tells us that age is positively correlated with the observation of diabetes. With a log odds ratio of 1.054, it seems that every year increases the risk of diabetes occurrence by 5.4%.\nRace:\nThe log odds ratio for categorical variables compares the other variables to the baseline “reference group”. Here, the “reference group” for the race variable is Non-Hispanic White. We can see that, in comparison to this group, all other races have significantly higher risk of diabetes: for example, the Hispanic population’s risk of diabetes occurrence is 2.36 times higher than the Non-Hispanic White population.\nGender:\nWith this variable, the reference group is men. We can see that women have a lower odds of having diabetes compared to men. Specifically, the risk of diabetes in women is about 85.6% of that of men.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#full-model",
    "href": "initial_modeling.html#full-model",
    "title": "4  Modeling Diabetes Occurence",
    "section": "4.3 Full Model",
    "text": "4.3 Full Model\nLastly, we want to create a model including confounding variables. To achieve this, we must first determine which other variables are confounding, meaning they have significant associations with diabetes.\nWe can achieve this by using chi squared test, which compares whether or not the observed ratios of diabetes and confounding variables matches the ratios expected by random chance. If the chi squared test determines significance, then diabetes and the other variables commonly occur together and therefore are confounding.\n\n4.3.0.1 Perform Chi Squared Tests:\n\n#Testing for BMI\nnhanes_bmi_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_bmi) %&gt;% drop_na(cc_bmi) %&gt;% drop_na(cc_diabetes)\nnhanes_bmi_diab &lt;- table(nhanes_bmi_diab)\n#nhanes_bmi_diab\nchisq.test(nhanes_bmi_diab)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_bmi_diab\nX-squared = 2368.3, df = 3, p-value &lt; 2.2e-16\n\n#Testing for Smoking\nnhanes_smoke_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, cc_smoke) %&gt;% drop_na(cc_smoke) %&gt;% drop_na(cc_diabetes)\nnhanes_smoke_diab &lt;- table(nhanes_smoke_diab)\n#nhanes_smoke_diab\nchisq.test(nhanes_smoke_diab)\n\n\n    Pearson's Chi-squared test\n\ndata:  nhanes_smoke_diab\nX-squared = 435.81, df = 2, p-value &lt; 2.2e-16\n\n#Testing for Hypertensive Medication use\nnhanes_med_diab &lt;- nhanes_data %&gt;% select(cc_diabetes, bp_med_use) %&gt;% drop_na(bp_med_use) %&gt;% drop_na(cc_diabetes)\nnhanes_med_diab &lt;- table(nhanes_med_diab)\n#nhanes_med_diab\nchisq.test(nhanes_med_diab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nhanes_med_diab\nX-squared = 5807.1, df = 1, p-value &lt; 2.2e-16\n\n\nAfter this analysis, we can see that all three variables, BMI, Smoking, and Medication Use, are all confounding. We can include all of them in the next model, in addition to systolic blood pressure and the demographic variables:\n\n#to prevent errors down the line, exclude the rows with na:\nused_vars = c('cc_diabetes', 'bp_sys_mean', 'demo_age_years', 'demo_race', 'demo_gender', 'cc_bmi', 'cc_smoke', 'bp_med_use')\nclean_nhanes &lt;- nhanes_data[complete.cases(nhanes_data[,..used_vars]), ]\n\nfull_diab_model_sys &lt;- glm(cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender+ cc_bmi + cc_smoke + bp_med_use, data = clean_nhanes, family = binomial)\n\nsummary(full_diab_model_sys)\n\n\nCall:\nglm(formula = cc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + \n    demo_gender + cc_bmi + cc_smoke + bp_med_use, family = binomial, \n    data = clean_nhanes)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -6.3003463  0.1112295 -56.643  &lt; 2e-16 ***\nbp_sys_mean                  0.0017066  0.0007373   2.315   0.0206 *  \ndemo_age_years               0.0470354  0.0011312  41.579  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Black  0.6987360  0.0374745  18.646  &lt; 2e-16 ***\ndemo_raceNon-Hispanic Asian  1.3022903  0.0660355  19.721  &lt; 2e-16 ***\ndemo_raceHispanic            0.8889260  0.0366792  24.235  &lt; 2e-16 ***\ndemo_raceOther               0.8913458  0.0763522  11.674  &lt; 2e-16 ***\ndemo_genderWomen            -0.3082492  0.0295124 -10.445  &lt; 2e-16 ***\ncc_bmi25 to &lt;30              0.5927344  0.0444524  13.334  &lt; 2e-16 ***\ncc_bmi30 to &lt;35              1.1736075  0.0463565  25.317  &lt; 2e-16 ***\ncc_bmi35+                    1.7702868  0.0480051  36.877  &lt; 2e-16 ***\ncc_smokeFormer               0.0614704  0.0335729   1.831   0.0671 .  \ncc_smokeCurrent              0.1853436  0.0403687   4.591 4.41e-06 ***\nbp_med_useYes                0.9121351  0.0314064  29.043  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 33055  on 52183  degrees of freedom\nAIC: 33083\n\nNumber of Fisher Scoring iterations: 6\n\nknitr::kable(tidy(full_diab_model_sys, exponentiate = TRUE, conf.int = TRUE), digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.002\n0.111\n-56.643\n0.000\n0.001\n0.002\n\n\nbp_sys_mean\n1.002\n0.001\n2.315\n0.021\n1.000\n1.003\n\n\ndemo_age_years\n1.048\n0.001\n41.579\n0.000\n1.046\n1.050\n\n\ndemo_raceNon-Hispanic Black\n2.011\n0.037\n18.646\n0.000\n1.869\n2.164\n\n\ndemo_raceNon-Hispanic Asian\n3.678\n0.066\n19.721\n0.000\n3.229\n4.183\n\n\ndemo_raceHispanic\n2.433\n0.037\n24.235\n0.000\n2.264\n2.614\n\n\ndemo_raceOther\n2.438\n0.076\n11.674\n0.000\n2.096\n2.828\n\n\ndemo_genderWomen\n0.735\n0.030\n-10.445\n0.000\n0.693\n0.778\n\n\ncc_bmi25 to &lt;30\n1.809\n0.044\n13.334\n0.000\n1.659\n1.974\n\n\ncc_bmi30 to &lt;35\n3.234\n0.046\n25.317\n0.000\n2.954\n3.542\n\n\ncc_bmi35+\n5.873\n0.048\n36.877\n0.000\n5.347\n6.454\n\n\ncc_smokeFormer\n1.063\n0.034\n1.831\n0.067\n0.996\n1.136\n\n\ncc_smokeCurrent\n1.204\n0.040\n4.591\n0.000\n1.112\n1.302\n\n\nbp_med_useYes\n2.490\n0.031\n29.043\n0.000\n2.341\n2.648\n\n\n\n\n\n\n\n4.3.0.2 Model Explanation\nThe previous variables in this model continue to show the same patterns, although again, the effect of systolic blood pressure is again reduced due to a lower log odds ratio. Now, the p value seems to be much higher at 0.02 (which is still significant, but much less so). The demographic variables also have much the same pattern, although Non-Hispanic Asians seem to have a much higher odds ratio than in the previous model.\n\n\n4.3.0.3 Covariates\nBMI:\nIn this variable, the baseline reference level is bmi &lt;25. In comparison, those with higher bmi have increased risk of having diabetes, with the risk increasing the higher the bmi becomes. For example, those with bmi from 25-30 have a 1.8 times higher risk, while those with a bmi of 35+ have a 5.8 times higher risk.\nSmoking:\nWith a baseline level of nonsmoking, former smokers may have about a 6% higher risk of diabetes. This may not be significant, however, given that the p value is only 0.067 and the odds ratio of 1 falls within the confidence interval. Current smokers, on the other hand, have about a 20% higher risk, this time with a much lower p value of 4*10^-6\nBlood Pressure Medication Use:\nCompared to those who do not use blood pressure medication, individuals who do have about a 2.5 times higher risk of experiencing diabetes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#model-selection",
    "href": "initial_modeling.html#model-selection",
    "title": "4  Modeling Diabetes Occurence",
    "section": "4.4 Model Selection",
    "text": "4.4 Model Selection\nIt is possible to find an even better model by modifying which variables we include in our logistic regression model. We can achieve this using model selection, which will selectively add or subtract our explanatory variables from the model and evaluate its performance to choose the final best set of variables.\nExplanation of model selection and or AIC?\n\n4.4.0.1 Backwards Selection:\n\nbackwards = step(full_diab_model_sys)\n\nStart:  AIC=33082.55\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n                 Df Deviance   AIC\n&lt;none&gt;                 33055 33083\n- bp_sys_mean     1    33060 33086\n- cc_smoke        2    33076 33100\n- demo_gender     1    33164 33190\n- bp_med_use      1    33909 33935\n- demo_race       4    33930 33950\n- cc_bmi          3    34756 34778\n- demo_age_years  1    34931 34957\n\nformula(backwards)\n\ncc_diabetes ~ bp_sys_mean + demo_age_years + demo_race + demo_gender + \n    cc_bmi + cc_smoke + bp_med_use\n\n\nIt looks like the backwards selection model returned the same full model. In other words, removing variables does not improve its AIC, and therefore does not improve its performance.\n\n\n4.4.0.2 Forward Selection\n\n#start from a model without any predictors\nnothing &lt;- glm(cc_diabetes ~ 1, data = clean_nhanes, family=binomial)\nsummary(nothing)\n\n\nCall:\nglm(formula = cc_diabetes ~ 1, family = binomial, data = clean_nhanes)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.85919    0.01282  -145.1   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 41278  on 52196  degrees of freedom\nResidual deviance: 41278  on 52196  degrees of freedom\nAIC: 41280\n\nNumber of Fisher Scoring iterations: 4\n\nforwards = step(nothing,\nscope=list(lower=formula(nothing),upper=formula(full_diab_model_sys)), direction=\"forward\")\n\nStart:  AIC=41279.9\ncc_diabetes ~ 1\n\n                 Df Deviance   AIC\n+ bp_med_use      1    37076 37080\n+ demo_age_years  1    37252 37256\n+ cc_bmi          3    39218 39226\n+ bp_sys_mean     1    39888 39892\n+ demo_race       4    40891 40901\n+ cc_smoke        2    40911 40917\n+ demo_gender     1    41242 41246\n&lt;none&gt;                 41278 41280\n\nStep:  AIC=37079.85\ncc_diabetes ~ bp_med_use\n\n                 Df Deviance   AIC\n+ demo_age_years  1    35675 35681\n+ cc_bmi          3    35907 35917\n+ demo_race       4    36597 36609\n+ bp_sys_mean     1    36788 36794\n+ cc_smoke        2    36968 36976\n+ demo_gender     1    37009 37015\n&lt;none&gt;                 37076 37080\n\nStep:  AIC=35681.48\ncc_diabetes ~ bp_med_use + demo_age_years\n\n              Df Deviance   AIC\n+ cc_bmi       3    34070 34082\n+ demo_race    4    34834 34848\n+ demo_gender  1    35624 35632\n+ bp_sys_mean  1    35654 35662\n+ cc_smoke     2    35670 35680\n&lt;none&gt;              35675 35681\n\nStep:  AIC=34082.43\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi\n\n              Df Deviance   AIC\n+ demo_race    4    33213 33233\n+ demo_gender  1    33963 33977\n+ bp_sys_mean  1    34050 34064\n+ cc_smoke     2    34054 34070\n&lt;none&gt;              34070 34082\n\nStep:  AIC=33232.52\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race\n\n              Df Deviance   AIC\n+ demo_gender  1    33081 33103\n+ cc_smoke     2    33170 33194\n+ bp_sys_mean  1    33208 33230\n&lt;none&gt;              33213 33233\n\nStep:  AIC=33102.89\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender\n\n              Df Deviance   AIC\n+ cc_smoke     2    33060 33086\n+ bp_sys_mean  1    33076 33100\n&lt;none&gt;              33081 33103\n\nStep:  AIC=33085.88\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke\n\n              Df Deviance   AIC\n+ bp_sys_mean  1    33055 33083\n&lt;none&gt;              33060 33086\n\nStep:  AIC=33082.55\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward Selection process again selects the full model.\n\n\n4.4.1 Forward-Backward Selection\n\nbothways = step(nothing, list(lower=formula(nothing),upper=formula(full_diab_model_sys)),\ndirection=\"both\",trace=0)\nformula(bothways)\n\ncc_diabetes ~ bp_med_use + demo_age_years + cc_bmi + demo_race + \n    demo_gender + cc_smoke + bp_sys_mean\n\n\nThe Forward-Backward algorithm also selects all of the variables.\nIn this case, the best model (as determined by the AIC) includes all of the variables (systolic blood pressure, age, race, sex, smoking status, BMI, and medication use). In other situations, it may have returned just a few of these variables, but for this example, we can proceed with the full model.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#model-diagnostics",
    "href": "initial_modeling.html#model-diagnostics",
    "title": "4  Modeling Diabetes Occurence",
    "section": "4.5 Model Diagnostics",
    "text": "4.5 Model Diagnostics\nI followed a guide online but I don’t really know what this is doing:\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"demo_age_years\"]*demo_age_years + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = demo_age_years, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"bp_sys_mean\"]*bp_sys_mean + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = bp_sys_mean, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nTest for Multicollinearity\n\nvif(full_diab_model_sys)\n\n                   GVIF Df GVIF^(1/(2*Df))\nbp_sys_mean    1.169212  1        1.081301\ndemo_age_years 1.528167  1        1.236191\ndemo_race      1.207663  4        1.023866\ndemo_gender    1.091056  1        1.044536\ncc_bmi         1.182024  3        1.028263\ncc_smoke       1.173951  2        1.040908\nbp_med_use     1.235766  1        1.111650\n\n\nOutliers\n\noutlier_nhanes &lt;-\n  clean_nhanes %&gt;% \n  mutate(dffits = dffits(full_diab_model_sys))\n\noutlier_nhanes %&gt;% \n  mutate(obs_number = row_number(),\n         large = ifelse(abs(dffits) &gt; 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)),\n                        \"red\", \"black\")) %&gt;% \n  ggplot(aes(obs_number, dffits, color = large)) +\n  geom_point() + \n  geom_hline(yintercept = c(-1,1) * 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)), color = \"red\") +\n  scale_color_identity()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#likelihood-ratio-test",
    "href": "initial_modeling.html#likelihood-ratio-test",
    "title": "4  Modeling Diabetes Occurence",
    "section": "5.1 Likelihood Ratio Test",
    "text": "5.1 Likelihood Ratio Test",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#model-fit",
    "href": "initial_modeling.html#model-fit",
    "title": "4  Modeling Diabetes Occurence",
    "section": "5.2 Model Fit",
    "text": "5.2 Model Fit",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#calibration-plot",
    "href": "initial_modeling.html#calibration-plot",
    "title": "4  Modeling Diabetes Occurence",
    "section": "5.3 Calibration Plot",
    "text": "5.3 Calibration Plot",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#homsler-lemeshow-test",
    "href": "initial_modeling.html#homsler-lemeshow-test",
    "title": "4  Modeling Diabetes Occurence",
    "section": "5.4 Homsler-Lemeshow Test",
    "text": "5.4 Homsler-Lemeshow Test",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#roc-curve",
    "href": "initial_modeling.html#roc-curve",
    "title": "4  Modeling Diabetes Occurence",
    "section": "5.5 ROC Curve",
    "text": "5.5 ROC Curve",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#residuals-histogram",
    "href": "initial_modeling.html#residuals-histogram",
    "title": "4  Modeling Diabetes Occurence",
    "section": "5.6 Residuals Histogram",
    "text": "5.6 Residuals Histogram",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  },
  {
    "objectID": "initial_modeling.html#ignore",
    "href": "initial_modeling.html#ignore",
    "title": "4  Modeling Diabetes Occurence",
    "section": "5.7 Ignore///",
    "text": "5.7 Ignore///\nI followed a guide online but I don’t really know what this is doing:\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"demo_age_years\"]*demo_age_years + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = demo_age_years, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nclean_nhanes %&gt;% \n  mutate(comp_res = coef(full_diab_model_sys)[\"bp_sys_mean\"]*bp_sys_mean + residuals(full_diab_model_sys, type = \"working\")) %&gt;% \n  ggplot(aes(x = bp_sys_mean, y = comp_res)) +\n  geom_point() +\n  geom_smooth(color = \"red\", method = \"lm\", linetype = 2, se = F) +\n  geom_smooth(se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nTest for Multicollinearity\n\nvif(full_diab_model_sys)\n\n                   GVIF Df GVIF^(1/(2*Df))\nbp_sys_mean    1.169212  1        1.081301\ndemo_age_years 1.528167  1        1.236191\ndemo_race      1.207663  4        1.023866\ndemo_gender    1.091056  1        1.044536\ncc_bmi         1.182024  3        1.028263\ncc_smoke       1.173951  2        1.040908\nbp_med_use     1.235766  1        1.111650\n\n\nOutliers\n\noutlier_nhanes &lt;-\n  clean_nhanes %&gt;% \n  mutate(dffits = dffits(full_diab_model_sys))\n\noutlier_nhanes %&gt;% \n  mutate(obs_number = row_number(),\n         large = ifelse(abs(dffits) &gt; 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)),\n                        \"red\", \"black\")) %&gt;% \n  ggplot(aes(obs_number, dffits, color = large)) +\n  geom_point() + \n  geom_hline(yintercept = c(-1,1) * 2*sqrt(length(coef(full_diab_model_sys))/nobs(full_diab_model_sys)), color = \"red\") +\n  scale_color_identity()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modeling Diabetes Occurence</span>"
    ]
  }
]